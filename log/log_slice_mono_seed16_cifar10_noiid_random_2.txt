nohup: 忽略输入
/home/jndx/STRAGGLER/mono-cnn-pytorch-main/FedMono/../models/layers/monoconv.py:54: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  'mono_exponent', torch.tensor(#mono_exponent被注册为模型的一部分，但不会作为可训练的参数进行优化，生成的m个滤波器都在这。
/home/jndx/STRAGGLER/mono-cnn-pytorch-main/FedMono/..
iid:False, method:slice, seed:16, model:resnet18, variant:mono, cifar100:False, onebyone:False,checkpoint,Noneteacher:None
==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
4545
4545
4545
4545
4545
4545
4545
4545
4545
4545
4545
==> Building model..
layer4.0: 1387520
layer3.0: 366080
1.conv1: 139968
layer2.0: 101120
layer4.1: 74752
layer3.1: 37376
layer1.0: 18688
layer2.1: 18688
layer1.1: 9344
linear: 5130
1.bn1: 2048
Epoch:0
0
Train Loss: 0.425 | Acc: 83.542 (3797/4545)
Train Loss: 0.160 | Acc: 93.971 (4271/4545)
1
Train Loss: 0.427 | Acc: 84.752 (3852/4545)
Train Loss: 0.193 | Acc: 92.035 (4183/4545)
2
Train Loss: 0.417 | Acc: 86.645 (3938/4545)
Train Loss: 0.186 | Acc: 93.355 (4243/4545)
3
Train Loss: 0.689 | Acc: 67.063 (3048/4545)
Train Loss: 0.478 | Acc: 77.338 (3515/4545)
4
Train Loss: 0.141 | Acc: 95.028 (4319/4545)
Train Loss: 0.000 | Acc: 100.000 (4545/4545)
5
Train Loss: 0.689 | Acc: 69.043 (3138/4545)
Train Loss: 0.512 | Acc: 77.470 (3521/4545)
6
Train Loss: 0.699 | Acc: 67.085 (3049/4545)
Train Loss: 0.482 | Acc: 77.778 (3535/4545)
7
Train Loss: 0.502 | Acc: 79.560 (3616/4545)
Train Loss: 0.271 | Acc: 89.329 (4060/4545)
8
Train Loss: 0.109 | Acc: 96.942 (4406/4545)
Train Loss: 0.000 | Acc: 100.000 (4545/4545)
9
Train Loss: 0.380 | Acc: 86.777 (3944/4545)
Train Loss: 0.135 | Acc: 94.785 (4308/4545)
10
Train Loss: 0.599 | Acc: 73.311 (3332/4545)
Train Loss: 0.349 | Acc: 85.743 (3897/4545)
layer3.0
layer1.1
layer4.0
linear
layer3.1
layer2.1
1.conv1
1.bn1
layer4.1
layer2.0
layer1.0
Test Loss: 14.885 | Acc: 10.000 (1000/10000)
mseloss[1]:2.4941539764404297, 2.549222230911255, 2.693422794342041, 1.5637258291244507
mseloss[2]:2.523967981338501, 2.2251954078674316, 2.558119058609009, 1.688263177871704
mseloss[3]:2.500209093093872, 2.59037184715271, 2.624284029006958, 1.5565211772918701
mseloss[4]:2.1024208068847656, 2.0827314853668213, 2.3475053310394287, 1.669464111328125
mseloss[5]:2.7091453075408936, 2.5461721420288086, 2.5989105701446533, 1.5311754941940308
mseloss[6]:2.7746572494506836, 2.84293270111084, 2.916185140609741, 1.6729432344436646
mseloss[7]:2.420067071914673, 2.555861234664917, 2.6295058727264404, 1.6730600595474243
mseloss[8]:2.113468647003174, 2.0973966121673584, 2.38627552986145, 1.6662497520446777
mseloss[9]:2.5867083072662354, 2.446789026260376, 2.581352472305298, 1.7958770990371704
Epoch:1
0
Train Loss: 3.013 | Acc: 72.409 (3291/4545)
Train Loss: 0.204 | Acc: 91.639 (4165/4545)
1
Train Loss: 2.924 | Acc: 70.033 (3183/4545)
Train Loss: 0.235 | Acc: 92.145 (4188/4545)
2
Train Loss: 1.722 | Acc: 62.684 (2849/4545)
Train Loss: 0.469 | Acc: 77.404 (3518/4545)
3
Train Loss: 1.626 | Acc: 77.118 (3505/4545)
Train Loss: 0.000 | Acc: 100.000 (4545/4545)
4
Train Loss: 2.603 | Acc: 43.740 (1988/4545)
Train Loss: 0.408 | Acc: 80.242 (3647/4545)
5
Train Loss: 2.385 | Acc: 44.840 (2038/4545)
Train Loss: 0.398 | Acc: 82.684 (3758/4545)
6
Train Loss: 0.556 | Acc: 72.387 (3290/4545)
Train Loss: 0.446 | Acc: 79.428 (3610/4545)
7
Train Loss: 2.159 | Acc: 60.506 (2750/4545)
Train Loss: 0.197 | Acc: 92.299 (4195/4545)
8
Train Loss: 1.497 | Acc: 74.653 (3393/4545)
Train Loss: 0.000 | Acc: 100.000 (4545/4545)
9
Train Loss: 0.849 | Acc: 69.989 (3181/4545)
Train Loss: 0.481 | Acc: 78.526 (3569/4545)
10
Train Loss: 1.532 | Acc: 63.696 (2895/4545)
Train Loss: 0.223 | Acc: 90.759 (4125/4545)
1.conv1
layer4.1
layer2.0
linear
layer2.1
layer3.1
layer1.0
layer3.0
1.bn1
layer1.1
layer4.0
Test Loss: 27.076 | Acc: 10.000 (1000/10000)
mseloss[1]:2.1263320446014404, 2.1706955432891846, 3.927259683609009, 0.5481589436531067
mseloss[2]:2.2619855403900146, 2.299609899520874, 4.031301021575928, 0.5600833892822266
mseloss[3]:1.9134465456008911, 2.1303460597991943, 4.1661882400512695, 0.5729600191116333
mseloss[4]:2.3155357837677, 2.384390115737915, 3.938947916030884, 0.5863155722618103
mseloss[5]:2.387030601501465, 2.884166955947876, 4.157351493835449, 0.547372579574585
mseloss[6]:2.2954750061035156, 2.4064817428588867, 3.5371243953704834, 0.7542433738708496
mseloss[7]:2.273341655731201, 2.480436325073242, 3.7466678619384766, 0.5442571640014648
mseloss[8]:2.178553581237793, 2.13517165184021, 3.064772367477417, 0.650274395942688
mseloss[9]:2.2783446311950684, 2.210296392440796, 4.040167808532715, 0.521564781665802
Epoch:2
0
Train Loss: 5.107 | Acc: 17.008 (773/4545)
Train Loss: 0.624 | Acc: 71.331 (3242/4545)
1
Train Loss: 5.226 | Acc: 14.477 (658/4545)
Train Loss: 0.602 | Acc: 66.249 (3011/4545)
2
Train Loss: 0.000 | Acc: 100.000 (4545/4545)
Train Loss: 0.000 | Acc: 100.000 (4545/4545)
3
Train Loss: 5.103 | Acc: 17.756 (807/4545)
Train Loss: 0.546 | Acc: 74.895 (3404/4545)
4
Train Loss: 5.327 | Acc: 29.593 (1345/4545)
Train Loss: 0.000 | Acc: 100.000 (4545/4545)
5
Train Loss: 4.850 | Acc: 24.180 (1099/4545)
Train Loss: 0.377 | Acc: 90.099 (4095/4545)
6
Train Loss: 6.462 | Acc: 11.243 (511/4545)
Train Loss: 0.334 | Acc: 86.513 (3932/4545)
7
Train Loss: 3.512 | Acc: 36.282 (1649/4545)
Train Loss: 0.304 | Acc: 90.869 (4130/4545)
8
Train Loss: 2.640 | Acc: 35.050 (1593/4545)
Train Loss: 0.501 | Acc: 79.978 (3635/4545)
9
Train Loss: 2.868 | Acc: 34.103 (1550/4545)
Train Loss: 0.565 | Acc: 74.257 (3375/4545)
10
Train Loss: 2.296 | Acc: 23.388 (1063/4545)
Train Loss: 0.618 | Acc: 66.755 (3034/4545)
layer2.1
layer4.1
layer3.1
layer1.1
layer1.0
layer2.0
linear
layer4.0
layer3.0
1.bn1
1.conv1
Test Loss: 6.655 | Acc: 10.000 (1000/10000)
mseloss[1]:2.0399203300476074, 2.40984845161438, 3.1720762252807617, 0.205964595079422
mseloss[2]:2.012860059738159, 2.179823160171509, 2.32779860496521, 0.1555289775133133
mseloss[3]:2.616748809814453, 4.570823669433594, 6.799028396606445, 0.17438946664333344
mseloss[4]:2.3149986267089844, 3.4575538635253906, 3.812788724899292, 0.21419167518615723
mseloss[5]:2.549299955368042, 3.965313196182251, 6.2939772605896, 0.13111652433872223
mseloss[6]:2.605604410171509, 3.450185775756836, 5.059528350830078, 0.22682777047157288
mseloss[7]:2.3352627754211426, 2.7142889499664307, 3.542849540710449, 0.2978259027004242
mseloss[8]:2.1674869060516357, 3.063861131668091, 3.5558619499206543, 0.15199080109596252
mseloss[9]:2.039393663406372, 2.6383583545684814, 3.481189727783203, 0.12846894562244415
Epoch:3
0
Train Loss: 0.930 | Acc: 76.282 (3467/4545)
Train Loss: 0.230 | Acc: 91.639 (4165/4545)
1
Train Loss: 1.789 | Acc: 65.215 (2964/4545)
Train Loss: 0.000 | Acc: 100.000 (4545/4545)
2
Train Loss: 1.914 | Acc: 50.451 (2293/4545)
Train Loss: 0.380 | Acc: 83.454 (3793/4545)
3
Train Loss: 2.897 | Acc: 32.189 (1463/4545)
Train Loss: 0.557 | Acc: 73.355 (3334/4545)
4
Train Loss: 2.822 | Acc: 26.843 (1220/4545)
Train Loss: 0.550 | Acc: 71.617 (3255/4545)
5
Train Loss: 0.264 | Acc: 89.329 (4060/4545)
Train Loss: 0.159 | Acc: 93.751 (4261/4545)
6
Train Loss: 2.814 | Acc: 27.041 (1229/4545)
Train Loss: 0.604 | Acc: 67.261 (3057/4545)
7
Train Loss: 2.140 | Acc: 49.175 (2235/4545)
Train Loss: 0.303 | Acc: 91.111 (4141/4545)
8
Train Loss: 1.993 | Acc: 33.729 (1533/4545)
Train Loss: 0.655 | Acc: 60.550 (2752/4545)
9
Train Loss: 1.794 | Acc: 51.419 (2337/4545)
Train Loss: 0.362 | Acc: 84.928 (3860/4545)
10
Train Loss: 1.083 | Acc: 69.373 (3153/4545)
Train Loss: 0.000 | Acc: 100.000 (4545/4545)
layer3.1
layer4.1
1.bn1
layer1.1
layer3.0
layer2.1
layer2.0
linear
layer4.0
1.conv1
layer1.0
Test Loss: 8.903 | Acc: 10.000 (1000/10000)
mseloss[1]:1.9255589246749878, 2.6736159324645996, 4.380932807922363, 0.39336487650871277
mseloss[2]:1.750503420829773, 2.328730344772339, 4.13298225402832, 0.39788496494293213
mseloss[3]:1.987920880317688, 3.201328992843628, 4.948879241943359, 0.1322300285100937
mseloss[4]:1.8221551179885864, 3.0265891551971436, 3.740600109100342, 0.29387006163597107
mseloss[5]:1.7023249864578247, 1.9221783876419067, 3.275137424468994, 0.4000878930091858
mseloss[6]:1.8199530839920044, 2.5305395126342773, 3.818683385848999, 0.16938996315002441
mseloss[7]:1.958522915840149, 2.910019874572754, 4.074367046356201, 0.19846990704536438
mseloss[8]:1.8311030864715576, 2.579362154006958, 5.073596477508545, 0.16427373886108398
mseloss[9]:1.8099358081817627, 2.872453212738037, 4.448605537414551, 0.15433111786842346
Epoch:4
0
Train Loss: 2.415 | Acc: 34.389 (1563/4545)
Train Loss: 0.615 | Acc: 70.869 (3221/4545)
1
Train Loss: 0.280 | Acc: 86.029 (3910/4545)
Train Loss: 0.000 | Acc: 100.000 (4545/4545)
2
Train Loss: 2.229 | Acc: 30.693 (1395/4545)
Train Loss: 0.631 | Acc: 64.334 (2924/4545)
3
Train Loss: 2.105 | Acc: 34.037 (1547/4545)
Train Loss: 0.672 | Acc: 62.002 (2818/4545)
4
Train Loss: 1.716 | Acc: 32.431 (1474/4545)
Train Loss: 0.578 | Acc: 70.627 (3210/4545)
5
Train Loss: 0.327 | Acc: 90.253 (4102/4545)
Train Loss: 0.240 | Acc: 91.771 (4171/4545)
6
Train Loss: 1.270 | Acc: 65.897 (2995/4545)
Train Loss: 0.001 | Acc: 100.000 (4545/4545)
7
Train Loss: 2.242 | Acc: 43.278 (1967/4545)
Train Loss: 0.289 | Acc: 88.427 (4019/4545)
8
Train Loss: 1.722 | Acc: 53.267 (2421/4545)
Train Loss: 0.362 | Acc: 90.099 (4095/4545)
9
Train Loss: 1.583 | Acc: 54.873 (2494/4545)
Train Loss: 0.294 | Acc: 87.393 (3972/4545)
10
Train Loss: 2.394 | Acc: 35.622 (1619/4545)
Train Loss: 0.560 | Acc: 74.257 (3375/4545)
layer3.0
layer4.1
layer2.1
layer3.1
layer1.1
layer1.0
linear
1.conv1
layer2.0
1.bn1
layer4.0
Test Loss: 27.791 | Acc: 10.000 (1000/10000)
mseloss[1]:1.662304162979126, 2.31258225440979, 3.8773903846740723, 0.44811195135116577
mseloss[2]:1.973551630973816, 3.2788796424865723, 5.259017467498779, 0.1127837672829628
mseloss[3]:1.893204689025879, 3.2211592197418213, 5.120023727416992, 0.10364298522472382
mseloss[4]:1.5184646844863892, 1.9763692617416382, 1.5248945951461792, 0.10169557482004166
mseloss[5]:1.8194676637649536, 3.115902900695801, 4.779587745666504, 0.1473320871591568
mseloss[6]:1.642760992050171, 1.765256404876709, 1.5975368022918701, 0.07108556479215622
mseloss[7]:1.6566816568374634, 2.380518674850464, 3.83921480178833, 0.44012942910194397
mseloss[8]:1.5891168117523193, 1.986403226852417, 1.855901837348938, 0.07957731187343597
mseloss[9]:1.5905691385269165, 2.4050168991088867, 4.280104637145996, 0.23616503179073334
Epoch:5
0
Train Loss: 3.860 | Acc: 36.744 (1670/4545)
Train Loss: 0.176 | Acc: 93.509 (4250/4545)
1
Train Loss: 0.001 | Acc: 100.000 (4545/4545)
Train Loss: 0.000 | Acc: 100.000 (4545/4545)
2
Train Loss: 4.792 | Acc: 27.855 (1266/4545)
Train Loss: 0.579 | Acc: 72.409 (3291/4545)
3
Train Loss: 3.387 | Acc: 21.254 (966/4545)
Train Loss: 0.603 | Acc: 71.111 (3232/4545)
4
Train Loss: 0.660 | Acc: 80.550 (3661/4545)
Train Loss: 0.000 | Acc: 100.000 (4545/4545)
5
Train Loss: 1.353 | Acc: 67.833 (3083/4545)
Train Loss: 0.251 | Acc: 90.671 (4121/4545)
6
Train Loss: 1.839 | Acc: 41.782 (1899/4545)
Train Loss: 0.298 | Acc: 87.151 (3961/4545)
7
Train Loss: 0.640 | Acc: 77.646 (3529/4545)
Train Loss: 0.223 | Acc: 92.365 (4198/4545)
8
Train Loss: 2.434 | Acc: 26.359 (1198/4545)
Train Loss: 0.603 | Acc: 66.821 (3037/4545)
9
Train Loss: 2.235 | Acc: 23.322 (1060/4545)
Train Loss: 0.582 | Acc: 69.197 (3145/4545)
10
Train Loss: 1.931 | Acc: 36.326 (1651/4545)
Train Loss: 0.521 | Acc: 75.534 (3433/4545)
layer2.1
layer3.1
layer3.0
1.conv1
layer4.0
layer4.1
linear
layer1.1
layer1.0
1.bn1
layer2.0
Test Loss: 9.659 | Acc: 10.000 (1000/10000)
mseloss[1]:1.547324538230896, 1.6654599905014038, 1.6006481647491455, 0.6287042498588562
mseloss[2]:1.8133245706558228, 2.396812915802002, 2.891737699508667, 0.6252443790435791
mseloss[3]:1.8142452239990234, 1.983583927154541, 3.4455270767211914, 0.6830703616142273
mseloss[4]:1.639681339263916, 1.8300542831420898, 3.5769169330596924, 0.8503282070159912
mseloss[5]:1.7102288007736206, 1.8767852783203125, 2.121708393096924, 0.6340805888175964
mseloss[6]:1.7318063974380493, 2.223727226257324, 3.5915470123291016, 0.6253376603126526
mseloss[7]:1.6315016746520996, 1.8527754545211792, 2.554098606109619, 0.6611469388008118
mseloss[8]:1.7329500913619995, 1.8463431596755981, 3.7314748764038086, 0.6566175222396851
mseloss[9]:1.8586406707763672, 2.1507065296173096, 3.6110310554504395, 0.6137142777442932
Epoch:6
0
Train Loss: 1.748 | Acc: 40.968 (1862/4545)
Train Loss: 0.554 | Acc: 75.138 (3415/4545)
1
Train Loss: 0.377 | Acc: 83.366 (3789/4545)
Train Loss: 0.188 | Acc: 92.497 (4204/4545)
2
Train Loss: 1.737 | Acc: 47.371 (2153/4545)
Train Loss: 0.189 | Acc: 92.497 (4204/4545)
3
Train Loss: 1.402 | Acc: 57.184 (2599/4545)
Train Loss: 0.291 | Acc: 90.121 (4096/4545)
4
Train Loss: 2.136 | Acc: 28.317 (1287/4545)
Train Loss: 0.663 | Acc: 64.400 (2927/4545)
5
Train Loss: 0.585 | Acc: 79.318 (3605/4545)
Train Loss: 0.000 | Acc: 100.000 (4545/4545)
6
Train Loss: 2.257 | Acc: 25.413 (1155/4545)
Train Loss: 0.622 | Acc: 66.337 (3015/4545)
7
Train Loss: 1.835 | Acc: 38.482 (1749/4545)
Train Loss: 0.480 | Acc: 77.910 (3541/4545)
8
Train Loss: 2.513 | Acc: 25.127 (1142/4545)
Train Loss: 0.550 | Acc: 72.167 (3280/4545)
9
Train Loss: 0.277 | Acc: 88.669 (4030/4545)
Train Loss: 0.000 | Acc: 100.000 (4545/4545)
10
Train Loss: 0.529 | Acc: 81.408 (3700/4545)
Train Loss: 0.268 | Acc: 90.583 (4117/4545)
1.conv1
layer4.0
1.bn1
layer3.0
layer1.1
layer2.1
layer1.0
layer3.1
layer4.1
linear
layer2.0
Test Loss: 9.637 | Acc: 10.000 (1000/10000)
mseloss[1]:1.5951446294784546, 1.9025524854660034, 3.5121233463287354, 0.2554973363876343
mseloss[2]:1.3501625061035156, 1.604717493057251, 3.313488245010376, 0.3315693140029907
mseloss[3]:1.4488794803619385, 1.509130835533142, 1.33054518699646, 0.08201052993535995
mseloss[4]:1.3912930488586426, 1.4133095741271973, 1.0620614290237427, 0.09454552829265594
mseloss[5]:1.5156733989715576, 1.6902995109558105, 2.317660093307495, 0.2987479567527771
mseloss[6]:1.774259328842163, 2.705545663833618, 4.7977190017700195, 0.1750064194202423
mseloss[7]:1.4082701206207275, 1.4316606521606445, 1.0495774745941162, 0.12298349291086197
mseloss[8]:1.734156608581543, 2.731149911880493, 3.9147534370422363, 0.17752882838249207
mseloss[9]:1.5669891834259033, 1.3189401626586914, 0.7892532348632812, 0.15353024005889893
Epoch:7
0
Train Loss: 0.869 | Acc: 74.213 (3373/4545)
Train Loss: 0.227 | Acc: 92.255 (4193/4545)
1
Train Loss: 0.712 | Acc: 70.451 (3202/4545)
Train Loss: 0.183 | Acc: 92.827 (4219/4545)
2
Train Loss: 0.973 | Acc: 69.307 (3150/4545)
Train Loss: 0.239 | Acc: 90.363 (4107/4545)
3
Train Loss: 2.037 | Acc: 31.111 (1414/4545)
Train Loss: 0.679 | Acc: 59.362 (2698/4545)
4
Train Loss: 1.888 | Acc: 41.892 (1904/4545)
Train Loss: 0.480 | Acc: 77.712 (3532/4545)
5
Train Loss: 0.041 | Acc: 99.846 (4538/4545)
Train Loss: 0.001 | Acc: 100.000 (4545/4545)
6
Train Loss: 1.513 | Acc: 54.433 (2474/4545)
Train Loss: 0.171 | Acc: 93.531 (4251/4545)
7
Train Loss: 2.056 | Acc: 32.629 (1483/4545)
Train Loss: 0.480 | Acc: 78.944 (3588/4545)
8
Train Loss: 2.530 | Acc: 23.520 (1069/4545)
Train Loss: 0.615 | Acc: 67.613 (3073/4545)
9
Train Loss: 1.295 | Acc: 52.739 (2397/4545)
Train Loss: 0.488 | Acc: 78.394 (3563/4545)
10
Train Loss: 0.895 | Acc: 69.703 (3168/4545)
Train Loss: 0.000 | Acc: 100.000 (4545/4545)
layer3.1
1.bn1
1.conv1
layer3.0
layer2.1
layer2.0
layer4.1
layer1.1
layer4.0
layer1.0
linear
Test Loss: 14.369 | Acc: 10.000 (1000/10000)
mseloss[1]:1.6629887819290161, 2.253209114074707, 2.887241840362549, 0.4782191812992096
mseloss[2]:1.7181861400604248, 2.867567300796509, 4.881078720092773, 0.24972642958164215
mseloss[3]:1.7623435258865356, 2.7198684215545654, 5.629456520080566, 0.24075336754322052
mseloss[4]:1.8838098049163818, 2.995068311691284, 4.5160231590271, 0.24623465538024902
mseloss[5]:1.6722838878631592, 2.492969274520874, 4.955037593841553, 0.27625709772109985
mseloss[6]:1.750335931777954, 2.5890164375305176, 3.312310218811035, 0.33037200570106506
mseloss[7]:1.7464443445205688, 2.504610538482666, 5.00370979309082, 0.24273858964443207
mseloss[8]:1.9593126773834229, 2.760098457336426, 3.422816276550293, 0.2529723346233368
mseloss[9]:1.7795504331588745, 2.87314772605896, 4.943817138671875, 0.24785293638706207
Epoch:8
0
Train Loss: 2.479 | Acc: 27.393 (1245/4545)
Train Loss: 0.713 | Acc: 63.080 (2867/4545)
1
Train Loss: 1.726 | Acc: 45.787 (2081/4545)
Train Loss: 0.222 | Acc: 91.221 (4146/4545)
2
Train Loss: 1.670 | Acc: 38.680 (1758/4545)
Train Loss: 0.508 | Acc: 77.492 (3522/4545)
3
Train Loss: 1.895 | Acc: 34.433 (1565/4545)
Train Loss: 0.559 | Acc: 74.411 (3382/4545)
4
Train Loss: 1.692 | Acc: 42.486 (1931/4545)
Train Loss: 0.481 | Acc: 78.570 (3571/4545)
5
Train Loss: 0.041 | Acc: 100.000 (4545/4545)
Train Loss: 0.000 | Acc: 100.000 (4545/4545)
6
Train Loss: 1.101 | Acc: 65.787 (2990/4545)
Train Loss: 0.276 | Acc: 90.165 (4098/4545)
7
Train Loss: 2.140 | Acc: 24.510 (1114/4545)
Train Loss: 0.673 | Acc: 68.801 (3127/4545)
8
Train Loss: 0.513 | Acc: 80.528 (3660/4545)
Train Loss: 0.002 | Acc: 100.000 (4545/4545)
9
Train Loss: 0.907 | Acc: 68.339 (3106/4545)
Train Loss: 0.260 | Acc: 90.715 (4123/4545)
10
Train Loss: 1.137 | Acc: 60.748 (2761/4545)
Train Loss: 0.218 | Acc: 91.529 (4160/4545)
layer1.0
layer4.0
linear
layer3.1
layer2.1
1.bn1
layer4.1
layer3.0
1.conv1
layer1.1
layer2.0
Test Loss: 5.813 | Acc: 10.000 (1000/10000)
mseloss[1]:1.9691137075424194, 2.2812602519989014, 4.448622226715088, 0.15218573808670044
mseloss[2]:1.6149561405181885, 1.9445350170135498, 2.522503137588501, 0.05065659433603287
mseloss[3]:1.5394763946533203, 1.3180161714553833, 1.030082106590271, 0.053700536489486694
mseloss[4]:1.7285085916519165, 1.864640474319458, 2.2392656803131104, 0.06702636182308197
mseloss[5]:1.5654398202896118, 1.7172142267227173, 3.3047823905944824, 0.108675017952919
mseloss[6]:1.464532494544983, 1.2999500036239624, 1.9687339067459106, 0.07618881016969681
mseloss[7]:1.5476677417755127, 1.286138653755188, 1.1199071407318115, 0.042289432138204575
mseloss[8]:1.5466505289077759, 1.4448597431182861, 2.4351937770843506, 0.09754765778779984
mseloss[9]:1.555253028869629, 1.7459845542907715, 3.1073548793792725, 0.07827401906251907
Epoch:9
0
Train Loss: 2.210 | Acc: 27.877 (1267/4545)
Train Loss: 0.513 | Acc: 76.920 (3496/4545)
1
Train Loss: 1.218 | Acc: 60.440 (2747/4545)
Train Loss: 0.272 | Acc: 90.363 (4107/4545)
2
Train Loss: 2.218 | Acc: 27.261 (1239/4545)
Train Loss: 0.554 | Acc: 74.455 (3384/4545)
3
Train Loss: 0.696 | Acc: 77.888 (3540/4545)
Train Loss: 0.001 | Acc: 100.000 (4545/4545)
4
Train Loss: 0.470 | Acc: 85.171 (3871/4545)
Train Loss: 0.000 | Acc: 100.000 (4545/4545)
5
Train Loss: 1.071 | Acc: 66.447 (3020/4545)
Train Loss: 0.162 | Acc: 93.927 (4269/4545)
6
Train Loss: 0.712 | Acc: 68.757 (3125/4545)
Train Loss: 0.199 | Acc: 92.365 (4198/4545)
7
Train Loss: 0.678 | Acc: 77.404 (3518/4545)
Train Loss: 0.225 | Acc: 92.211 (4191/4545)
8
Train Loss: 1.682 | Acc: 41.694 (1895/4545)
Train Loss: 0.390 | Acc: 83.674 (3803/4545)
9
Train Loss: 1.502 | Acc: 49.439 (2247/4545)
Train Loss: 0.529 | Acc: 74.213 (3373/4545)
10
Train Loss: 0.685 | Acc: 74.697 (3395/4545)
Train Loss: 0.469 | Acc: 79.296 (3604/4545)
1.bn1
layer1.0
layer3.0
layer3.1
layer4.1
layer1.1
layer4.0
layer2.1
1.conv1
layer2.0
linear
Test Loss: 7.065 | Acc: 9.720 (972/10000)
mseloss[1]:1.5691601037979126, 1.938306450843811, 3.361567974090576, 0.14962904155254364
mseloss[2]:1.4180591106414795, 1.3641949892044067, 1.6968884468078613, 0.09563583880662918
mseloss[3]:1.4802873134613037, 1.7116247415542603, 3.0950021743774414, 0.2991222143173218
mseloss[4]:1.5298631191253662, 1.8299368619918823, 1.8172844648361206, 0.7247753739356995
mseloss[5]:1.4915047883987427, 1.4900559186935425, 1.86164391040802, 0.14218826591968536
mseloss[6]:1.5512791872024536, 1.6726362705230713, 1.8457528352737427, 0.35866159200668335
mseloss[7]:1.4960637092590332, 1.6481808423995972, 2.340784788131714, 0.38185611367225647
mseloss[8]:1.5714924335479736, 1.6436203718185425, 2.5040345191955566, 0.17711196839809418
mseloss[9]:1.4488255977630615, 1.7087352275848389, 3.341973304748535, 0.14340665936470032
Epoch:10
0
Train Loss: 1.475 | Acc: 57.228 (2601/4545)
Train Loss: 0.178 | Acc: 93.245 (4238/4545)
1
Train Loss: 0.357 | Acc: 88.427 (4019/4545)
Train Loss: 0.000 | Acc: 100.000 (4545/4545)
2
Train Loss: 0.585 | Acc: 75.820 (3446/4545)
Train Loss: 0.456 | Acc: 79.560 (3616/4545)
3
Train Loss: 2.374 | Acc: 31.309 (1423/4545)
Train Loss: 0.587 | Acc: 72.343 (3288/4545)
4
Train Loss: 1.159 | Acc: 61.870 (2812/4545)
Train Loss: 0.192 | Acc: 93.399 (4245/4545)
5
Train Loss: 2.536 | Acc: 14.807 (673/4545)
Train Loss: 0.761 | Acc: 52.607 (2391/4545)
6
Train Loss: 1.753 | Acc: 44.510 (2023/4545)
Train Loss: 0.568 | Acc: 73.399 (3336/4545)
7
Train Loss: 1.427 | Acc: 57.338 (2606/4545)
Train Loss: 0.272 | Acc: 90.759 (4125/4545)
8
Train Loss: 2.339 | Acc: 22.860 (1039/4545)
Train Loss: 0.612 | Acc: 71.265 (3239/4545)
9
Train Loss: 0.794 | Acc: 75.534 (3433/4545)
Train Loss: 0.001 | Acc: 100.000 (4545/4545)
10
Train Loss: 0.692 | Acc: 70.583 (3208/4545)
Train Loss: 0.175 | Acc: 93.201 (4236/4545)
1.bn1
layer2.0
layer4.0
layer2.1
layer3.0
1.conv1
layer4.1
layer3.1
linear
layer1.1
layer1.0
Test Loss: 4.216 | Acc: 9.920 (992/10000)
mseloss[1]:1.3596054315567017, 1.7395753860473633, 3.393268346786499, 0.4012852609157562
mseloss[2]:1.3891775608062744, 1.397580623626709, 2.5555107593536377, 0.3697313368320465
mseloss[3]:1.5391044616699219, 2.2034010887145996, 3.139626979827881, 0.2714223563671112
mseloss[4]:1.4964243173599243, 1.2904306650161743, 2.2152791023254395, 0.4658504128456116
mseloss[5]:1.5556154251098633, 1.8495535850524902, 4.703697681427002, 0.27543219923973083
mseloss[6]:1.5794330835342407, 1.99297034740448, 3.887479305267334, 0.2765960991382599
mseloss[7]:1.409529209136963, 1.5180445909500122, 3.1742615699768066, 0.24412865936756134
mseloss[8]:1.555419683456421, 1.667079210281372, 2.2814483642578125, 0.23368407785892487
mseloss[9]:1.3751097917556763, 1.6581000089645386, 3.9916508197784424, 0.37071892619132996
Epoch:11
0
Train Loss: 0.569 | Acc: 86.073 (3912/4545)
Train Loss: 0.000 | Acc: 100.000 (4545/4545)
1
Train Loss: 1.576 | Acc: 58.680 (2667/4545)
Train Loss: 0.506 | Acc: 76.480 (3476/4545)
2
Train Loss: 0.422 | Acc: 81.914 (3723/4545)
Train Loss: 0.269 | Acc: 89.175 (4053/4545)
3
Train Loss: 2.079 | Acc: 40.044 (1820/4545)
Train Loss: 0.501 | Acc: 76.898 (3495/4545)
4
Train Loss: 0.770 | Acc: 78.636 (3574/4545)
Train Loss: 0.000 | Acc: 100.000 (4545/4545)
5
Train Loss: 1.000 | Acc: 72.211 (3282/4545)
Train Loss: 0.165 | Acc: 94.125 (4278/4545)
6
Train Loss: 1.880 | Acc: 59.582 (2708/4545)
Train Loss: 0.226 | Acc: 91.331 (4151/4545)
7
Train Loss: 0.587 | Acc: 79.076 (3594/4545)
Train Loss: 0.143 | Acc: 94.477 (4294/4545)
8
Train Loss: 0.709 | Acc: 68.229 (3101/4545)
Train Loss: 0.467 | Acc: 78.988 (3590/4545)
9
Train Loss: 1.776 | Acc: 52.959 (2407/4545)
Train Loss: 0.209 | Acc: 92.079 (4185/4545)
10
Train Loss: 1.182 | Acc: 64.994 (2954/4545)
Train Loss: 0.297 | Acc: 87.767 (3989/4545)
layer3.0
layer1.1
layer2.1
1.bn1
linear
layer3.1
layer4.1
layer2.0
layer4.0
layer1.0
1.conv1
Test Loss: 5.422 | Acc: 10.020 (1002/10000)
mseloss[1]:1.5626286268234253, 1.823172688484192, 2.1995649337768555, 0.5725148916244507
mseloss[2]:1.3418878316879272, 1.5977712869644165, 1.2624926567077637, 0.5169562101364136
mseloss[3]:1.5298454761505127, 1.9929988384246826, 2.390317916870117, 0.6033053994178772
mseloss[4]:1.318225383758545, 1.4827042818069458, 0.7469642758369446, 0.46976256370544434
mseloss[5]:1.3589656352996826, 1.586055874824524, 0.8232287168502808, 0.6535168290138245
mseloss[6]:1.387969970703125, 1.6078139543533325, 2.0880086421966553, 0.6236702799797058
mseloss[7]:1.362160563468933, 1.7347115278244019, 1.2888507843017578, 0.5871187448501587
mseloss[8]:1.3589003086090088, 1.340371012687683, 1.1501562595367432, 0.5365557670593262
mseloss[9]:1.4618406295776367, 1.7312356233596802, 1.4707880020141602, 0.5562350749969482
Epoch:12
0
Train Loss: 2.798 | Acc: 47.877 (2176/4545)
Train Loss: 0.197 | Acc: 92.409 (4200/4545)
1
Train Loss: 1.327 | Acc: 60.198 (2736/4545)
Train Loss: 0.460 | Acc: 79.516 (3614/4545)
2
Train Loss: 1.297 | Acc: 68.493 (3113/4545)
Train Loss: 0.174 | Acc: 93.421 (4246/4545)
3
Train Loss: 0.645 | Acc: 82.772 (3762/4545)
Train Loss: 0.000 | Acc: 100.000 (4545/4545)
4
Train Loss: 1.398 | Acc: 61.848 (2811/4545)
Train Loss: 0.248 | Acc: 90.495 (4113/4545)
5
Train Loss: 0.026 | Acc: 99.912 (4541/4545)
Train Loss: 0.000 | Acc: 100.000 (4545/4545)
6
Train Loss: 2.030 | Acc: 37.602 (1709/4545)
Train Loss: 0.550 | Acc: 72.497 (3295/4545)
7
Train Loss: 1.711 | Acc: 45.017 (2046/4545)
Train Loss: 0.526 | Acc: 74.081 (3367/4545)
8
Train Loss: 0.611 | Acc: 79.890 (3631/4545)
Train Loss: 0.156 | Acc: 94.059 (4275/4545)
9
Train Loss: 1.062 | Acc: 64.356 (2925/4545)
Train Loss: 0.304 | Acc: 87.591 (3981/4545)
10
Train Loss: 1.476 | Acc: 63.190 (2872/4545)
Train Loss: 0.207 | Acc: 91.441 (4156/4545)
layer2.1
linear
layer4.1
layer2.0
layer1.0
layer1.1
layer3.0
1.conv1
layer3.1
1.bn1
layer4.0
Test Loss: 3.839 | Acc: 10.810 (1081/10000)
mseloss[1]:1.7159860134124756, 1.7554975748062134, 3.2179510593414307, 0.21461214125156403
mseloss[2]:1.6499779224395752, 1.7573363780975342, 2.7678020000457764, 0.33638134598731995
mseloss[3]:1.6032638549804688, 1.7133381366729736, 2.7571284770965576, 0.40697845816612244
mseloss[4]:1.7835915088653564, 1.8677408695220947, 2.552173137664795, 0.2545720338821411
mseloss[5]:1.6253926753997803, 1.4714423418045044, 2.7049243450164795, 0.5768919587135315
mseloss[6]:1.907551646232605, 2.2205617427825928, 3.4930498600006104, 0.2024109810590744
mseloss[7]:1.9991629123687744, 2.5991899967193604, 3.4360361099243164, 0.19572213292121887
mseloss[8]:1.7279353141784668, 1.9596713781356812, 2.865729808807373, 0.26011204719543457
mseloss[9]:1.801294207572937, 1.889082431793213, 2.9665884971618652, 0.2319500744342804
Epoch:13
0
Train Loss: 1.304 | Acc: 63.212 (2873/4545)
Train Loss: 0.280 | Acc: 90.341 (4106/4545)
1
Train Loss: 1.034 | Acc: 69.043 (3138/4545)
Train Loss: 0.230 | Acc: 91.727 (4169/4545)
2
Train Loss: 0.612 | Acc: 77.294 (3513/4545)
Train Loss: 0.154 | Acc: 93.993 (4272/4545)
3
Train Loss: 0.765 | Acc: 75.490 (3431/4545)
Train Loss: 0.174 | Acc: 93.773 (4262/4545)
4
Train Loss: 1.373 | Acc: 59.934 (2724/4545)
Train Loss: 0.179 | Acc: 93.553 (4252/4545)
5
Train Loss: 0.320 | Acc: 89.461 (4066/4545)
Train Loss: 0.000 | Acc: 100.000 (4545/4545)
6
Train Loss: 0.623 | Acc: 75.512 (3432/4545)
Train Loss: 0.462 | Acc: 79.120 (3596/4545)
7
Train Loss: 1.644 | Acc: 42.442 (1929/4545)
Train Loss: 0.503 | Acc: 76.150 (3461/4545)
8
Train Loss: 0.437 | Acc: 83.388 (3790/4545)
Train Loss: 0.000 | Acc: 100.000 (4545/4545)
9
Train Loss: 1.392 | Acc: 51.375 (2335/4545)
Train Loss: 0.520 | Acc: 74.675 (3394/4545)
10
Train Loss: 0.852 | Acc: 69.219 (3146/4545)
Train Loss: 0.287 | Acc: 88.141 (4006/4545)
layer2.1
1.bn1
layer4.0
layer1.0
layer3.1
layer4.1
layer1.1
1.conv1
layer3.0
linear
layer2.0
Test Loss: 8.343 | Acc: 10.940 (1094/10000)
mseloss[1]:1.5418922901153564, 1.3818359375, 0.9212377071380615, 0.07195451855659485
mseloss[2]:1.5480462312698364, 1.8248037099838257, 1.5499927997589111, 0.1652831733226776
mseloss[3]:1.461519718170166, 1.8410707712173462, 1.9419454336166382, 0.2085755616426468
mseloss[4]:1.4384504556655884, 1.4141749143600464, 1.28738272190094, 0.10700666159391403
mseloss[5]:1.4039233922958374, 1.5791034698486328, 1.389777660369873, 0.2610527276992798
mseloss[6]:1.632332444190979, 1.8701139688491821, 2.2190303802490234, 0.20797668397426605
mseloss[7]:1.548987627029419, 1.4772237539291382, 1.293465495109558, 0.06964313983917236
mseloss[8]:1.5294198989868164, 1.7755383253097534, 2.081289529800415, 0.2869935929775238
mseloss[9]:1.8406519889831543, 2.4960248470306396, 2.2753262519836426, 0.08257192373275757
Epoch:14
0
Train Loss: 0.572 | Acc: 71.595 (3254/4545)
Train Loss: 0.452 | Acc: 79.362 (3607/4545)
1
Train Loss: 1.780 | Acc: 55.798 (2536/4545)
Train Loss: 0.222 | Acc: 91.155 (4143/4545)
2
Train Loss: 2.003 | Acc: 51.573 (2344/4545)
Train Loss: 0.172 | Acc: 93.619 (4255/4545)
3
Train Loss: 1.149 | Acc: 71.155 (3234/4545)
Train Loss: 0.183 | Acc: 93.201 (4236/4545)
4
Train Loss: 0.792 | Acc: 68.471 (3112/4545)
Train Loss: 0.466 | Acc: 79.384 (3608/4545)
5
Train Loss: 0.993 | Acc: 71.023 (3228/4545)
Train Loss: 0.151 | Acc: 93.993 (4272/4545)
6
Train Loss: 0.495 | Acc: 85.171 (3871/4545)
Train Loss: 0.000 | Acc: 100.000 (4545/4545)
7
Train Loss: 0.676 | Acc: 83.124 (3778/4545)
Train Loss: 0.000 | Acc: 100.000 (4545/4545)
8
Train Loss: 1.344 | Acc: 60.176 (2735/4545)
Train Loss: 0.210 | Acc: 92.035 (4183/4545)
9
Train Loss: 1.053 | Acc: 66.513 (3023/4545)
Train Loss: 0.275 | Acc: 89.263 (4057/4545)
10
Train Loss: 0.883 | Acc: 69.153 (3143/4545)
Train Loss: 0.432 | Acc: 80.924 (3678/4545)
1.bn1
layer3.1
layer1.0
1.conv1
layer2.0
layer2.1
linear
layer4.1
layer1.1
layer3.0
layer4.0
Test Loss: 4.501 | Acc: 10.000 (1000/10000)
mseloss[1]:1.6963365077972412, 1.9359749555587769, 2.6356916427612305, 0.20890368521213531
mseloss[2]:1.587029218673706, 1.7413392066955566, 2.2193782329559326, 0.24489831924438477
mseloss[3]:1.5251494646072388, 1.6641080379486084, 2.38382887840271, 0.41950657963752747
mseloss[4]:1.590166687965393, 1.7409340143203735, 2.124246120452881, 0.19104285538196564
mseloss[5]:1.552679181098938, 1.8052396774291992, 2.4221341609954834, 0.23986771702766418
mseloss[6]:1.5278538465499878, 1.6625027656555176, 2.238693952560425, 0.3865780234336853
mseloss[7]:1.536222219467163, 1.6467868089675903, 2.6836800575256348, 0.5922215580940247
mseloss[8]:1.5278024673461914, 1.3806990385055542, 1.2850947380065918, 0.17251946032047272
mseloss[9]:1.5436080694198608, 1.385453224182129, 0.7981275320053101, 0.16830724477767944
Epoch:15
0
Train Loss: 2.195 | Acc: 51.419 (2337/4545)
Train Loss: 0.247 | Acc: 91.045 (4138/4545)
1
Train Loss: 1.746 | Acc: 59.560 (2707/4545)
Train Loss: 0.179 | Acc: 93.157 (4234/4545)
2
Train Loss: 1.920 | Acc: 51.133 (2324/4545)
Train Loss: 0.486 | Acc: 78.086 (3549/4545)
3
Train Loss: 2.390 | Acc: 43.146 (1961/4545)
Train Loss: 0.250 | Acc: 90.869 (4130/4545)
4
Train Loss: 1.697 | Acc: 51.441 (2338/4545)
Train Loss: 0.482 | Acc: 78.152 (3552/4545)
5
Train Loss: 0.013 | Acc: 100.000 (4545/4545)
Train Loss: 0.001 | Acc: 100.000 (4545/4545)
6
Train Loss: 1.985 | Acc: 49.439 (2247/4545)
Train Loss: 0.170 | Acc: 94.213 (4282/4545)
7
Train Loss: 1.074 | Acc: 51.617 (2346/4545)
Train Loss: 0.497 | Acc: 75.996 (3454/4545)
8
Train Loss: 0.677 | Acc: 78.570 (3571/4545)
Train Loss: 0.000 | Acc: 100.000 (4545/4545)
9
Train Loss: 1.131 | Acc: 68.691 (3122/4545)
Train Loss: 0.185 | Acc: 93.025 (4228/4545)
10
Train Loss: 0.750 | Acc: 76.018 (3455/4545)
Train Loss: 0.260 | Acc: 89.637 (4074/4545)
layer3.1
layer2.1
1.bn1
layer2.0
layer4.1
layer1.1
1.conv1
layer1.0
layer3.0
linear
layer4.0
Test Loss: 5.346 | Acc: 10.010 (1001/10000)
mseloss[1]:1.6822468042373657, 2.310504674911499, 2.384920835494995, 0.2938736081123352
mseloss[2]:1.9916198253631592, 3.052544116973877, 2.432814836502075, 0.2520909011363983
mseloss[3]:1.7784762382507324, 2.071949005126953, 1.6530402898788452, 0.19064350426197052
mseloss[4]:1.5511232614517212, 1.2925972938537598, 0.7398127913475037, 0.10391327738761902
mseloss[5]:1.699232578277588, 2.2798686027526855, 2.1847801208496094, 0.2423180490732193
mseloss[6]:1.536926031112671, 1.7801812887191772, 1.6054779291152954, 0.22159233689308167
mseloss[7]:1.740664005279541, 2.4745233058929443, 2.133537769317627, 0.22248564660549164
mseloss[8]:1.5700339078903198, 1.7579623460769653, 1.861838459968567, 0.23982077836990356
mseloss[9]:1.5024763345718384, 1.9150820970535278, 1.9383544921875, 0.3479310870170593
Epoch:16
0
Train Loss: 1.838 | Acc: 56.876 (2585/4545)
Train Loss: 0.356 | Acc: 90.319 (4105/4545)
1
Train Loss: 0.964 | Acc: 64.312 (2923/4545)
Train Loss: 0.444 | Acc: 79.604 (3618/4545)
2
Train Loss: 1.137 | Acc: 66.315 (3014/4545)
Train Loss: 0.231 | Acc: 91.661 (4166/4545)
3
Train Loss: 0.648 | Acc: 73.465 (3339/4545)
Train Loss: 0.277 | Acc: 88.801 (4036/4545)
4
Train Loss: 1.229 | Acc: 68.427 (3110/4545)
Train Loss: 0.176 | Acc: 93.201 (4236/4545)
5
Train Loss: 1.495 | Acc: 56.678 (2576/4545)
Train Loss: 0.501 | Acc: 77.712 (3532/4545)
6
Train Loss: 0.291 | Acc: 89.879 (4085/4545)
Train Loss: 0.000 | Acc: 100.000 (4545/4545)
7
Train Loss: 1.121 | Acc: 54.785 (2490/4545)
Train Loss: 0.516 | Acc: 74.653 (3393/4545)
8
Train Loss: 0.374 | Acc: 87.965 (3998/4545)
Train Loss: 0.176 | Acc: 93.861 (4266/4545)
9
Train Loss: 2.074 | Acc: 50.869 (2312/4545)
Train Loss: 0.178 | Acc: 94.015 (4273/4545)
10
Train Loss: 1.621 | Acc: 66.447 (3020/4545)
Train Loss: 0.001 | Acc: 100.000 (4545/4545)
layer2.0
layer1.1
linear
layer4.1
layer3.1
layer1.0
layer2.1
1.bn1
layer4.0
1.conv1
layer3.0
Test Loss: 4.264 | Acc: 10.090 (1009/10000)
mseloss[1]:1.4681236743927002, 1.5941826105117798, 1.5213415622711182, 0.096491239964962
mseloss[2]:1.5333037376403809, 1.4884973764419556, 1.5029019117355347, 0.11329727619886398
mseloss[3]:1.5722591876983643, 1.8535858392715454, 2.5526621341705322, 0.15147408843040466
mseloss[4]:1.475036382675171, 1.7420374155044556, 2.2795894145965576, 0.20146508514881134
mseloss[5]:1.4482775926589966, 1.557281732559204, 1.5323030948638916, 0.12358025461435318
mseloss[6]:1.60189688205719, 1.6690913438796997, 1.8942326307296753, 0.18725058436393738
mseloss[7]:1.5814238786697388, 2.2651283740997314, 2.8907978534698486, 0.13177642226219177
mseloss[8]:1.4486083984375, 1.5960217714309692, 2.0851285457611084, 0.3382628858089447
mseloss[9]:1.3669099807739258, 1.4365733861923218, 1.407672643661499, 0.11235640197992325
Epoch:17
0
Train Loss: 1.532 | Acc: 46.007 (2091/4545)
Train Loss: 0.537 | Acc: 73.553 (3343/4545)
1
Train Loss: 1.628 | Acc: 54.059 (2457/4545)
Train Loss: 0.471 | Acc: 79.164 (3598/4545)
2
Train Loss: 1.881 | Acc: 54.961 (2498/4545)
Train Loss: 0.285 | Acc: 91.419 (4155/4545)
3
Train Loss: 1.535 | Acc: 49.593 (2254/4545)
Train Loss: 0.468 | Acc: 79.098 (3595/4545)
4
Train Loss: 0.597 | Acc: 80.814 (3673/4545)
Train Loss: 0.000 | Acc: 100.000 (4545/4545)
5
Train Loss: 1.334 | Acc: 63.762 (2898/4545)
Train Loss: 0.166 | Acc: 93.751 (4261/4545)
6
Train Loss: 0.924 | Acc: 70.319 (3196/4545)
Train Loss: 0.279 | Acc: 88.053 (4002/4545)
7
Train Loss: 0.814 | Acc: 75.534 (3433/4545)
Train Loss: 0.149 | Acc: 95.314 (4332/4545)
8
Train Loss: 1.140 | Acc: 72.629 (3301/4545)
Train Loss: 0.000 | Acc: 100.000 (4545/4545)
9
Train Loss: 0.670 | Acc: 78.372 (3562/4545)
Train Loss: 0.167 | Acc: 93.949 (4270/4545)
10
Train Loss: 0.508 | Acc: 81.232 (3692/4545)
Train Loss: 0.202 | Acc: 92.211 (4191/4545)
layer3.0
layer2.0
1.conv1
layer4.0
layer1.0
layer2.1
linear
layer3.1
1.bn1
layer4.1
layer1.1
Test Loss: 8.157 | Acc: 10.000 (1000/10000)
mseloss[1]:1.5729687213897705, 2.230684757232666, 2.507265090942383, 0.2468436062335968
mseloss[2]:1.549572467803955, 2.1829166412353516, 3.409472942352295, 0.222051203250885
mseloss[3]:1.5607004165649414, 2.353060722351074, 3.0995843410491943, 0.17637518048286438
mseloss[4]:1.5757174491882324, 2.054253101348877, 2.3012588024139404, 0.36465880274772644
mseloss[5]:1.5593786239624023, 2.0564260482788086, 2.7631468772888184, 0.29001733660697937
mseloss[6]:1.547588586807251, 1.9243292808532715, 2.6429951190948486, 0.1890774369239807
mseloss[7]:1.4847266674041748, 1.8906792402267456, 2.5976648330688477, 0.22272925078868866
mseloss[8]:1.5113966464996338, 2.2775869369506836, 2.74843692779541, 0.3795262575149536
mseloss[9]:1.4839653968811035, 2.112654209136963, 2.3126487731933594, 0.43745937943458557
Epoch:18
0
Train Loss: 0.462 | Acc: 83.278 (3785/4545)
Train Loss: 0.168 | Acc: 94.147 (4279/4545)
1
Train Loss: 1.689 | Acc: 50.979 (2317/4545)
Train Loss: 0.179 | Acc: 94.807 (4309/4545)
2
Train Loss: 0.669 | Acc: 80.572 (3662/4545)
Train Loss: 0.000 | Acc: 100.000 (4545/4545)
3
Train Loss: 1.041 | Acc: 64.312 (2923/4545)
Train Loss: 0.446 | Acc: 80.110 (3641/4545)
4
Train Loss: 1.968 | Acc: 49.857 (2266/4545)
Train Loss: 0.250 | Acc: 91.573 (4162/4545)
5
Train Loss: 0.208 | Acc: 91.045 (4138/4545)
Train Loss: 0.000 | Acc: 100.000 (4545/4545)
6
Train Loss: 0.632 | Acc: 74.565 (3389/4545)
Train Loss: 0.283 | Acc: 88.515 (4023/4545)
7
Train Loss: 1.133 | Acc: 64.906 (2950/4545)
Train Loss: 0.257 | Acc: 89.725 (4078/4545)
8
Train Loss: 1.037 | Acc: 65.897 (2995/4545)
Train Loss: 0.453 | Acc: 79.626 (3619/4545)
9
Train Loss: 1.029 | Acc: 59.164 (2689/4545)
Train Loss: 0.443 | Acc: 79.648 (3620/4545)
10
Train Loss: 0.792 | Acc: 74.785 (3399/4545)
Train Loss: 0.147 | Acc: 94.345 (4288/4545)
1.bn1
1.conv1
layer1.0
layer3.1
linear
layer2.1
layer4.0
layer4.1
layer1.1
layer2.0
layer3.0
Test Loss: 5.923 | Acc: 10.000 (1000/10000)
mseloss[1]:1.289029598236084, 1.8562464714050293, 2.5436551570892334, 0.33663177490234375
mseloss[2]:1.237538456916809, 1.4185354709625244, 1.8608003854751587, 0.5539325475692749
mseloss[3]:1.2607502937316895, 1.5361062288284302, 1.5933687686920166, 0.41956958174705505
mseloss[4]:1.2397738695144653, 1.4294898509979248, 2.421987295150757, 0.3213307857513428
mseloss[5]:1.2124136686325073, 1.2168784141540527, 1.2639176845550537, 0.5498067736625671
mseloss[6]:1.2741676568984985, 1.2891618013381958, 2.2357311248779297, 0.3577970266342163
mseloss[7]:1.308823823928833, 1.3316947221755981, 1.9885902404785156, 0.30449652671813965
mseloss[8]:1.3760364055633545, 1.605121374130249, 2.466679811477661, 0.3383055031299591
mseloss[9]:1.3000848293304443, 1.3114405870437622, 1.5944159030914307, 0.3467874825000763
Epoch:19
0
Train Loss: 1.548 | Acc: 60.462 (2748/4545)
Train Loss: 0.161 | Acc: 94.103 (4277/4545)
1
Train Loss: 2.254 | Acc: 42.288 (1922/4545)
Train Loss: 0.500 | Acc: 77.316 (3514/4545)
2
Train Loss: 0.913 | Acc: 76.216 (3464/4545)
Train Loss: 0.149 | Acc: 94.433 (4292/4545)
3
Train Loss: 1.041 | Acc: 73.905 (3359/4545)
Train Loss: 0.148 | Acc: 94.499 (4295/4545)
4
Train Loss: 0.572 | Acc: 84.840 (3856/4545)
Train Loss: 0.000 | Acc: 100.000 (4545/4545)
5
Train Loss: 1.320 | Acc: 60.594 (2754/4545)
Train Loss: 0.293 | Acc: 88.141 (4006/4545)
6
Train Loss: 0.296 | Acc: 90.627 (4119/4545)
Train Loss: 0.183 | Acc: 92.915 (4223/4545)
7
Train Loss: 0.984 | Acc: 69.219 (3146/4545)
Train Loss: 0.209 | Acc: 92.145 (4188/4545)
8
Train Loss: 1.681 | Acc: 52.849 (2402/4545)
Train Loss: 0.434 | Acc: 80.308 (3650/4545)
9
Train Loss: 0.491 | Acc: 85.633 (3892/4545)
Train Loss: 0.000 | Acc: 100.000 (4545/4545)
10
Train Loss: 1.082 | Acc: 64.400 (2927/4545)
Train Loss: 0.442 | Acc: 80.132 (3642/4545)
layer1.0
layer2.0
layer1.1
1.conv1
linear
layer3.0
layer4.1
layer2.1
1.bn1
layer4.0
layer3.1
Test Loss: 15.300 | Acc: 10.000 (1000/10000)
mseloss[1]:1.4735102653503418, 1.912284016609192, 1.7151845693588257, 0.10046721994876862
mseloss[2]:1.3255767822265625, 1.7821348905563354, 1.796103596687317, 0.4685118496417999
mseloss[3]:1.3503203392028809, 1.625067114830017, 1.5651341676712036, 0.25453609228134155
mseloss[4]:1.3139609098434448, 1.5037977695465088, 1.4086881875991821, 0.2598211169242859
mseloss[5]:1.5314713716506958, 1.9540739059448242, 2.3731720447540283, 0.15693435072898865
mseloss[6]:1.2647932767868042, 1.5765453577041626, 1.7532265186309814, 0.22863082587718964
mseloss[7]:1.375677466392517, 1.625388264656067, 1.4528791904449463, 0.12537379562854767
mseloss[8]:1.442671537399292, 2.081204652786255, 2.0822975635528564, 0.1635306030511856
mseloss[9]:1.2822084426879883, 1.4285415410995483, 1.5158485174179077, 0.4910869598388672
Epoch:20
0
Train Loss: 0.813 | Acc: 69.659 (3166/4545)
Train Loss: 0.287 | Acc: 88.097 (4004/4545)
1
Train Loss: 1.133 | Acc: 63.564 (2889/4545)
Train Loss: 0.148 | Acc: 94.763 (4307/4545)
2
Train Loss: 0.780 | Acc: 76.282 (3467/4545)
Train Loss: 0.134 | Acc: 94.653 (4302/4545)
3
Train Loss: 0.166 | Acc: 92.123 (4187/4545)
Train Loss: 0.000 | Acc: 100.000 (4545/4545)
4
Train Loss: 1.584 | Acc: 52.035 (2365/4545)
Train Loss: 0.465 | Acc: 79.406 (3609/4545)
5
Train Loss: 0.173 | Acc: 94.301 (4286/4545)
Train Loss: 0.000 | Acc: 100.000 (4545/4545)
6
Train Loss: 0.917 | Acc: 72.211 (3282/4545)
Train Loss: 0.163 | Acc: 94.125 (4278/4545)
7
Train Loss: 0.952 | Acc: 70.209 (3191/4545)
Train Loss: 0.333 | Acc: 90.121 (4096/4545)
8
Train Loss: 1.291 | Acc: 58.350 (2652/4545)
Train Loss: 0.239 | Acc: 90.869 (4130/4545)
9
Train Loss: 1.501 | Acc: 53.509 (2432/4545)
Train Loss: 0.462 | Acc: 78.702 (3577/4545)
10
Train Loss: 1.222 | Acc: 61.738 (2806/4545)
Train Loss: 0.461 | Acc: 79.560 (3616/4545)
layer4.0
layer2.0
linear
layer4.1
layer3.1
layer2.1
layer1.1
1.conv1
layer1.0
layer3.0
1.bn1
Test Loss: 3.739 | Acc: 10.020 (1002/10000)
mseloss[1]:1.377982497215271, 1.6674041748046875, 2.29187273979187, 0.11441700905561447
mseloss[2]:1.419152855873108, 1.6096656322479248, 2.2294979095458984, 0.23664973676204681
mseloss[3]:1.3555684089660645, 1.4985827207565308, 2.023258924484253, 0.2942972779273987
mseloss[4]:1.4030932188034058, 1.33790922164917, 1.131163239479065, 0.08916809409856796
mseloss[5]:1.4601588249206543, 1.8164763450622559, 2.004340171813965, 0.21674960851669312
mseloss[6]:1.3663859367370605, 1.3638626337051392, 1.2981921434402466, 0.1955612152814865
mseloss[7]:1.4635765552520752, 2.0588600635528564, 2.985297918319702, 0.11250637471675873
mseloss[8]:1.398047685623169, 1.1996620893478394, 0.9346556663513184, 0.11030054092407227
mseloss[9]:1.4170551300048828, 1.2508724927902222, 0.7082816362380981, 0.11628500372171402
Epoch:21
0
Train Loss: 0.543 | Acc: 80.616 (3664/4545)
Train Loss: 0.146 | Acc: 94.411 (4291/4545)
1
Train Loss: 1.874 | Acc: 41.496 (1886/4545)
Train Loss: 0.526 | Acc: 75.534 (3433/4545)
2
Train Loss: 0.863 | Acc: 68.801 (3127/4545)
Train Loss: 0.194 | Acc: 92.783 (4217/4545)
3
Train Loss: 0.991 | Acc: 74.587 (3390/4545)
Train Loss: 0.000 | Acc: 100.000 (4545/4545)
4
Train Loss: 0.749 | Acc: 72.497 (3295/4545)
Train Loss: 0.269 | Acc: 89.373 (4062/4545)
5
Train Loss: 1.099 | Acc: 61.188 (2781/4545)
Train Loss: 0.423 | Acc: 80.902 (3677/4545)
6
Train Loss: 1.443 | Acc: 55.072 (2503/4545)
Train Loss: 0.506 | Acc: 77.536 (3524/4545)
7
Train Loss: 0.943 | Acc: 67.921 (3087/4545)
Train Loss: 0.139 | Acc: 95.424 (4337/4545)
8
Train Loss: 0.685 | Acc: 79.318 (3605/4545)
Train Loss: 0.209 | Acc: 92.123 (4187/4545)
9
Train Loss: 0.549 | Acc: 81.122 (3687/4545)
Train Loss: 0.175 | Acc: 93.729 (4260/4545)
10
Train Loss: 0.381 | Acc: 86.579 (3935/4545)
Train Loss: 0.000 | Acc: 100.000 (4545/4545)
layer4.1
layer1.0
layer1.1
layer3.0
linear
layer2.0
layer3.1
layer4.0
1.conv1
1.bn1
layer2.1
Test Loss: 4.105 | Acc: 10.000 (1000/10000)
mseloss[1]:1.380768895149231, 1.8832967281341553, 2.6138782501220703, 0.1347362995147705
mseloss[2]:1.301239252090454, 1.5902647972106934, 2.0363986492156982, 0.14686329662799835
mseloss[3]:1.1759663820266724, 1.2742351293563843, 0.9402185082435608, 0.11292863637208939
mseloss[4]:1.37543523311615, 1.8044081926345825, 2.7040319442749023, 0.15353639423847198
mseloss[5]:1.431520938873291, 1.9489974975585938, 2.4779722690582275, 0.13213032484054565
mseloss[6]:1.4361131191253662, 1.8515061140060425, 2.6234207153320312, 0.16033945977687836
mseloss[7]:1.271170973777771, 1.405025839805603, 1.473696231842041, 0.1197725236415863
mseloss[8]:1.2734001874923706, 1.5215909481048584, 1.8800231218338013, 0.1323251724243164
mseloss[9]:1.27164626121521, 1.7435636520385742, 2.5739028453826904, 0.16238099336624146
Epoch:22
0
Train Loss: 1.689 | Acc: 51.089 (2322/4545)
Train Loss: 0.482 | Acc: 78.438 (3565/4545)
1
Train Loss: 0.894 | Acc: 68.823 (3128/4545)
Train Loss: 0.184 | Acc: 93.289 (4240/4545)
2
Train Loss: 1.136 | Acc: 74.345 (3379/4545)
Train Loss: 0.000 | Acc: 100.000 (4545/4545)
3
Train Loss: 0.509 | Acc: 80.022 (3637/4545)
Train Loss: 0.151 | Acc: 94.081 (4276/4545)
4
Train Loss: 1.558 | Acc: 54.741 (2488/4545)
Train Loss: 0.445 | Acc: 79.802 (3627/4545)
5
Train Loss: 0.971 | Acc: 71.155 (3234/4545)
Train Loss: 0.196 | Acc: 91.925 (4178/4545)
6
Train Loss: 0.544 | Acc: 76.326 (3469/4545)
Train Loss: 0.274 | Acc: 88.735 (4033/4545)
7
Train Loss: 0.352 | Acc: 88.911 (4041/4545)
Train Loss: 0.000 | Acc: 100.000 (4545/4545)
8
Train Loss: 1.156 | Acc: 70.935 (3224/4545)
Train Loss: 0.419 | Acc: 81.606 (3709/4545)
9
Train Loss: 1.194 | Acc: 69.439 (3156/4545)
Train Loss: 0.130 | Acc: 94.895 (4313/4545)
10
Train Loss: 0.526 | Acc: 85.083 (3867/4545)
Train Loss: 0.175 | Acc: 93.971 (4271/4545)
layer2.1
layer4.0
layer4.1
layer1.1
layer3.1
layer2.0
layer1.0
layer3.0
linear
1.conv1
1.bn1
Test Loss: 4.620 | Acc: 12.680 (1268/10000)
mseloss[1]:1.278753399848938, 1.5326738357543945, 1.7010753154754639, 0.1581457555294037
mseloss[2]:1.196549654006958, 1.3223093748092651, 1.0768885612487793, 0.25736966729164124
mseloss[3]:1.3148266077041626, 1.6420624256134033, 2.417414665222168, 0.41226476430892944
mseloss[4]:1.3208222389221191, 1.9733912944793701, 2.858898878097534, 0.18176431953907013
mseloss[5]:1.2425771951675415, 1.4326674938201904, 1.2849280834197998, 0.1441657394170761
mseloss[6]:1.3219382762908936, 1.8247088193893433, 2.265489101409912, 0.1896175593137741
mseloss[7]:1.2084078788757324, 1.309241533279419, 1.082112431526184, 0.39251893758773804
mseloss[8]:1.3579517602920532, 1.7030071020126343, 1.726065754890442, 0.1343996524810791
mseloss[9]:1.2367359399795532, 1.5098942518234253, 1.3539847135543823, 0.15025188028812408
Epoch:23
0
Train Loss: 0.337 | Acc: 88.361 (4016/4545)
Train Loss: 0.000 | Acc: 100.000 (4545/4545)
1
Train Loss: 0.639 | Acc: 81.870 (3721/4545)
Train Loss: 0.172 | Acc: 93.751 (4261/4545)
2
Train Loss: 1.232 | Acc: 69.527 (3160/4545)
Train Loss: 0.126 | Acc: 95.512 (4341/4545)
3
Train Loss: 0.619 | Acc: 72.651 (3302/4545)
Train Loss: 0.408 | Acc: 81.408 (3700/4545)
4
Train Loss: 1.559 | Acc: 62.332 (2833/4545)
Train Loss: 0.196 | Acc: 92.255 (4193/4545)
5
Train Loss: 1.135 | Acc: 70.341 (3197/4545)
Train Loss: 0.438 | Acc: 79.538 (3615/4545)
6
Train Loss: 0.654 | Acc: 76.370 (3471/4545)
Train Loss: 0.249 | Acc: 90.165 (4098/4545)
7
Train Loss: 0.859 | Acc: 73.685 (3349/4545)
Train Loss: 0.133 | Acc: 95.006 (4318/4545)
8
Train Loss: 1.326 | Acc: 61.804 (2809/4545)
Train Loss: 0.193 | Acc: 92.981 (4226/4545)
9
Train Loss: 1.551 | Acc: 51.925 (2360/4545)
Train Loss: 0.456 | Acc: 79.450 (3611/4545)
10
Train Loss: 0.562 | Acc: 83.344 (3788/4545)
Train Loss: 0.000 | Acc: 100.000 (4545/4545)
layer1.0
layer4.0
1.bn1
layer1.1
layer3.1
layer4.1
linear
layer3.0
1.conv1
layer2.0
layer2.1
Test Loss: 3.149 | Acc: 10.380 (1038/10000)
mseloss[1]:1.139492392539978, 1.3543260097503662, 1.9900599718093872, 0.2363276332616806
mseloss[2]:1.132376790046692, 1.3586915731430054, 1.8971000909805298, 0.27862319350242615
mseloss[3]:1.2488141059875488, 1.5616731643676758, 2.1474201679229736, 0.32131272554397583
mseloss[4]:1.2219784259796143, 1.700189471244812, 1.7429633140563965, 0.23989790678024292
mseloss[5]:1.2306077480316162, 1.6386836767196655, 2.091047525405884, 0.2714069187641144
mseloss[6]:1.2177563905715942, 1.6623269319534302, 2.130664348602295, 0.2843778729438782
mseloss[7]:1.1296004056930542, 1.2479196786880493, 1.041688323020935, 0.26633456349372864
mseloss[8]:1.2188936471939087, 1.6442301273345947, 2.14168643951416, 0.30351904034614563
mseloss[9]:1.1529337167739868, 1.2897261381149292, 1.6893470287322998, 0.4281269311904907
Epoch:24
0
Train Loss: 0.840 | Acc: 68.273 (3103/4545)
Train Loss: 0.431 | Acc: 80.836 (3674/4545)
1
Train Loss: 0.549 | Acc: 76.876 (3494/4545)
Train Loss: 0.237 | Acc: 90.495 (4113/4545)
2
Train Loss: 0.932 | Acc: 65.501 (2977/4545)
Train Loss: 0.452 | Acc: 80.616 (3664/4545)
3
Train Loss: 0.619 | Acc: 80.374 (3653/4545)
Train Loss: 0.000 | Acc: 100.000 (4545/4545)
4
Train Loss: 1.664 | Acc: 52.365 (2380/4545)
Train Loss: 0.142 | Acc: 94.763 (4307/4545)
5
Train Loss: 0.709 | Acc: 74.125 (3369/4545)
Train Loss: 0.390 | Acc: 83.454 (3793/4545)
6
Train Loss: 1.326 | Acc: 65.523 (2978/4545)
Train Loss: 0.222 | Acc: 91.749 (4170/4545)
7
Train Loss: 0.650 | Acc: 78.262 (3557/4545)
Train Loss: 0.126 | Acc: 95.050 (4320/4545)
8
Train Loss: 0.763 | Acc: 77.954 (3543/4545)
Train Loss: 0.148 | Acc: 94.807 (4309/4545)
9
Train Loss: 1.080 | Acc: 71.001 (3227/4545)
Train Loss: 0.190 | Acc: 92.937 (4224/4545)
10
Train Loss: 0.438 | Acc: 86.579 (3935/4545)
Train Loss: 0.000 | Acc: 100.000 (4545/4545)
layer4.0
1.bn1
layer2.1
layer1.0
layer2.0
linear
1.conv1
layer3.0
layer4.1
layer1.1
layer3.1
Test Loss: 6.264 | Acc: 10.020 (1002/10000)
mseloss[1]:1.2504642009735107, 1.2396353483200073, 0.992712140083313, 0.14776675403118134
mseloss[2]:1.419416069984436, 2.03639554977417, 2.6183817386627197, 0.30363497138023376
mseloss[3]:1.1975125074386597, 1.603601098060608, 2.213920831680298, 0.3857686519622803
mseloss[4]:1.2797083854675293, 1.796182632446289, 3.113495349884033, 0.21038198471069336
mseloss[5]:1.2566157579421997, 1.3928775787353516, 1.0991641283035278, 0.16290080547332764
mseloss[6]:1.2028634548187256, 1.703356385231018, 3.101821184158325, 0.22972887754440308
mseloss[7]:1.2438119649887085, 1.4524794816970825, 2.218440294265747, 0.5896257162094116
mseloss[8]:1.217271327972412, 1.3819934129714966, 1.8405910730361938, 0.3358389139175415
mseloss[9]:1.2778220176696777, 1.6548879146575928, 1.5518279075622559, 0.16855522990226746
Epoch:25
0
Train Loss: 1.571 | Acc: 56.392 (2563/4545)
Train Loss: 0.201 | Acc: 93.377 (4244/4545)
1
Train Loss: 0.997 | Acc: 65.655 (2984/4545)
Train Loss: 0.424 | Acc: 81.320 (3696/4545)
2
Train Loss: 0.710 | Acc: 74.763 (3398/4545)
Train Loss: 0.249 | Acc: 89.879 (4085/4545)
3
Train Loss: 2.111 | Acc: 41.408 (1882/4545)
Train Loss: 0.181 | Acc: 93.025 (4228/4545)
4
Train Loss: 1.556 | Acc: 59.450 (2702/4545)
Train Loss: 0.291 | Acc: 91.001 (4136/4545)
5
Train Loss: 0.634 | Acc: 79.868 (3630/4545)
Train Loss: 0.158 | Acc: 94.125 (4278/4545)
6
Train Loss: 0.550 | Acc: 79.054 (3593/4545)
Train Loss: 0.144 | Acc: 94.477 (4294/4545)
7
Train Loss: 0.312 | Acc: 89.395 (4063/4545)
Train Loss: 0.000 | Acc: 100.000 (4545/4545)
8
Train Loss: 0.524 | Acc: 84.378 (3835/4545)
Train Loss: 0.000 | Acc: 100.000 (4545/4545)
9
Train Loss: 0.627 | Acc: 69.659 (3166/4545)
Train Loss: 0.390 | Acc: 82.926 (3769/4545)
10
Train Loss: 0.924 | Acc: 72.695 (3304/4545)
Train Loss: 0.406 | Acc: 81.694 (3713/4545)
1.bn1
layer3.1
linear
layer4.0
1.conv1
layer4.1
layer2.0
layer2.1
layer1.0
layer3.0
layer1.1
Test Loss: 4.570 | Acc: 10.000 (1000/10000)
mseloss[1]:1.258631944656372, 1.5831364393234253, 1.3250768184661865, 0.2912901043891907
mseloss[2]:1.2806971073150635, 1.3308110237121582, 0.9051232933998108, 0.14405423402786255
mseloss[3]:1.212019443511963, 1.436242699623108, 1.4943128824234009, 0.14659954607486725
mseloss[4]:1.2579758167266846, 1.3401745557785034, 1.202783226966858, 0.13726627826690674
mseloss[5]:1.300737977027893, 1.7152825593948364, 1.484255313873291, 0.263853520154953
mseloss[6]:1.2804561853408813, 1.6987770795822144, 1.8049226999282837, 0.32056930661201477
mseloss[7]:1.2625954151153564, 1.8393874168395996, 1.3796627521514893, 0.3891054093837738
mseloss[8]:1.2562649250030518, 1.6350151300430298, 1.7634646892547607, 0.23955386877059937
mseloss[9]:1.2374008893966675, 1.0417839288711548, 1.0008479356765747, 0.41759631037712097
Epoch:26
0
Train Loss: 1.870 | Acc: 58.658 (2666/4545)
Train Loss: 0.116 | Acc: 95.490 (4340/4545)
1
Train Loss: 0.824 | Acc: 78.834 (3583/4545)
Train Loss: 0.000 | Acc: 100.000 (4545/4545)
2
Train Loss: 1.280 | Acc: 60.308 (2741/4545)
Train Loss: 0.431 | Acc: 81.518 (3705/4545)
3
Train Loss: 0.924 | Acc: 72.475 (3294/4545)
Train Loss: 0.169 | Acc: 93.861 (4266/4545)
4
Train Loss: 1.303 | Acc: 59.230 (2692/4545)
Train Loss: 0.410 | Acc: 81.694 (3713/4545)
5
Train Loss: 1.169 | Acc: 70.209 (3191/4545)
Train Loss: 0.180 | Acc: 92.849 (4220/4545)
6
Train Loss: 0.831 | Acc: 71.155 (3234/4545)
Train Loss: 0.389 | Acc: 82.574 (3753/4545)
7
Train Loss: 0.478 | Acc: 84.048 (3820/4545)
Train Loss: 0.148 | Acc: 94.213 (4282/4545)
8
Train Loss: 0.365 | Acc: 88.295 (4013/4545)
Train Loss: 0.000 | Acc: 100.000 (4545/4545)
9
Train Loss: 0.435 | Acc: 82.794 (3763/4545)
Train Loss: 0.235 | Acc: 90.099 (4095/4545)
10
Train Loss: 0.856 | Acc: 75.666 (3439/4545)
Train Loss: 0.123 | Acc: 95.072 (4321/4545)
layer2.0
layer1.0
linear
layer2.1
layer1.1
layer3.0
layer4.1
layer3.1
layer4.0
1.bn1
1.conv1
Test Loss: 6.049 | Acc: 10.000 (1000/10000)
mseloss[1]:1.1363208293914795, 1.3889216184616089, 1.1616820096969604, 0.2091965675354004
mseloss[2]:1.1700519323349, 1.272128701210022, 1.240433931350708, 0.2682720124721527
mseloss[3]:1.1962709426879883, 1.5358022451400757, 1.2419614791870117, 0.1409609615802765
mseloss[4]:1.162315011024475, 1.514410376548767, 1.8362540006637573, 0.21772469580173492
mseloss[5]:1.1635509729385376, 1.5801022052764893, 1.8969670534133911, 0.21067090332508087
mseloss[6]:1.194513201713562, 1.6719411611557007, 1.2995994091033936, 0.15886355936527252
mseloss[7]:1.1402297019958496, 1.4092029333114624, 1.8074604272842407, 0.3078726530075073
mseloss[8]:1.0821073055267334, 1.4547802209854126, 1.3576124906539917, 0.4720298945903778
mseloss[9]:1.1960030794143677, 1.526962399482727, 1.8050353527069092, 0.3350648581981659
Epoch:27
0
Train Loss: 0.546 | Acc: 79.560 (3616/4545)
Train Loss: 0.115 | Acc: 95.578 (4344/4545)
1
Train Loss: 1.528 | Acc: 68.185 (3099/4545)
Train Loss: 0.107 | Acc: 95.842 (4356/4545)
2
Train Loss: 1.224 | Acc: 59.384 (2699/4545)
Train Loss: 0.423 | Acc: 81.012 (3682/4545)
3
Train Loss: 1.003 | Acc: 70.847 (3220/4545)
Train Loss: 0.162 | Acc: 93.729 (4260/4545)
4
Train Loss: 0.605 | Acc: 75.908 (3450/4545)
Train Loss: 0.426 | Acc: 81.540 (3706/4545)
5
Train Loss: 0.925 | Acc: 79.120 (3596/4545)
Train Loss: 0.000 | Acc: 100.000 (4545/4545)
6
Train Loss: 1.177 | Acc: 71.177 (3235/4545)
Train Loss: 0.155 | Acc: 94.125 (4278/4545)
7
Train Loss: 0.739 | Acc: 74.191 (3372/4545)
Train Loss: 0.262 | Acc: 89.945 (4088/4545)
8
Train Loss: 1.157 | Acc: 70.979 (3226/4545)
Train Loss: 0.158 | Acc: 93.795 (4263/4545)
9
Train Loss: 0.782 | Acc: 65.523 (2978/4545)
Train Loss: 0.426 | Acc: 80.902 (3677/4545)
10
Train Loss: 0.629 | Acc: 82.948 (3770/4545)
Train Loss: 0.000 | Acc: 100.000 (4545/4545)
1.conv1
layer1.0
1.bn1
layer3.1
layer4.1
linear
layer2.0
layer1.1
layer4.0
layer3.0
layer2.1
Test Loss: 10.927 | Acc: 10.000 (1000/10000)
mseloss[1]:1.166745662689209, 1.4242969751358032, 1.5044893026351929, 0.26382309198379517
mseloss[2]:1.2225295305252075, 1.8590792417526245, 1.7892372608184814, 0.27121612429618835
mseloss[3]:1.1920236349105835, 1.6406676769256592, 1.627463936805725, 0.2743651568889618
mseloss[4]:1.174108624458313, 1.2268574237823486, 0.9717126488685608, 0.2904759645462036
mseloss[5]:1.1191602945327759, 1.2271205186843872, 0.7779642939567566, 0.2427041083574295
mseloss[6]:1.1479828357696533, 1.5092941522598267, 1.8040484189987183, 0.29085275530815125
mseloss[7]:1.2430051565170288, 1.8646435737609863, 2.044590473175049, 0.3020772635936737
mseloss[8]:1.207485318183899, 1.781389594078064, 1.7284609079360962, 0.29535722732543945
mseloss[9]:1.188114881515503, 1.7486788034439087, 1.8401358127593994, 0.27078065276145935
Epoch:28
0
Train Loss: 1.741 | Acc: 66.733 (3033/4545)
Train Loss: 0.164 | Acc: 94.235 (4283/4545)
1
Train Loss: 1.409 | Acc: 55.446 (2520/4545)
Train Loss: 0.436 | Acc: 80.154 (3643/4545)
2
Train Loss: 1.750 | Acc: 48.537 (2206/4545)
Train Loss: 0.293 | Acc: 88.273 (4012/4545)
3
Train Loss: 1.642 | Acc: 54.301 (2468/4545)
Train Loss: 0.421 | Acc: 81.496 (3704/4545)
4
Train Loss: 1.916 | Acc: 58.702 (2668/4545)
Train Loss: 0.099 | Acc: 96.304 (4377/4545)
5
Train Loss: 0.830 | Acc: 80.418 (3655/4545)
Train Loss: 0.000 | Acc: 100.000 (4545/4545)
6
Train Loss: 1.216 | Acc: 68.471 (3112/4545)
Train Loss: 0.132 | Acc: 94.939 (4315/4545)
7
Train Loss: 0.008 | Acc: 100.000 (4545/4545)
Train Loss: 0.001 | Acc: 100.000 (4545/4545)
8
Train Loss: 1.411 | Acc: 57.998 (2636/4545)
Train Loss: 0.435 | Acc: 81.144 (3688/4545)
9
Train Loss: 0.894 | Acc: 73.399 (3336/4545)
Train Loss: 0.144 | Acc: 94.455 (4293/4545)
10
Train Loss: 1.688 | Acc: 56.128 (2551/4545)
Train Loss: 0.284 | Acc: 88.933 (4042/4545)
layer2.1
layer2.0
linear
layer4.0
layer1.0
layer4.1
layer3.1
layer3.0
1.conv1
layer1.1
1.bn1
Test Loss: 5.374 | Acc: 10.000 (1000/10000)
mseloss[1]:1.221242070198059, 1.5065537691116333, 1.632490634918213, 0.35232803225517273
mseloss[2]:1.237784743309021, 1.3840157985687256, 1.9601668119430542, 0.37996938824653625
mseloss[3]:1.1819669008255005, 1.5086984634399414, 1.1069780588150024, 0.16709119081497192
mseloss[4]:1.1766164302825928, 1.191767692565918, 1.0367482900619507, 0.21214859187602997
mseloss[5]:1.189432144165039, 1.291398525238037, 1.456069827079773, 0.4739921987056732
mseloss[6]:1.1868380308151245, 1.2496079206466675, 1.4226309061050415, 0.31815585494041443
mseloss[7]:1.1379005908966064, 1.233993649482727, 1.4637995958328247, 0.2680972218513489
mseloss[8]:1.2608015537261963, 1.3350439071655273, 1.5644066333770752, 0.43088430166244507
mseloss[9]:1.1646215915679932, 1.2768040895462036, 1.5405768156051636, 0.31250450015068054
Epoch:29
0
Train Loss: 0.368 | Acc: 84.334 (3833/4545)
Train Loss: 0.239 | Acc: 90.429 (4110/4545)
1
Train Loss: 1.189 | Acc: 60.506 (2750/4545)
Train Loss: 0.421 | Acc: 81.364 (3698/4545)
2
Train Loss: 2.309 | Acc: 49.087 (2231/4545)
Train Loss: 0.114 | Acc: 95.732 (4351/4545)
3
Train Loss: 0.957 | Acc: 78.240 (3556/4545)
Train Loss: 0.000 | Acc: 100.000 (4545/4545)
4
Train Loss: 0.841 | Acc: 76.986 (3499/4545)
Train Loss: 0.126 | Acc: 95.270 (4330/4545)
5
Train Loss: 1.061 | Acc: 71.089 (3231/4545)
Train Loss: 0.392 | Acc: 83.322 (3787/4545)
6
Train Loss: 0.968 | Acc: 63.894 (2904/4545)
Train Loss: 0.375 | Acc: 84.026 (3819/4545)
7
Train Loss: 0.984 | Acc: 76.062 (3457/4545)
Train Loss: 0.122 | Acc: 95.446 (4338/4545)
8
Train Loss: 1.132 | Acc: 70.583 (3208/4545)
Train Loss: 0.147 | Acc: 94.389 (4290/4545)
9
Train Loss: 0.392 | Acc: 87.547 (3979/4545)
Train Loss: 0.000 | Acc: 100.000 (4545/4545)
10
Train Loss: 1.174 | Acc: 68.669 (3121/4545)
Train Loss: 0.183 | Acc: 92.871 (4221/4545)
layer1.0
layer4.0
linear
layer2.0
layer1.1
layer3.1
1.conv1
layer4.1
layer3.0
layer2.1
1.bn1
Test Loss: 6.902 | Acc: 10.000 (1000/10000)
mseloss[1]:1.1928863525390625, 1.3013702630996704, 1.2398433685302734, 0.5353127121925354
mseloss[2]:1.3813549280166626, 1.6539819240570068, 1.748238444328308, 0.4071945250034332
mseloss[3]:1.2292450666427612, 1.369112491607666, 1.3771204948425293, 0.5625056624412537
mseloss[4]:1.2453863620758057, 1.3258908987045288, 1.3744033575057983, 0.481984406709671
mseloss[5]:1.2330070734024048, 1.8116919994354248, 1.877038598060608, 0.41939640045166016
mseloss[6]:1.1863154172897339, 1.3969568014144897, 1.3817511796951294, 0.4422259032726288
mseloss[7]:1.1861863136291504, 1.1785646677017212, 1.341727375984192, 0.5027055740356445
mseloss[8]:1.2171553373336792, 1.3288850784301758, 1.3382209539413452, 0.4162342846393585
mseloss[9]:1.294822335243225, 1.4460902214050293, 1.258014440536499, 0.525040864944458
Epoch:30
0
Train Loss: 2.068 | Acc: 44.906 (2041/4545)
Train Loss: 0.281 | Acc: 89.549 (4070/4545)
1
Train Loss: 1.965 | Acc: 44.004 (2000/4545)
Train Loss: 0.464 | Acc: 80.374 (3653/4545)
2
Train Loss: 0.973 | Acc: 70.231 (3192/4545)
Train Loss: 0.140 | Acc: 95.094 (4322/4545)
3
Train Loss: 0.700 | Acc: 77.778 (3535/4545)
Train Loss: 0.161 | Acc: 93.685 (4258/4545)
4
Train Loss: 0.613 | Acc: 77.558 (3525/4545)
Train Loss: 0.135 | Acc: 95.226 (4328/4545)
5
Train Loss: 0.275 | Acc: 92.673 (4212/4545)
Train Loss: 0.091 | Acc: 96.832 (4401/4545)
6
Train Loss: 0.757 | Acc: 74.015 (3364/4545)
Train Loss: 0.123 | Acc: 95.534 (4342/4545)
7
Train Loss: 0.545 | Acc: 82.398 (3745/4545)
Train Loss: 0.000 | Acc: 100.000 (4545/4545)
8
Train Loss: 0.647 | Acc: 80.374 (3653/4545)
Train Loss: 0.000 | Acc: 100.000 (4545/4545)
9
Train Loss: 0.940 | Acc: 64.510 (2932/4545)
Train Loss: 0.402 | Acc: 81.760 (3716/4545)
10
Train Loss: 1.245 | Acc: 59.076 (2685/4545)
Train Loss: 0.382 | Acc: 83.762 (3807/4545)
layer2.0
layer1.0
1.bn1
1.conv1
layer3.0
layer3.1
layer4.1
layer4.0
layer1.1
linear
layer2.1
Test Loss: 3.492 | Acc: 9.890 (989/10000)
mseloss[1]:1.307807445526123, 1.2142707109451294, 0.8799867033958435, 0.1612589806318283
mseloss[2]:1.303518533706665, 1.450034737586975, 1.2993528842926025, 0.27896547317504883
mseloss[3]:1.311295509338379, 1.1387804746627808, 0.9015869498252869, 0.2492012083530426
mseloss[4]:1.361494541168213, 1.5964292287826538, 1.9508421421051025, 0.40253764390945435
mseloss[5]:1.3320680856704712, 1.5324420928955078, 1.671042561531067, 0.4224056005477905
mseloss[6]:1.3368836641311646, 1.5910958051681519, 1.9582817554473877, 0.4226839542388916
mseloss[7]:1.2639273405075073, 1.6454977989196777, 1.8582569360733032, 0.3779500126838684
mseloss[8]:1.364745855331421, 1.5756659507751465, 1.9412134885787964, 0.4566141664981842
mseloss[9]:1.3568661212921143, 1.5091044902801514, 1.9186292886734009, 0.7390950918197632
Epoch:31
0
Train Loss: 1.448 | Acc: 56.282 (2558/4545)
Train Loss: 0.429 | Acc: 81.078 (3685/4545)
1
Train Loss: 1.135 | Acc: 66.777 (3035/4545)
Train Loss: 0.175 | Acc: 93.509 (4250/4545)
2
Train Loss: 0.341 | Acc: 89.813 (4082/4545)
Train Loss: 0.117 | Acc: 95.644 (4347/4545)
3
Train Loss: 1.017 | Acc: 72.365 (3289/4545)
Train Loss: 0.166 | Acc: 93.773 (4262/4545)
4
Train Loss: 0.715 | Acc: 80.792 (3672/4545)
Train Loss: 0.000 | Acc: 100.000 (4545/4545)
5
Train Loss: 0.330 | Acc: 87.591 (3981/4545)
Train Loss: 0.000 | Acc: 100.000 (4545/4545)
6
Train Loss: 1.058 | Acc: 68.845 (3129/4545)
Train Loss: 0.127 | Acc: 95.688 (4349/4545)
7
Train Loss: 1.740 | Acc: 48.647 (2211/4545)
Train Loss: 0.454 | Acc: 81.562 (3707/4545)
8
Train Loss: 1.023 | Acc: 72.035 (3274/4545)
Train Loss: 0.253 | Acc: 90.627 (4119/4545)
9
Train Loss: 0.536 | Acc: 83.850 (3811/4545)
Train Loss: 0.152 | Acc: 94.455 (4293/4545)
10
Train Loss: 0.600 | Acc: 75.512 (3432/4545)
Train Loss: 0.419 | Acc: 81.320 (3696/4545)
layer2.1
1.bn1
layer4.1
1.conv1
layer1.1
layer4.0
layer2.0
layer1.0
layer3.1
linear
layer3.0
Test Loss: 6.965 | Acc: 10.000 (1000/10000)
mseloss[1]:1.1761301755905151, 1.2500615119934082, 1.0416630506515503, 0.19290344417095184
mseloss[2]:1.1467832326889038, 1.332071304321289, 1.6935704946517944, 0.2792656123638153
mseloss[3]:1.1123665571212769, 1.4113332033157349, 1.88018000125885, 0.25092482566833496
mseloss[4]:1.2369052171707153, 1.5472736358642578, 1.6287885904312134, 0.28161853551864624
mseloss[5]:1.230971097946167, 1.4579391479492188, 1.6174137592315674, 0.2301291525363922
mseloss[6]:1.2232919931411743, 1.502772331237793, 1.8534080982208252, 0.24470676481723785
mseloss[7]:1.20222806930542, 1.2987830638885498, 1.2702322006225586, 0.13196192681789398
mseloss[8]:1.153849482536316, 1.008543610572815, 0.7852423787117004, 0.1468399316072464
mseloss[9]:1.1559464931488037, 1.1740310192108154, 1.2245633602142334, 0.1527017503976822
Epoch:32
0
Train Loss: 1.223 | Acc: 66.139 (3006/4545)
Train Loss: 0.151 | Acc: 94.323 (4287/4545)
1
Train Loss: 1.928 | Acc: 36.678 (1667/4545)
Train Loss: 0.453 | Acc: 80.308 (3650/4545)
2
Train Loss: 1.171 | Acc: 55.248 (2511/4545)
Train Loss: 0.418 | Acc: 81.562 (3707/4545)
3
Train Loss: 1.287 | Acc: 60.858 (2766/4545)
Train Loss: 0.105 | Acc: 96.480 (4385/4545)
4
Train Loss: 0.239 | Acc: 92.651 (4211/4545)
Train Loss: 0.122 | Acc: 95.468 (4339/4545)
5
Train Loss: 0.833 | Acc: 74.279 (3376/4545)
Train Loss: 0.125 | Acc: 95.028 (4319/4545)
6
Train Loss: 1.955 | Acc: 37.140 (1688/4545)
Train Loss: 0.582 | Acc: 79.890 (3631/4545)
7
Train Loss: 0.388 | Acc: 82.288 (3740/4545)
Train Loss: 0.000 | Acc: 100.000 (4545/4545)
8
Train Loss: 1.034 | Acc: 68.603 (3118/4545)
Train Loss: 0.154 | Acc: 94.323 (4287/4545)
9
Train Loss: 0.993 | Acc: 70.011 (3182/4545)
Train Loss: 0.258 | Acc: 90.319 (4105/4545)
10
Train Loss: 1.075 | Acc: 72.453 (3293/4545)
Train Loss: 0.000 | Acc: 100.000 (4545/4545)
layer4.0
layer4.1
1.conv1
layer1.1
layer2.0
linear
layer3.1
layer2.1
layer1.0
1.bn1
layer3.0
Test Loss: 3.282 | Acc: 12.990 (1299/10000)
mseloss[1]:1.1820684671401978, 1.6442210674285889, 2.0616257190704346, 0.2964635491371155
mseloss[2]:1.1234523057937622, 1.1305625438690186, 1.4985593557357788, 0.38439255952835083
mseloss[3]:1.1602046489715576, 1.4267891645431519, 1.7029578685760498, 0.3219202756881714
mseloss[4]:1.1145193576812744, 1.229522466659546, 1.3452986478805542, 0.33179110288619995
mseloss[5]:1.1228123903274536, 1.1430548429489136, 1.69306480884552, 0.4618566632270813
mseloss[6]:1.2270536422729492, 1.6503909826278687, 1.8613396883010864, 0.28260836005210876
mseloss[7]:1.1769206523895264, 1.3925694227218628, 1.148328423500061, 0.5059809684753418
mseloss[8]:1.1436796188354492, 1.1240525245666504, 1.3207345008850098, 0.43991392850875854
mseloss[9]:1.178085207939148, 1.3633099794387817, 1.4585978984832764, 0.3655703663825989
Epoch:33
0
Train Loss: 1.450 | Acc: 52.145 (2370/4545)
Train Loss: 0.289 | Acc: 89.087 (4049/4545)
1
Train Loss: 0.553 | Acc: 82.596 (3754/4545)
Train Loss: 0.088 | Acc: 96.766 (4398/4545)
2
Train Loss: 0.584 | Acc: 83.168 (3780/4545)
Train Loss: 0.000 | Acc: 100.000 (4545/4545)
3
Train Loss: 0.218 | Acc: 91.595 (4163/4545)
Train Loss: 0.103 | Acc: 96.150 (4370/4545)
4
Train Loss: 0.716 | Acc: 70.275 (3194/4545)
Train Loss: 0.391 | Acc: 82.376 (3744/4545)
5
Train Loss: 1.300 | Acc: 60.748 (2761/4545)
Train Loss: 0.170 | Acc: 93.773 (4262/4545)
6
Train Loss: 1.283 | Acc: 53.465 (2430/4545)
Train Loss: 0.412 | Acc: 81.518 (3705/4545)
7
Train Loss: 1.573 | Acc: 51.881 (2358/4545)
Train Loss: 0.428 | Acc: 81.320 (3696/4545)
8
Train Loss: 0.601 | Acc: 79.802 (3627/4545)
Train Loss: 0.138 | Acc: 95.050 (4320/4545)
9
Train Loss: 0.471 | Acc: 84.906 (3859/4545)
Train Loss: 0.000 | Acc: 100.000 (4545/4545)
10
Train Loss: 0.507 | Acc: 81.518 (3705/4545)
Train Loss: 0.145 | Acc: 94.763 (4307/4545)
layer4.1
layer1.1
1.conv1
layer4.0
layer2.0
layer3.0
layer1.0
layer3.1
1.bn1
layer2.1
linear
Test Loss: 6.725 | Acc: 10.980 (1098/10000)
mseloss[1]:1.2382798194885254, 1.5350319147109985, 1.3925236463546753, 0.3200516402721405
mseloss[2]:1.221329927444458, 1.3988999128341675, 1.0136067867279053, 0.38486602902412415
mseloss[3]:1.2262883186340332, 1.4626342058181763, 1.0198920965194702, 0.41423189640045166
mseloss[4]:1.2110756635665894, 1.464559555053711, 1.1910966634750366, 0.47138988971710205
mseloss[5]:1.2471139430999756, 1.2420847415924072, 1.09064781665802, 0.2531842291355133
mseloss[6]:1.2266486883163452, 1.1420855522155762, 1.185563564300537, 0.23441411554813385
mseloss[7]:1.3673388957977295, 1.7217745780944824, 1.6443291902542114, 0.2920674979686737
mseloss[8]:1.23187255859375, 1.4440102577209473, 1.2129313945770264, 0.2990669906139374
mseloss[9]:1.2522246837615967, 1.5176522731781006, 0.8758683204650879, 0.2953333854675293
Epoch:34
0
Train Loss: 0.861 | Acc: 75.534 (3433/4545)
Train Loss: 0.000 | Acc: 100.000 (4545/4545)
1
Train Loss: 0.613 | Acc: 78.702 (3577/4545)
Train Loss: 0.135 | Acc: 94.697 (4304/4545)
2
Train Loss: 0.944 | Acc: 70.253 (3193/4545)
Train Loss: 0.157 | Acc: 95.028 (4319/4545)
3
Train Loss: 1.189 | Acc: 66.425 (3019/4545)
Train Loss: 0.172 | Acc: 94.081 (4276/4545)
4
Train Loss: 1.184 | Acc: 60.132 (2733/4545)
Train Loss: 0.411 | Acc: 82.112 (3732/4545)
5
Train Loss: 1.025 | Acc: 66.491 (3022/4545)
Train Loss: 0.118 | Acc: 95.600 (4345/4545)
6
Train Loss: 0.821 | Acc: 64.928 (2951/4545)
Train Loss: 0.406 | Acc: 82.222 (3737/4545)
7
Train Loss: 0.373 | Acc: 88.207 (4009/4545)
Train Loss: 0.119 | Acc: 95.424 (4337/4545)
8
Train Loss: 0.378 | Acc: 83.476 (3794/4545)
Train Loss: 0.000 | Acc: 100.000 (4545/4545)
9
Train Loss: 1.549 | Acc: 44.246 (2011/4545)
Train Loss: 0.479 | Acc: 80.594 (3663/4545)
10
Train Loss: 1.084 | Acc: 64.422 (2928/4545)
Train Loss: 0.276 | Acc: 90.231 (4101/4545)
layer2.1
layer2.0
layer4.0
layer1.1
1.conv1
linear
layer1.0
layer3.1
1.bn1
layer3.0
layer4.1
Test Loss: 3.504 | Acc: 10.000 (1000/10000)
mseloss[1]:1.094538927078247, 1.1945704221725464, 0.9603943824768066, 0.291472464799881
mseloss[2]:1.083169937133789, 1.3036707639694214, 1.166054606437683, 0.3104303777217865
mseloss[3]:1.057283878326416, 1.109479308128357, 1.2634941339492798, 0.29435813426971436
mseloss[4]:1.1138300895690918, 1.305102825164795, 1.3561066389083862, 0.3246194124221802
mseloss[5]:1.0586183071136475, 1.2821182012557983, 1.2369118928909302, 0.2749694883823395
mseloss[6]:1.0649027824401855, 0.96665358543396, 0.7242312431335449, 0.25488394498825073
mseloss[7]:1.0189666748046875, 0.9951646327972412, 0.9977452158927917, 0.3009674549102783
mseloss[8]:1.0027190446853638, 0.9305357933044434, 0.7461379766464233, 0.23770612478256226
mseloss[9]:1.1389507055282593, 1.5607720613479614, 1.5693330764770508, 0.3169846832752228
Epoch:35
0
Train Loss: 1.497 | Acc: 55.424 (2519/4545)
Train Loss: 0.388 | Acc: 82.332 (3742/4545)
1
Train Loss: 0.778 | Acc: 70.737 (3215/4545)
Train Loss: 0.240 | Acc: 91.551 (4161/4545)
2
Train Loss: 1.694 | Acc: 49.087 (2231/4545)
Train Loss: 0.438 | Acc: 82.486 (3749/4545)
3
Train Loss: 0.322 | Acc: 87.679 (3985/4545)
Train Loss: 0.129 | Acc: 95.402 (4336/4545)
4
Train Loss: 0.471 | Acc: 84.136 (3824/4545)
Train Loss: 0.000 | Acc: 100.000 (4545/4545)
5
Train Loss: 0.969 | Acc: 71.771 (3262/4545)
Train Loss: 0.125 | Acc: 95.314 (4332/4545)
6
Train Loss: 0.994 | Acc: 69.593 (3163/4545)
Train Loss: 0.158 | Acc: 94.477 (4294/4545)
7
Train Loss: 2.095 | Acc: 39.340 (1788/4545)
Train Loss: 0.432 | Acc: 81.760 (3716/4545)
8
Train Loss: 0.953 | Acc: 73.069 (3321/4545)
Train Loss: 0.117 | Acc: 95.182 (4326/4545)
9
Train Loss: 1.204 | Acc: 71.991 (3272/4545)
Train Loss: 0.000 | Acc: 100.000 (4545/4545)
10
Train Loss: 0.335 | Acc: 91.683 (4167/4545)
Train Loss: 0.091 | Acc: 96.854 (4402/4545)
linear
1.conv1
layer4.0
layer4.1
layer1.1
layer3.1
layer2.0
1.bn1
layer3.0
layer1.0
layer2.1
Test Loss: 3.084 | Acc: 10.000 (1000/10000)
mseloss[1]:1.1837708950042725, 1.5949307680130005, 1.5587540864944458, 0.3788379430770874
mseloss[2]:1.244285225868225, 1.4542497396469116, 1.3992462158203125, 0.32663604617118835
mseloss[3]:1.1071537733078003, 1.1024249792099, 0.9936471581459045, 0.32977402210235596
mseloss[4]:1.0728027820587158, 0.9732232093811035, 0.6616817116737366, 0.3300544321537018
mseloss[5]:1.231788158416748, 1.4232279062271118, 0.9910372495651245, 0.352338582277298
mseloss[6]:1.1315160989761353, 1.0406397581100464, 0.8818026781082153, 0.31741881370544434
mseloss[7]:1.2058945894241333, 1.5808789730072021, 1.5429922342300415, 0.38991403579711914
mseloss[8]:1.2054370641708374, 1.4060593843460083, 1.1783076524734497, 0.3699127733707428
mseloss[9]:1.082417607307434, 1.0309947729110718, 0.6511373519897461, 0.2923884987831116
Epoch:36
0
Train Loss: 0.590 | Acc: 80.792 (3672/4545)
Train Loss: 0.113 | Acc: 95.996 (4363/4545)
1
Train Loss: 0.474 | Acc: 80.308 (3650/4545)
Train Loss: 0.365 | Acc: 84.246 (3829/4545)
2
Train Loss: 1.119 | Acc: 72.915 (3314/4545)
Train Loss: 0.235 | Acc: 91.375 (4153/4545)
3
Train Loss: 1.829 | Acc: 63.520 (2887/4545)
Train Loss: 0.167 | Acc: 93.839 (4265/4545)
4
Train Loss: 1.182 | Acc: 70.121 (3187/4545)
Train Loss: 0.166 | Acc: 94.235 (4283/4545)
5
Train Loss: 0.982 | Acc: 77.624 (3528/4545)
Train Loss: 0.102 | Acc: 96.150 (4370/4545)
6
Train Loss: 1.694 | Acc: 55.248 (2511/4545)
Train Loss: 0.415 | Acc: 83.036 (3774/4545)
7
Train Loss: 1.049 | Acc: 77.492 (3522/4545)
Train Loss: 0.000 | Acc: 100.000 (4545/4545)
8
Train Loss: 0.233 | Acc: 91.067 (4139/4545)
Train Loss: 0.000 | Acc: 100.000 (4545/4545)
9
Train Loss: 0.370 | Acc: 85.303 (3877/4545)
Train Loss: 0.103 | Acc: 95.952 (4361/4545)
10
Train Loss: 1.512 | Acc: 64.862 (2948/4545)
Train Loss: 0.393 | Acc: 83.278 (3785/4545)
layer3.1
layer4.1
layer3.0
layer1.1
layer2.0
linear
layer1.0
layer2.1
1.bn1
1.conv1
layer4.0
Test Loss: 6.694 | Acc: 10.000 (1000/10000)
mseloss[1]:1.114168405532837, 1.0733987092971802, 0.8962288498878479, 0.267184317111969
mseloss[2]:1.1685307025909424, 1.5704063177108765, 1.9645863771438599, 0.3940373659133911
mseloss[3]:1.1250659227371216, 1.4382139444351196, 1.620436191558838, 0.3381023108959198
mseloss[4]:1.1487003564834595, 1.6400197744369507, 2.0906710624694824, 0.35209277272224426
mseloss[5]:1.1178176403045654, 1.2560392618179321, 1.664302945137024, 0.3137522041797638
mseloss[6]:1.1680424213409424, 1.5949997901916504, 2.1933677196502686, 0.34918585419654846
mseloss[7]:1.1281368732452393, 1.330727219581604, 0.918927013874054, 0.26568275690078735
mseloss[8]:1.081080675125122, 1.3108551502227783, 1.004209280014038, 0.29000601172447205
mseloss[9]:1.063228964805603, 1.19757878780365, 0.965389609336853, 0.2651265561580658
Epoch:37
0
Train Loss: 0.940 | Acc: 65.303 (2968/4545)
Train Loss: 0.389 | Acc: 82.640 (3756/4545)
1
Train Loss: 0.832 | Acc: 77.250 (3511/4545)
Train Loss: 0.112 | Acc: 95.930 (4360/4545)
2
Train Loss: 0.666 | Acc: 81.364 (3698/4545)
Train Loss: 0.000 | Acc: 100.000 (4545/4545)
3
Train Loss: 0.169 | Acc: 94.279 (4285/4545)
Train Loss: 0.071 | Acc: 97.250 (4420/4545)
4
Train Loss: 1.294 | Acc: 65.655 (2984/4545)
Train Loss: 0.242 | Acc: 91.111 (4141/4545)
5
Train Loss: 0.599 | Acc: 80.924 (3678/4545)
Train Loss: 0.143 | Acc: 95.402 (4336/4545)
6
Train Loss: 1.348 | Acc: 66.579 (3026/4545)
Train Loss: 0.000 | Acc: 100.000 (4545/4545)
7
Train Loss: 0.764 | Acc: 75.974 (3453/4545)
Train Loss: 0.108 | Acc: 95.908 (4359/4545)
8
Train Loss: 0.611 | Acc: 79.780 (3626/4545)
Train Loss: 0.127 | Acc: 95.556 (4343/4545)
9
Train Loss: 1.303 | Acc: 57.228 (2601/4545)
Train Loss: 0.382 | Acc: 83.762 (3807/4545)
10
Train Loss: 1.192 | Acc: 59.274 (2694/4545)
Train Loss: 0.370 | Acc: 84.202 (3827/4545)
layer3.0
layer1.0
layer1.1
1.conv1
1.bn1
layer4.0
layer2.1
layer2.0
linear
layer4.1
layer3.1
Test Loss: 3.174 | Acc: 10.000 (1000/10000)
mseloss[1]:1.1110823154449463, 1.2555763721466064, 0.6984295845031738, 0.2858359217643738
mseloss[2]:1.0610905885696411, 0.9284171462059021, 0.5242804288864136, 0.24424108862876892
mseloss[3]:1.0846021175384521, 0.9871340394020081, 0.6052489876747131, 0.24603606760501862
mseloss[4]:1.1148359775543213, 1.563832402229309, 1.8805835247039795, 0.3201146721839905
mseloss[5]:1.0844119787216187, 1.2475767135620117, 1.554476022720337, 0.2680315673351288
mseloss[6]:1.0673469305038452, 0.924326479434967, 1.0872722864151, 0.2691507339477539
mseloss[7]:1.1198151111602783, 1.204120397567749, 0.8511150479316711, 0.300197035074234
mseloss[8]:1.0979307889938354, 1.1497993469238281, 0.7162978053092957, 0.20313890278339386
mseloss[9]:1.1873737573623657, 1.5360335111618042, 1.3865712881088257, 0.25805166363716125
Epoch:38
0
Train Loss: 1.331 | Acc: 58.262 (2648/4545)
Train Loss: 0.389 | Acc: 83.498 (3795/4545)
1
Train Loss: 0.711 | Acc: 79.384 (3608/4545)
Train Loss: 0.098 | Acc: 96.150 (4370/4545)
2
Train Loss: 1.258 | Acc: 71.353 (3243/4545)
Train Loss: 0.120 | Acc: 95.930 (4360/4545)
3
Train Loss: 1.037 | Acc: 71.243 (3238/4545)
Train Loss: 0.142 | Acc: 95.204 (4327/4545)
4
Train Loss: 1.022 | Acc: 61.474 (2794/4545)
Train Loss: 0.378 | Acc: 83.674 (3803/4545)
5
Train Loss: 0.395 | Acc: 91.573 (4162/4545)
Train Loss: 0.128 | Acc: 95.160 (4325/4545)
6
Train Loss: 1.340 | Acc: 68.295 (3104/4545)
Train Loss: 0.000 | Acc: 100.000 (4545/4545)
7
Train Loss: 0.718 | Acc: 78.394 (3563/4545)
Train Loss: 0.000 | Acc: 100.000 (4545/4545)
8
Train Loss: 0.694 | Acc: 73.795 (3354/4545)
Train Loss: 0.234 | Acc: 90.957 (4134/4545)
9
Train Loss: 1.037 | Acc: 63.014 (2864/4545)
Train Loss: 0.395 | Acc: 82.882 (3767/4545)
10
Train Loss: 0.593 | Acc: 79.934 (3633/4545)
Train Loss: 0.092 | Acc: 96.788 (4399/4545)
1.conv1
layer2.1
layer1.0
layer4.1
1.bn1
layer2.0
layer1.1
linear
layer4.0
layer3.0
layer3.1
Test Loss: 3.979 | Acc: 9.970 (997/10000)
mseloss[1]:1.0512712001800537, 1.253889799118042, 1.5291211605072021, 0.2854081094264984
mseloss[2]:1.0945541858673096, 1.178038239479065, 1.3364146947860718, 0.28142043948173523
mseloss[3]:1.0666382312774658, 1.0211857557296753, 0.9147309064865112, 0.09632246941328049
mseloss[4]:1.094813585281372, 1.071937918663025, 0.7938956618309021, 0.08228272199630737
mseloss[5]:1.077370524406433, 1.2449802160263062, 1.5154039859771729, 0.18501369655132294
mseloss[6]:1.0887246131896973, 1.297493577003479, 1.5994653701782227, 0.10518590360879898
mseloss[7]:1.1137770414352417, 1.2969194650650024, 1.5333809852600098, 0.19545094668865204
mseloss[8]:1.108298659324646, 0.9601637721061707, 0.4450816810131073, 0.08546038717031479
mseloss[9]:1.156577467918396, 1.305290937423706, 1.765316128730774, 0.13408270478248596
Epoch:39
0
Train Loss: 1.954 | Acc: 44.334 (2015/4545)
Train Loss: 0.431 | Acc: 80.880 (3676/4545)
1
Train Loss: 1.436 | Acc: 55.468 (2521/4545)
Train Loss: 0.430 | Acc: 80.968 (3680/4545)
2
Train Loss: 0.757 | Acc: 74.917 (3405/4545)
Train Loss: 0.133 | Acc: 95.116 (4323/4545)
3
Train Loss: 0.526 | Acc: 79.934 (3633/4545)
Train Loss: 0.229 | Acc: 91.265 (4148/4545)
4
Train Loss: 0.734 | Acc: 79.296 (3604/4545)
Train Loss: 0.100 | Acc: 96.568 (4389/4545)
5
Train Loss: 1.161 | Acc: 64.070 (2912/4545)
Train Loss: 0.386 | Acc: 83.806 (3809/4545)
6
Train Loss: 0.593 | Acc: 79.252 (3602/4545)
Train Loss: 0.080 | Acc: 97.074 (4412/4545)
7
Train Loss: 0.024 | Acc: 100.000 (4545/4545)
Train Loss: 0.000 | Acc: 100.000 (4545/4545)
8
Train Loss: 0.814 | Acc: 75.314 (3423/4545)
Train Loss: 0.143 | Acc: 94.697 (4304/4545)
9
Train Loss: 1.060 | Acc: 76.084 (3458/4545)
Train Loss: 0.000 | Acc: 100.000 (4545/4545)
10
Train Loss: 1.398 | Acc: 67.305 (3059/4545)
Train Loss: 0.128 | Acc: 95.094 (4322/4545)
1.conv1
linear
layer1.1
layer3.1
layer2.1
layer4.0
layer4.1
1.bn1
layer2.0
layer3.0
layer1.0
Test Loss: 4.145 | Acc: 10.000 (1000/10000)
mseloss[1]:1.206870436668396, 1.607588768005371, 1.7390398979187012, 0.10745692253112793
mseloss[2]:1.121117353439331, 1.1782474517822266, 0.9277202486991882, 0.0802229642868042
mseloss[3]:1.123753309249878, 1.2004880905151367, 0.6448990702629089, 0.07523857802152634
mseloss[4]:1.1201610565185547, 1.4291820526123047, 1.6931663751602173, 0.20207278430461884
mseloss[5]:1.1415482759475708, 1.2644095420837402, 0.9168127179145813, 0.056582022458314896
mseloss[6]:1.1174750328063965, 1.360222339630127, 1.6335629224777222, 0.29462555050849915
mseloss[7]:1.1352850198745728, 1.4168754816055298, 1.6210860013961792, 0.24368655681610107
mseloss[8]:1.0929887294769287, 1.4005314111709595, 1.7752225399017334, 0.17443817853927612
mseloss[9]:1.1120089292526245, 1.404135823249817, 1.7238117456436157, 0.17722734808921814
Epoch:40
0
Train Loss: 0.473 | Acc: 82.046 (3729/4545)
Train Loss: 0.082 | Acc: 96.876 (4403/4545)
1
Train Loss: 0.668 | Acc: 74.477 (3385/4545)
Train Loss: 0.373 | Acc: 83.146 (3779/4545)
2
Train Loss: 0.829 | Acc: 78.130 (3551/4545)
Train Loss: 0.000 | Acc: 100.000 (4545/4545)
3
Train Loss: 0.661 | Acc: 75.094 (3413/4545)
Train Loss: 0.216 | Acc: 91.595 (4163/4545)
4
Train Loss: 0.984 | Acc: 63.630 (2892/4545)
Train Loss: 0.359 | Acc: 84.642 (3847/4545)
5
Train Loss: 0.765 | Acc: 79.428 (3610/4545)
Train Loss: 0.000 | Acc: 100.000 (4545/4545)
6
Train Loss: 0.708 | Acc: 77.646 (3529/4545)
Train Loss: 0.091 | Acc: 96.810 (4400/4545)
7
Train Loss: 0.685 | Acc: 77.536 (3524/4545)
Train Loss: 0.123 | Acc: 95.468 (4339/4545)
8
Train Loss: 1.188 | Acc: 72.343 (3288/4545)
Train Loss: 0.124 | Acc: 95.556 (4343/4545)
9
Train Loss: 0.591 | Acc: 81.276 (3694/4545)
Train Loss: 0.115 | Acc: 95.886 (4358/4545)
10
Train Loss: 1.097 | Acc: 69.571 (3162/4545)
Train Loss: 0.392 | Acc: 82.970 (3771/4545)
layer1.0
1.conv1
layer2.1
layer4.1
linear
1.bn1
layer1.1
layer2.0
layer4.0
layer3.1
layer3.0
Test Loss: 2.773 | Acc: 17.690 (1769/10000)
mseloss[1]:1.0355942249298096, 1.0170704126358032, 1.241662621498108, 0.19433599710464478
mseloss[2]:0.9947478175163269, 1.1380864381790161, 1.4511324167251587, 0.24906733632087708
mseloss[3]:1.0861191749572754, 1.2680195569992065, 1.7147517204284668, 0.23195092380046844
mseloss[4]:1.104844093322754, 1.238862156867981, 1.6419771909713745, 0.24628067016601562
mseloss[5]:0.9822802543640137, 1.0574865341186523, 1.2767256498336792, 0.20315510034561157
mseloss[6]:1.001453161239624, 1.0242364406585693, 0.8123739361763, 0.19839683175086975
mseloss[7]:1.0690289735794067, 1.246294379234314, 1.6325935125350952, 0.2857384979724884
mseloss[8]:1.0133056640625, 1.0287247896194458, 0.7635300159454346, 0.1681012362241745
mseloss[9]:0.9831033945083618, 0.9093780517578125, 0.8110378384590149, 0.17338573932647705
Epoch:41
0
Train Loss: 0.722 | Acc: 77.866 (3539/4545)
Train Loss: 0.079 | Acc: 97.008 (4409/4545)
1
Train Loss: 0.472 | Acc: 80.748 (3670/4545)
Train Loss: 0.338 | Acc: 86.139 (3915/4545)
2
Train Loss: 0.866 | Acc: 78.174 (3553/4545)
Train Loss: 0.112 | Acc: 95.820 (4355/4545)
3
Train Loss: 0.670 | Acc: 78.020 (3546/4545)
Train Loss: 0.110 | Acc: 95.974 (4362/4545)
4
Train Loss: 0.244 | Acc: 91.903 (4177/4545)
Train Loss: 0.000 | Acc: 100.000 (4545/4545)
5
Train Loss: 0.386 | Acc: 87.283 (3967/4545)
Train Loss: 0.000 | Acc: 100.000 (4545/4545)
6
Train Loss: 1.004 | Acc: 66.513 (3023/4545)
Train Loss: 0.395 | Acc: 83.410 (3791/4545)
7
Train Loss: 0.666 | Acc: 78.944 (3588/4545)
Train Loss: 0.227 | Acc: 91.595 (4163/4545)
8
Train Loss: 0.685 | Acc: 78.196 (3554/4545)
Train Loss: 0.136 | Acc: 95.270 (4330/4545)
9
Train Loss: 0.937 | Acc: 65.479 (2976/4545)
Train Loss: 0.392 | Acc: 82.376 (3744/4545)
10
Train Loss: 0.414 | Acc: 84.950 (3861/4545)
Train Loss: 0.092 | Acc: 96.238 (4374/4545)
layer3.1
1.conv1
linear
layer2.1
1.bn1
layer2.0
layer3.0
layer1.0
layer4.0
layer1.1
layer4.1
Test Loss: 6.734 | Acc: 10.000 (1000/10000)
mseloss[1]:0.9996760487556458, 0.9955576062202454, 1.1255096197128296, 0.22259171307086945
mseloss[2]:0.9372072219848633, 0.827157735824585, 0.6223453283309937, 0.18190020322799683
mseloss[3]:0.9455773830413818, 0.7704617977142334, 0.5062481760978699, 0.2380000799894333
mseloss[4]:0.9141806960105896, 0.7529681324958801, 0.4603523910045624, 0.22254212200641632
mseloss[5]:0.9603381156921387, 0.8582299947738647, 0.9990990161895752, 0.40673190355300903
mseloss[6]:1.013756275177002, 0.9143804311752319, 1.2355350255966187, 0.22601059079170227
mseloss[7]:1.018385648727417, 1.006723403930664, 1.387992262840271, 0.23465445637702942
mseloss[8]:0.9787294864654541, 0.8362382650375366, 1.032990574836731, 0.26167434453964233
mseloss[9]:0.9757336974143982, 0.817173182964325, 0.9057591557502747, 0.33814874291419983
Epoch:42
0
Train Loss: 0.594 | Acc: 81.606 (3709/4545)
Train Loss: 0.214 | Acc: 92.057 (4184/4545)
1
Train Loss: 0.527 | Acc: 81.826 (3719/4545)
Train Loss: 0.000 | Acc: 100.000 (4545/4545)
2
Train Loss: 1.268 | Acc: 58.042 (2638/4545)
Train Loss: 0.388 | Acc: 83.432 (3792/4545)
3
Train Loss: 0.882 | Acc: 69.175 (3144/4545)
Train Loss: 0.345 | Acc: 85.721 (3896/4545)
4
Train Loss: 0.472 | Acc: 87.987 (3999/4545)
Train Loss: 0.126 | Acc: 95.710 (4350/4545)
5
Train Loss: 0.458 | Acc: 83.278 (3785/4545)
Train Loss: 0.111 | Acc: 95.930 (4360/4545)
6
Train Loss: 0.707 | Acc: 77.778 (3535/4545)
Train Loss: 0.096 | Acc: 96.348 (4379/4545)
7
Train Loss: 0.941 | Acc: 61.650 (2802/4545)
Train Loss: 0.408 | Acc: 82.024 (3728/4545)
8
Train Loss: 1.092 | Acc: 69.791 (3172/4545)
Train Loss: 0.134 | Acc: 95.160 (4325/4545)
9
Train Loss: 0.738 | Acc: 79.384 (3608/4545)
Train Loss: 0.000 | Acc: 100.000 (4545/4545)
10
Train Loss: 0.921 | Acc: 73.289 (3331/4545)
Train Loss: 0.089 | Acc: 97.008 (4409/4545)
layer3.0
layer1.1
linear
layer2.0
layer1.0
layer2.1
layer4.1
layer4.0
layer3.1
1.bn1
1.conv1
Test Loss: 3.942 | Acc: 10.020 (1002/10000)
mseloss[1]:0.9627726674079895, 1.0104714632034302, 1.7426104545593262, 0.2242678999900818
mseloss[2]:0.9958221316337585, 0.9171816110610962, 0.582497239112854, 0.07320921868085861
mseloss[3]:0.9956024289131165, 0.927996814250946, 0.7359212040901184, 0.07496742904186249
mseloss[4]:0.9996044635772705, 0.9433752298355103, 0.6775879263877869, 0.11163588613271713
mseloss[5]:0.9923864603042603, 1.132325530052185, 1.3454941511154175, 0.26825639605522156
mseloss[6]:1.0039141178131104, 1.0460643768310547, 1.5628663301467896, 0.16262181103229523
mseloss[7]:0.9836459755897522, 1.0522792339324951, 1.6569560766220093, 0.19252216815948486
mseloss[8]:1.0096426010131836, 1.0733163356781006, 1.2466648817062378, 0.30074822902679443
mseloss[9]:0.9925658106803894, 1.0289665460586548, 1.3254474401474, 0.5240962505340576
Epoch:43
0
Train Loss: 1.157 | Acc: 69.131 (3142/4545)
Train Loss: 0.140 | Acc: 95.204 (4327/4545)
1
Train Loss: 0.666 | Acc: 75.600 (3436/4545)
Train Loss: 0.085 | Acc: 96.854 (4402/4545)
2
Train Loss: 0.744 | Acc: 78.020 (3546/4545)
Train Loss: 0.142 | Acc: 95.446 (4338/4545)
3
Train Loss: 0.776 | Acc: 79.406 (3609/4545)
Train Loss: 0.000 | Acc: 100.000 (4545/4545)
4
Train Loss: 0.876 | Acc: 73.509 (3341/4545)
Train Loss: 0.216 | Acc: 92.145 (4188/4545)
5
Train Loss: 1.360 | Acc: 63.410 (2882/4545)
Train Loss: 0.143 | Acc: 94.983 (4317/4545)
6
Train Loss: 0.908 | Acc: 75.952 (3452/4545)
Train Loss: 0.000 | Acc: 100.000 (4545/4545)
7
Train Loss: 0.611 | Acc: 75.468 (3430/4545)
Train Loss: 0.348 | Acc: 85.919 (3905/4545)
8
Train Loss: 0.643 | Acc: 75.204 (3418/4545)
Train Loss: 0.365 | Acc: 84.092 (3822/4545)
9
Train Loss: 1.101 | Acc: 65.743 (2988/4545)
Train Loss: 0.353 | Acc: 85.545 (3888/4545)
10
Train Loss: 1.182 | Acc: 69.329 (3151/4545)
Train Loss: 0.109 | Acc: 97.008 (4409/4545)
1.bn1
layer3.1
layer3.0
layer1.1
layer4.0
1.conv1
layer1.0
layer4.1
linear
layer2.1
layer2.0
Test Loss: 3.599 | Acc: 12.740 (1274/10000)
mseloss[1]:0.9947749376296997, 1.029712200164795, 1.3208434581756592, 0.23727290332317352
mseloss[2]:1.0207536220550537, 0.9880434274673462, 1.0361626148223877, 0.22230087220668793
mseloss[3]:0.9763741493225098, 0.9769765734672546, 1.0294232368469238, 0.20840398967266083
mseloss[4]:1.0592843294143677, 1.0843437910079956, 1.1260359287261963, 0.2156025469303131
mseloss[5]:0.9722449779510498, 0.9326959848403931, 1.1344435214996338, 0.20973923802375793
mseloss[6]:0.9496877789497375, 0.9559585452079773, 1.0125751495361328, 0.3167710304260254
mseloss[7]:1.045290231704712, 0.97231125831604, 1.0551992654800415, 0.2073892205953598
mseloss[8]:1.0450001955032349, 0.9728235602378845, 1.0235865116119385, 0.22529268264770508
mseloss[9]:1.0715136528015137, 1.0184003114700317, 1.0691306591033936, 0.20994555950164795
Epoch:44
0
Train Loss: 0.608 | Acc: 78.394 (3563/4545)
Train Loss: 0.205 | Acc: 92.189 (4190/4545)
1
Train Loss: 0.603 | Acc: 74.543 (3388/4545)
Train Loss: 0.345 | Acc: 85.897 (3904/4545)
2
Train Loss: 0.547 | Acc: 78.878 (3585/4545)
Train Loss: 0.301 | Acc: 88.097 (4004/4545)
3
Train Loss: 1.123 | Acc: 73.619 (3346/4545)
Train Loss: 0.075 | Acc: 97.382 (4426/4545)
4
Train Loss: 0.669 | Acc: 77.426 (3519/4545)
Train Loss: 0.099 | Acc: 96.304 (4377/4545)
5
Train Loss: 1.018 | Acc: 77.778 (3535/4545)
Train Loss: 0.000 | Acc: 100.000 (4545/4545)
6
Train Loss: 1.273 | Acc: 70.143 (3188/4545)
Train Loss: 0.113 | Acc: 95.974 (4362/4545)
7
Train Loss: 0.754 | Acc: 81.782 (3717/4545)
Train Loss: 0.000 | Acc: 100.000 (4545/4545)
8
Train Loss: 0.835 | Acc: 75.248 (3420/4545)
Train Loss: 0.119 | Acc: 96.062 (4366/4545)
9
Train Loss: 0.623 | Acc: 72.695 (3304/4545)
Train Loss: 0.376 | Acc: 83.652 (3802/4545)
10
Train Loss: 1.023 | Acc: 73.927 (3360/4545)
Train Loss: 0.116 | Acc: 95.534 (4342/4545)
layer2.1
layer3.0
layer3.1
1.bn1
layer2.0
layer1.1
layer4.1
linear
layer1.0
layer4.0
1.conv1
Test Loss: 7.435 | Acc: 12.630 (1263/10000)
mseloss[1]:0.9830964207649231, 0.819901704788208, 0.4814210832118988, 0.07559525221586227
mseloss[2]:0.9779170751571655, 0.8611699342727661, 0.6873711347579956, 0.0960676372051239
mseloss[3]:1.014540433883667, 0.9644614458084106, 1.26973557472229, 0.2008560299873352
mseloss[4]:1.006455659866333, 0.9754996299743652, 1.2250629663467407, 0.24991853535175323
mseloss[5]:1.0004485845565796, 1.0283433198928833, 1.387326955795288, 0.5770330429077148
mseloss[6]:0.9786023497581482, 0.9693491458892822, 1.2550426721572876, 0.3616597354412079
mseloss[7]:0.971552848815918, 0.9816259741783142, 1.3849602937698364, 0.3668685257434845
mseloss[8]:0.9815241694450378, 0.872772216796875, 0.7547770142555237, 0.11828213185071945
mseloss[9]:0.9843152165412903, 0.9295250177383423, 1.1492472887039185, 0.34040960669517517
Epoch:45
0
Train Loss: 1.020 | Acc: 74.983 (3408/4545)
Train Loss: 0.111 | Acc: 95.996 (4363/4545)
1
Train Loss: 1.448 | Acc: 66.205 (3009/4545)
Train Loss: 0.122 | Acc: 95.578 (4344/4545)
2
Train Loss: 0.016 | Acc: 99.912 (4541/4545)
Train Loss: 0.001 | Acc: 100.000 (4545/4545)
3
Train Loss: 0.791 | Acc: 78.174 (3553/4545)
Train Loss: 0.086 | Acc: 97.096 (4413/4545)
4
Train Loss: 1.288 | Acc: 70.473 (3203/4545)
Train Loss: 0.079 | Acc: 97.404 (4427/4545)
5
Train Loss: 1.313 | Acc: 61.078 (2776/4545)
Train Loss: 0.410 | Acc: 82.772 (3762/4545)
6
Train Loss: 0.923 | Acc: 66.117 (3005/4545)
Train Loss: 0.382 | Acc: 83.388 (3790/4545)
7
Train Loss: 1.094 | Acc: 70.561 (3207/4545)
Train Loss: 0.127 | Acc: 95.820 (4355/4545)
8
Train Loss: 1.033 | Acc: 68.405 (3109/4545)
Train Loss: 0.223 | Acc: 91.287 (4149/4545)
9
Train Loss: 0.608 | Acc: 81.342 (3697/4545)
Train Loss: 0.000 | Acc: 100.000 (4545/4545)
10
Train Loss: 0.946 | Acc: 67.085 (3049/4545)
Train Loss: 0.325 | Acc: 86.711 (3941/4545)
linear
layer2.1
layer3.1
layer2.0
layer1.1
layer4.0
layer1.0
1.bn1
1.conv1
layer3.0
layer4.1
Test Loss: 3.058 | Acc: 10.230 (1023/10000)
mseloss[1]:0.9224330186843872, 0.9626560807228088, 1.1727229356765747, 0.2679838538169861
mseloss[2]:0.9105959534645081, 0.8738967180252075, 0.7800743579864502, 0.24436281621456146
mseloss[3]:0.9483303427696228, 1.0065734386444092, 1.265091896057129, 0.3129594624042511
mseloss[4]:0.9692688584327698, 1.0201390981674194, 1.3223843574523926, 0.26546674966812134
mseloss[5]:0.988370954990387, 1.0691882371902466, 1.3924647569656372, 0.2832830548286438
mseloss[6]:0.9722093939781189, 0.952151894569397, 1.009000539779663, 0.24315981566905975
mseloss[7]:0.9614940881729126, 0.9792696237564087, 1.5127277374267578, 0.29287365078926086
mseloss[8]:0.9995864629745483, 0.9841234683990479, 1.5479812622070312, 0.31266239285469055
mseloss[9]:0.8979119062423706, 0.9103286862373352, 0.9554754495620728, 0.25463739037513733
Epoch:46
0
Train Loss: 0.575 | Acc: 80.000 (3636/4545)
Train Loss: 0.341 | Acc: 86.051 (3911/4545)
1
Train Loss: 0.791 | Acc: 70.011 (3182/4545)
Train Loss: 0.355 | Acc: 84.224 (3828/4545)
2
Train Loss: 0.675 | Acc: 75.776 (3444/4545)
Train Loss: 0.075 | Acc: 97.360 (4425/4545)
3
Train Loss: 0.436 | Acc: 83.696 (3804/4545)
Train Loss: 0.098 | Acc: 96.414 (4382/4545)
4
Train Loss: 0.874 | Acc: 73.179 (3326/4545)
Train Loss: 0.121 | Acc: 96.150 (4370/4545)
5
Train Loss: 0.835 | Acc: 73.773 (3353/4545)
Train Loss: 0.111 | Acc: 96.084 (4367/4545)
6
Train Loss: 0.749 | Acc: 76.810 (3491/4545)
Train Loss: 0.000 | Acc: 100.000 (4545/4545)
7
Train Loss: 0.669 | Acc: 78.504 (3568/4545)
Train Loss: 0.000 | Acc: 100.000 (4545/4545)
8
Train Loss: 0.871 | Acc: 69.571 (3162/4545)
Train Loss: 0.325 | Acc: 87.063 (3957/4545)
9
Train Loss: 0.686 | Acc: 77.008 (3500/4545)
Train Loss: 0.209 | Acc: 92.255 (4193/4545)
10
Train Loss: 1.028 | Acc: 71.265 (3239/4545)
Train Loss: 0.071 | Acc: 97.558 (4434/4545)
layer1.1
layer2.1
1.bn1
layer1.0
linear
1.conv1
layer3.0
layer3.1
layer4.1
layer4.0
layer2.0
Test Loss: 4.369 | Acc: 11.400 (1140/10000)
mseloss[1]:1.0160417556762695, 0.9843372702598572, 1.0574449300765991, 0.13782529532909393
mseloss[2]:0.9540789127349854, 0.9490522146224976, 1.0905463695526123, 0.17957085371017456
mseloss[3]:0.9772201776504517, 1.039165735244751, 1.126039981842041, 0.37161684036254883
mseloss[4]:0.9192225933074951, 0.7992689609527588, 0.7891939878463745, 0.08028030395507812
mseloss[5]:0.9371362328529358, 0.9342188835144043, 1.0724706649780273, 0.16862492263317108
mseloss[6]:0.9754589200019836, 1.07881760597229, 1.133463740348816, 0.26599350571632385
mseloss[7]:0.9630131125450134, 1.0182286500930786, 1.2360551357269287, 0.3204030990600586
mseloss[8]:0.9822716116905212, 0.8903016448020935, 0.8065946698188782, 0.06494276970624924
mseloss[9]:0.9669354557991028, 0.8017069697380066, 0.5633761286735535, 0.057562559843063354
Epoch:47
0
Train Loss: 0.534 | Acc: 83.784 (3808/4545)
Train Loss: 0.000 | Acc: 100.000 (4545/4545)
1
Train Loss: 0.971 | Acc: 74.829 (3401/4545)
Train Loss: 0.098 | Acc: 96.458 (4384/4545)
2
Train Loss: 1.406 | Acc: 63.102 (2868/4545)
Train Loss: 0.317 | Acc: 86.821 (3946/4545)
3
Train Loss: 0.343 | Acc: 87.085 (3958/4545)
Train Loss: 0.105 | Acc: 96.370 (4380/4545)
4
Train Loss: 0.329 | Acc: 91.287 (4149/4545)
Train Loss: 0.061 | Acc: 98.064 (4457/4545)
5
Train Loss: 0.869 | Acc: 77.008 (3500/4545)
Train Loss: 0.100 | Acc: 96.260 (4375/4545)
6
Train Loss: 0.369 | Acc: 85.963 (3907/4545)
Train Loss: 0.083 | Acc: 96.678 (4394/4545)
7
Train Loss: 1.570 | Acc: 60.418 (2746/4545)
Train Loss: 0.324 | Acc: 86.337 (3924/4545)
8
Train Loss: 0.810 | Acc: 78.262 (3557/4545)
Train Loss: 0.224 | Acc: 91.991 (4181/4545)
9
Train Loss: 1.332 | Acc: 63.608 (2891/4545)
Train Loss: 0.337 | Acc: 85.303 (3877/4545)
10
Train Loss: 0.606 | Acc: 83.410 (3791/4545)
Train Loss: 0.000 | Acc: 100.000 (4545/4545)
layer3.0
layer4.0
layer2.1
layer1.1
linear
layer2.0
1.conv1
layer3.1
layer1.0
1.bn1
layer4.1
Test Loss: 9.064 | Acc: 10.310 (1031/10000)
mseloss[1]:0.9192284345626831, 1.0010981559753418, 0.8927359580993652, 0.38647088408470154
mseloss[2]:1.0323749780654907, 1.3814107179641724, 1.3967307806015015, 0.4228530526161194
mseloss[3]:0.9760621786117554, 1.2232414484024048, 1.0971108675003052, 0.40179443359375
mseloss[4]:0.9738636612892151, 1.0371793508529663, 0.9255821704864502, 0.3904336392879486
mseloss[5]:0.9340988993644714, 1.0020147562026978, 0.9031693935394287, 0.40078264474868774
mseloss[6]:0.8999539613723755, 0.9817308783531189, 0.9365202188491821, 0.35574042797088623
mseloss[7]:1.0086798667907715, 1.2585357427597046, 1.1155184507369995, 0.40751007199287415
mseloss[8]:1.0395797491073608, 1.2998294830322266, 1.4110983610153198, 0.43785127997398376
mseloss[9]:0.9702330231666565, 1.0507500171661377, 0.9201709628105164, 0.45955774188041687
Epoch:48
0
Train Loss: 1.064 | Acc: 78.460 (3566/4545)
Train Loss: 0.000 | Acc: 100.000 (4545/4545)
1
Train Loss: 0.135 | Acc: 95.710 (4350/4545)
Train Loss: 0.054 | Acc: 98.064 (4457/4545)
2
Train Loss: 1.856 | Acc: 65.523 (2978/4545)
Train Loss: 0.213 | Acc: 92.299 (4195/4545)
3
Train Loss: 1.050 | Acc: 76.128 (3460/4545)
Train Loss: 0.125 | Acc: 95.314 (4332/4545)
4
Train Loss: 0.629 | Acc: 81.980 (3726/4545)
Train Loss: 0.000 | Acc: 100.000 (4545/4545)
5
Train Loss: 1.423 | Acc: 60.836 (2765/4545)
Train Loss: 0.362 | Acc: 83.982 (3817/4545)
6
Train Loss: 1.443 | Acc: 62.882 (2858/4545)
Train Loss: 0.340 | Acc: 85.963 (3907/4545)
7
Train Loss: 1.060 | Acc: 67.855 (3084/4545)
Train Loss: 0.306 | Acc: 88.383 (4017/4545)
8
Train Loss: 0.331 | Acc: 85.259 (3875/4545)
Train Loss: 0.088 | Acc: 96.612 (4391/4545)
9
Train Loss: 0.919 | Acc: 75.116 (3414/4545)
Train Loss: 0.099 | Acc: 96.150 (4370/4545)
10
Train Loss: 1.216 | Acc: 69.659 (3166/4545)
Train Loss: 0.076 | Acc: 97.272 (4421/4545)
1.conv1
layer2.0
layer3.0
1.bn1
layer4.0
layer1.0
layer3.1
layer4.1
linear
layer2.1
layer1.1
Test Loss: 4.535 | Acc: 16.850 (1685/10000)
mseloss[1]:0.9277628064155579, 1.0385336875915527, 0.8947974443435669, 0.3406400978565216
mseloss[2]:1.0037933588027954, 1.3501410484313965, 1.6581615209579468, 0.4580429792404175
mseloss[3]:1.0433242321014404, 1.4913090467453003, 1.3926899433135986, 0.4435136914253235
mseloss[4]:0.9499502778053284, 1.185978651046753, 0.9642223119735718, 0.4219892621040344
mseloss[5]:0.9804692268371582, 1.3073701858520508, 1.0694127082824707, 0.4281670153141022
mseloss[6]:0.9716095328330994, 1.447940468788147, 1.3556151390075684, 0.43887650966644287
mseloss[7]:0.9736130237579346, 1.3518190383911133, 1.6668485403060913, 0.43862849473953247
mseloss[8]:0.912038266658783, 1.078231930732727, 1.038676381111145, 0.42487141489982605
mseloss[9]:0.9399203062057495, 1.0981303453445435, 1.0851560831069946, 0.47192999720573425
Epoch:49
0
Train Loss: 0.683 | Acc: 78.790 (3581/4545)
Train Loss: 0.063 | Acc: 97.712 (4441/4545)
1
Train Loss: 0.743 | Acc: 78.240 (3556/4545)
Train Loss: 0.211 | Acc: 92.717 (4214/4545)
2
Train Loss: 0.120 | Acc: 96.590 (4390/4545)
Train Loss: 0.000 | Acc: 100.000 (4545/4545)
3
Train Loss: 0.405 | Acc: 83.652 (3802/4545)
Train Loss: 0.113 | Acc: 95.820 (4355/4545)
4
Train Loss: 1.222 | Acc: 62.728 (2851/4545)
Train Loss: 0.375 | Acc: 84.774 (3853/4545)
5
Train Loss: 0.973 | Acc: 68.185 (3099/4545)
Train Loss: 0.329 | Acc: 87.063 (3957/4545)
6
Train Loss: 0.849 | Acc: 69.263 (3148/4545)
Train Loss: 0.124 | Acc: 95.468 (4339/4545)
7
Train Loss: 1.290 | Acc: 64.422 (2928/4545)
Train Loss: 0.079 | Acc: 97.008 (4409/4545)
8
Train Loss: 1.048 | Acc: 70.055 (3184/4545)
Train Loss: 0.093 | Acc: 96.370 (4380/4545)
9
Train Loss: 1.190 | Acc: 61.914 (2814/4545)
Train Loss: 0.364 | Acc: 84.444 (3838/4545)
10
Train Loss: 0.919 | Acc: 74.653 (3393/4545)
Train Loss: 0.000 | Acc: 100.000 (4545/4545)
layer4.0
layer3.1
layer1.0
layer1.1
layer2.0
linear
1.conv1
layer4.1
layer3.0
1.bn1
layer2.1
Test Loss: 2.899 | Acc: 18.510 (1851/10000)
mseloss[1]:0.9899640679359436, 1.1683738231658936, 1.5486087799072266, 0.2044508159160614
mseloss[2]:0.8701664805412292, 0.9046385884284973, 0.7743203639984131, 0.2244223654270172
mseloss[3]:0.8868345022201538, 0.885272204875946, 0.659418523311615, 0.17911341786384583
mseloss[4]:0.9761097431182861, 1.2726517915725708, 1.8180197477340698, 0.2188354730606079
mseloss[5]:0.9751033782958984, 1.1203460693359375, 1.5008125305175781, 0.20488525927066803
mseloss[6]:0.9090405702590942, 1.0088231563568115, 1.220689296722412, 0.2144496738910675
mseloss[7]:0.9187677502632141, 0.9675090909004211, 0.9721572995185852, 0.2154669612646103
mseloss[8]:0.9014571905136108, 0.9882352352142334, 1.1365454196929932, 0.26424556970596313
mseloss[9]:0.9532671570777893, 0.932833731174469, 0.7381719946861267, 0.20162922143936157
Epoch:50
0
Train Loss: 0.446 | Acc: 83.190 (3781/4545)
Train Loss: 0.293 | Acc: 88.911 (4041/4545)
1
Train Loss: 0.556 | Acc: 82.552 (3752/4545)
Train Loss: 0.211 | Acc: 92.233 (4192/4545)
2
Train Loss: 0.667 | Acc: 79.758 (3625/4545)
Train Loss: 0.118 | Acc: 95.600 (4345/4545)
3
Train Loss: 0.756 | Acc: 76.128 (3460/4545)
Train Loss: 0.334 | Acc: 86.557 (3934/4545)
4
Train Loss: 0.746 | Acc: 80.814 (3673/4545)
Train Loss: 0.000 | Acc: 100.000 (4545/4545)
5
Train Loss: 0.421 | Acc: 85.369 (3880/4545)
Train Loss: 0.061 | Acc: 97.712 (4441/4545)
6
Train Loss: 0.507 | Acc: 84.268 (3830/4545)
Train Loss: 0.000 | Acc: 100.000 (4545/4545)
7
Train Loss: 0.913 | Acc: 72.453 (3293/4545)
Train Loss: 0.108 | Acc: 96.458 (4384/4545)
8
Train Loss: 0.920 | Acc: 65.039 (2956/4545)
Train Loss: 0.374 | Acc: 83.476 (3794/4545)
9
Train Loss: 0.509 | Acc: 82.464 (3748/4545)
Train Loss: 0.068 | Acc: 97.514 (4432/4545)
10
Train Loss: 0.316 | Acc: 89.087 (4049/4545)
Train Loss: 0.082 | Acc: 97.118 (4414/4545)
layer2.0
layer4.0
layer2.1
layer3.1
layer4.1
linear
layer1.1
layer1.0
1.bn1
layer3.0
1.conv1
Test Loss: 6.864 | Acc: 10.000 (1000/10000)
mseloss[1]:0.9005503058433533, 0.8686015605926514, 0.7447643876075745, 0.08098596334457397
mseloss[2]:0.8810306787490845, 1.019394874572754, 1.1228423118591309, 0.27749112248420715
mseloss[3]:0.901759684085846, 0.893522322177887, 0.80001300573349, 0.0792207270860672
mseloss[4]:0.8846570253372192, 1.0480891466140747, 1.3404291868209839, 0.36642250418663025
mseloss[5]:0.913360595703125, 1.0838431119918823, 1.5373469591140747, 0.3693571388721466
mseloss[6]:0.8851380944252014, 0.9142720699310303, 1.0516706705093384, 0.2479662448167801
mseloss[7]:0.8589475154876709, 0.8254191875457764, 0.5729814171791077, 0.1252177655696869
mseloss[8]:0.8959923982620239, 1.016933560371399, 1.2951594591140747, 0.2566787004470825
mseloss[9]:0.8984196782112122, 0.9962268471717834, 1.3102504014968872, 0.3068132698535919
Epoch:51
0
Train Loss: 0.680 | Acc: 77.360 (3516/4545)
Train Loss: 0.074 | Acc: 96.986 (4408/4545)
1
Train Loss: 0.464 | Acc: 84.224 (3828/4545)
Train Loss: 0.095 | Acc: 97.008 (4409/4545)
2
Train Loss: 0.586 | Acc: 76.568 (3480/4545)
Train Loss: 0.277 | Acc: 89.417 (4064/4545)
3
Train Loss: 0.531 | Acc: 81.540 (3706/4545)
Train Loss: 0.062 | Acc: 97.998 (4454/4545)
4
Train Loss: 0.940 | Acc: 64.906 (2950/4545)
Train Loss: 0.358 | Acc: 84.400 (3836/4545)
5
Train Loss: 0.387 | Acc: 85.589 (3890/4545)
Train Loss: 0.000 | Acc: 100.000 (4545/4545)
6
Train Loss: 0.818 | Acc: 79.076 (3594/4545)
Train Loss: 0.000 | Acc: 100.000 (4545/4545)
7
Train Loss: 0.274 | Acc: 91.221 (4146/4545)
Train Loss: 0.064 | Acc: 97.712 (4441/4545)
8
Train Loss: 0.662 | Acc: 78.438 (3565/4545)
Train Loss: 0.207 | Acc: 92.651 (4211/4545)
9
Train Loss: 0.577 | Acc: 78.394 (3563/4545)
Train Loss: 0.107 | Acc: 96.018 (4364/4545)
10
Train Loss: 0.953 | Acc: 67.437 (3065/4545)
Train Loss: 0.336 | Acc: 86.403 (3927/4545)
layer4.1
layer2.0
layer3.1
layer2.1
layer3.0
layer1.0
layer4.0
layer1.1
1.bn1
linear
1.conv1
Test Loss: 7.334 | Acc: 10.000 (1000/10000)
mseloss[1]:0.8681119084358215, 0.9668360948562622, 1.315085768699646, 0.4603557288646698
mseloss[2]:0.9226962924003601, 1.1110140085220337, 1.6086562871932983, 0.4723888039588928
mseloss[3]:0.8381432890892029, 0.8920848369598389, 1.2705011367797852, 0.4304354786872864
mseloss[4]:0.8701461553573608, 0.9741817712783813, 1.1648391485214233, 0.3883580267429352
mseloss[5]:0.8022509813308716, 0.867504894733429, 0.9509955644607544, 0.36798155307769775
mseloss[6]:0.8146697878837585, 0.8286170363426208, 0.8270581960678101, 0.29385170340538025
mseloss[7]:0.8626124262809753, 0.8974672555923462, 0.9929386973381042, 0.35920557379722595
mseloss[8]:0.9126502871513367, 1.1339921951293945, 1.548783302307129, 0.494789719581604
mseloss[9]:0.8139130473136902, 0.9183709025382996, 1.076346516609192, 0.417896568775177
Epoch:52
0
Train Loss: 1.058 | Acc: 70.495 (3204/4545)
Train Loss: 0.100 | Acc: 96.502 (4386/4545)
1
Train Loss: 1.205 | Acc: 59.296 (2695/4545)
Train Loss: 0.370 | Acc: 83.938 (3815/4545)
2
Train Loss: 0.823 | Acc: 77.096 (3504/4545)
Train Loss: 0.000 | Acc: 100.000 (4545/4545)
3
Train Loss: 0.957 | Acc: 72.035 (3274/4545)
Train Loss: 0.213 | Acc: 92.321 (4196/4545)
4
Train Loss: 0.887 | Acc: 70.781 (3217/4545)
Train Loss: 0.298 | Acc: 88.207 (4009/4545)
5
Train Loss: 0.272 | Acc: 92.541 (4206/4545)
Train Loss: 0.106 | Acc: 96.018 (4364/4545)
6
Train Loss: 0.588 | Acc: 80.154 (3643/4545)
Train Loss: 0.000 | Acc: 100.000 (4545/4545)
7
Train Loss: 1.034 | Acc: 66.865 (3039/4545)
Train Loss: 0.331 | Acc: 88.229 (4010/4545)
8
Train Loss: 0.625 | Acc: 80.660 (3666/4545)
Train Loss: 0.074 | Acc: 97.426 (4428/4545)
9
Train Loss: 0.667 | Acc: 77.954 (3543/4545)
Train Loss: 0.074 | Acc: 97.558 (4434/4545)
10
Train Loss: 0.588 | Acc: 78.108 (3550/4545)
Train Loss: 0.088 | Acc: 96.722 (4396/4545)
layer1.1
1.conv1
layer1.0
layer3.1
layer2.0
layer4.0
1.bn1
linear
layer4.1
layer2.1
layer3.0
Test Loss: 2.804 | Acc: 11.730 (1173/10000)
mseloss[1]:0.8867483139038086, 0.9506295323371887, 1.3341408967971802, 0.18813547492027283
mseloss[2]:0.8911757469177246, 1.0318479537963867, 1.7396715879440308, 0.27318084239959717
mseloss[3]:0.9330973625183105, 0.920660674571991, 0.8560499548912048, 0.11840809136629105
mseloss[4]:0.8960383534431458, 0.7972384095191956, 0.4850784242153168, 0.09694384783506393
mseloss[5]:0.8939456343650818, 0.9129732847213745, 0.9550649523735046, 0.2470495104789734
mseloss[6]:0.8690460324287415, 0.9600133895874023, 1.3936235904693604, 0.20125001668930054
mseloss[7]:0.9050513505935669, 0.8671957850456238, 1.0003505945205688, 0.13899774849414825
mseloss[8]:0.8963223695755005, 0.9559747576713562, 1.4252570867538452, 0.22426605224609375
mseloss[9]:0.8669613003730774, 0.9636925458908081, 1.7055624723434448, 0.23602385818958282
Epoch:53
0
Train Loss: 0.601 | Acc: 81.474 (3703/4545)
Train Loss: 0.000 | Acc: 100.000 (4545/4545)
1
Train Loss: 0.639 | Acc: 79.428 (3610/4545)
Train Loss: 0.080 | Acc: 96.854 (4402/4545)
2
Train Loss: 0.806 | Acc: 72.739 (3306/4545)
Train Loss: 0.216 | Acc: 91.947 (4179/4545)
3
Train Loss: 0.510 | Acc: 84.312 (3832/4545)
Train Loss: 0.000 | Acc: 100.000 (4545/4545)
4
Train Loss: 0.560 | Acc: 81.056 (3684/4545)
Train Loss: 0.301 | Acc: 88.647 (4029/4545)
5
Train Loss: 0.556 | Acc: 79.714 (3623/4545)
Train Loss: 0.110 | Acc: 96.018 (4364/4545)
6
Train Loss: 0.527 | Acc: 82.970 (3771/4545)
Train Loss: 0.076 | Acc: 97.162 (4416/4545)
7
Train Loss: 0.988 | Acc: 68.141 (3097/4545)
Train Loss: 0.342 | Acc: 84.664 (3848/4545)
8
Train Loss: 1.000 | Acc: 69.175 (3144/4545)
Train Loss: 0.265 | Acc: 90.275 (4103/4545)
9
Train Loss: 0.898 | Acc: 74.829 (3401/4545)
Train Loss: 0.104 | Acc: 96.304 (4377/4545)
10
Train Loss: 1.078 | Acc: 70.913 (3223/4545)
Train Loss: 0.076 | Acc: 97.426 (4428/4545)
layer4.0
layer3.0
1.bn1
layer2.1
layer4.1
layer1.1
layer1.0
linear
layer3.1
1.conv1
layer2.0
Test Loss: 3.118 | Acc: 13.160 (1316/10000)
mseloss[1]:0.84664386510849, 0.9046335816383362, 1.0898001194000244, 0.22205759584903717
mseloss[2]:0.9297959208488464, 1.277864933013916, 1.8186240196228027, 0.2972799241542816
mseloss[3]:0.8149359226226807, 0.8147870302200317, 0.8089620471000671, 0.2796558141708374
mseloss[4]:0.8809755444526672, 1.0786116123199463, 1.7500903606414795, 0.2747091054916382
mseloss[5]:0.8292672038078308, 0.8835561871528625, 0.8993522524833679, 0.23172402381896973
mseloss[6]:0.853977382183075, 0.918128252029419, 0.8032376766204834, 0.24731753766536713
mseloss[7]:0.8364570736885071, 0.7517310380935669, 0.5641493797302246, 0.21114479005336761
mseloss[8]:0.9304251670837402, 1.2192381620407104, 1.6597070693969727, 0.2729830741882324
mseloss[9]:0.8660858869552612, 1.0805871486663818, 1.36399507522583, 0.25688275694847107
Epoch:54
0
Train Loss: 0.574 | Acc: 76.414 (3473/4545)
Train Loss: 0.327 | Acc: 85.721 (3896/4545)
1
Train Loss: 0.887 | Acc: 73.377 (3335/4545)
Train Loss: 0.090 | Acc: 96.612 (4391/4545)
2
Train Loss: 1.098 | Acc: 67.019 (3046/4545)
Train Loss: 0.214 | Acc: 91.991 (4181/4545)
3
Train Loss: 1.060 | Acc: 70.869 (3221/4545)
Train Loss: 0.109 | Acc: 96.216 (4373/4545)
4
Train Loss: 0.889 | Acc: 71.661 (3257/4545)
Train Loss: 0.247 | Acc: 90.671 (4121/4545)
5
Train Loss: 1.037 | Acc: 75.226 (3419/4545)
Train Loss: 0.000 | Acc: 100.000 (4545/4545)
6
Train Loss: 0.365 | Acc: 85.171 (3871/4545)
Train Loss: 0.061 | Acc: 97.800 (4445/4545)
7
Train Loss: 0.836 | Acc: 75.006 (3409/4545)
Train Loss: 0.068 | Acc: 97.580 (4435/4545)
8
Train Loss: 0.930 | Acc: 73.421 (3337/4545)
Train Loss: 0.094 | Acc: 96.986 (4408/4545)
9
Train Loss: 0.402 | Acc: 85.149 (3870/4545)
Train Loss: 0.000 | Acc: 100.000 (4545/4545)
10
Train Loss: 0.640 | Acc: 74.433 (3383/4545)
Train Loss: 0.311 | Acc: 87.965 (3998/4545)
1.bn1
layer1.1
layer4.0
layer2.1
layer1.0
layer4.1
layer3.0
linear
layer3.1
layer2.0
1.conv1
Test Loss: 5.357 | Acc: 10.020 (1002/10000)
mseloss[1]:0.8818854093551636, 0.9149941205978394, 1.415008306503296, 0.517534613609314
mseloss[2]:0.9167777299880981, 1.145451307296753, 1.8719087839126587, 0.3238722085952759
mseloss[3]:0.8792775273323059, 0.8371031284332275, 0.8777765035629272, 0.24515587091445923
mseloss[4]:0.9174779057502747, 1.0500818490982056, 1.4627338647842407, 0.28387555480003357
mseloss[5]:0.8707268238067627, 0.7872384786605835, 0.8125757575035095, 0.22426734864711761
mseloss[6]:0.8768180012702942, 0.7939743399620056, 0.7949853539466858, 0.2353462278842926
mseloss[7]:0.8947991132736206, 0.8725166916847229, 1.0575059652328491, 0.294971764087677
mseloss[8]:0.876067042350769, 0.9193856120109558, 1.325657844543457, 0.2667897045612335
mseloss[9]:0.8373897671699524, 0.7418506145477295, 0.6837334036827087, 0.2325545698404312
Epoch:55
0
Train Loss: 0.263 | Acc: 92.805 (4218/4545)
Train Loss: 0.085 | Acc: 97.118 (4414/4545)
1
Train Loss: 0.169 | Acc: 94.169 (4280/4545)
Train Loss: 0.051 | Acc: 98.174 (4462/4545)
2
Train Loss: 1.460 | Acc: 56.260 (2557/4545)
Train Loss: 0.385 | Acc: 83.454 (3793/4545)
3
Train Loss: 0.744 | Acc: 72.035 (3274/4545)
Train Loss: 0.239 | Acc: 91.001 (4136/4545)
4
Train Loss: 0.531 | Acc: 81.034 (3683/4545)
Train Loss: 0.195 | Acc: 93.069 (4230/4545)
5
Train Loss: 0.819 | Acc: 74.345 (3379/4545)
Train Loss: 0.110 | Acc: 95.622 (4346/4545)
6
Train Loss: 1.375 | Acc: 68.999 (3136/4545)
Train Loss: 0.000 | Acc: 100.000 (4545/4545)
7
Train Loss: 0.958 | Acc: 67.459 (3066/4545)
Train Loss: 0.303 | Acc: 88.273 (4012/4545)
8
Train Loss: 0.884 | Acc: 73.949 (3361/4545)
Train Loss: 0.065 | Acc: 97.756 (4443/4545)
9
Train Loss: 1.057 | Acc: 71.331 (3242/4545)
Train Loss: 0.090 | Acc: 96.568 (4389/4545)
10
Train Loss: 0.627 | Acc: 81.012 (3682/4545)
Train Loss: 0.000 | Acc: 100.000 (4545/4545)
1.conv1
layer4.1
layer4.0
layer2.1
linear
1.bn1
layer1.1
layer3.0
layer2.0
layer1.0
layer3.1
Test Loss: 4.298 | Acc: 14.350 (1435/10000)
mseloss[1]:0.8846493363380432, 0.9845487475395203, 1.4805876016616821, 0.3038896322250366
mseloss[2]:0.8731675148010254, 0.8655137419700623, 1.2575687170028687, 0.18306168913841248
mseloss[3]:0.8790856003761292, 0.7581727504730225, 0.49678778648376465, 0.10541641712188721
mseloss[4]:0.911727786064148, 0.8296200633049011, 0.7650094628334045, 0.11651208996772766
mseloss[5]:0.8719308972358704, 0.8352158665657043, 0.9780017733573914, 0.14991669356822968
mseloss[6]:0.8512111902236938, 0.9277176260948181, 1.473054051399231, 0.2362118661403656
mseloss[7]:0.8784803152084351, 0.783560574054718, 0.8972173929214478, 0.12547637522220612
mseloss[8]:0.8619778156280518, 0.9125598669052124, 1.5254606008529663, 0.2755378186702728
mseloss[9]:0.8980914950370789, 0.9254006743431091, 1.2789852619171143, 0.37411123514175415
Epoch:56
0
Train Loss: 0.773 | Acc: 75.424 (3428/4545)
Train Loss: 0.214 | Acc: 92.299 (4195/4545)
1
Train Loss: 0.418 | Acc: 88.801 (4036/4545)
Train Loss: 0.046 | Acc: 98.504 (4477/4545)
2
Train Loss: 0.490 | Acc: 82.398 (3745/4545)
Train Loss: 0.098 | Acc: 96.304 (4377/4545)
3
Train Loss: 0.786 | Acc: 77.580 (3526/4545)
Train Loss: 0.284 | Acc: 89.043 (4047/4545)
4
Train Loss: 1.160 | Acc: 71.441 (3247/4545)
Train Loss: 0.085 | Acc: 96.986 (4408/4545)
5
Train Loss: 0.588 | Acc: 80.858 (3675/4545)
Train Loss: 0.309 | Acc: 86.601 (3936/4545)
6
Train Loss: 0.796 | Acc: 73.949 (3361/4545)
Train Loss: 0.103 | Acc: 96.700 (4395/4545)
7
Train Loss: 1.574 | Acc: 69.373 (3153/4545)
Train Loss: 0.001 | Acc: 100.000 (4545/4545)
8
Train Loss: 0.798 | Acc: 76.480 (3476/4545)
Train Loss: 0.064 | Acc: 97.822 (4446/4545)
9
Train Loss: 0.930 | Acc: 70.715 (3214/4545)
Train Loss: 0.241 | Acc: 91.265 (4148/4545)
10
Train Loss: 0.426 | Acc: 85.039 (3865/4545)
Train Loss: 0.000 | Acc: 100.000 (4545/4545)
layer2.0
layer2.1
layer4.1
layer3.0
layer1.0
layer3.1
1.bn1
linear
layer1.1
layer4.0
1.conv1
Test Loss: 3.066 | Acc: 12.300 (1230/10000)
mseloss[1]:0.9451543688774109, 1.0657552480697632, 1.7590328454971313, 0.34458127617836
mseloss[2]:0.9634031057357788, 1.0766305923461914, 1.6608942747116089, 0.319580078125
mseloss[3]:0.948826014995575, 0.8332701921463013, 0.7291536927223206, 0.09759307652711868
mseloss[4]:0.9267937541007996, 1.0756759643554688, 1.689972162246704, 0.5449023246765137
mseloss[5]:0.9400951862335205, 1.024702787399292, 1.6971672773361206, 0.24933691322803497
mseloss[6]:0.9265965819358826, 0.8095276951789856, 0.8468188047409058, 0.11928101629018784
mseloss[7]:0.929154634475708, 1.043917179107666, 1.8557120561599731, 0.2234087884426117
mseloss[8]:0.9648822546005249, 1.0312654972076416, 1.5031951665878296, 0.269419401884079
mseloss[9]:0.9440985918045044, 0.8321000337600708, 0.9560034871101379, 0.12787526845932007
Epoch:57
0
Train Loss: 0.885 | Acc: 68.075 (3094/4545)
Train Loss: 0.326 | Acc: 85.765 (3898/4545)
1
Train Loss: 0.489 | Acc: 83.542 (3797/4545)
Train Loss: 0.216 | Acc: 92.563 (4207/4545)
2
Train Loss: 0.873 | Acc: 73.377 (3335/4545)
Train Loss: 0.057 | Acc: 97.932 (4451/4545)
3
Train Loss: 0.513 | Acc: 81.672 (3712/4545)
Train Loss: 0.051 | Acc: 98.152 (4461/4545)
4
Train Loss: 0.540 | Acc: 80.550 (3661/4545)
Train Loss: 0.103 | Acc: 96.238 (4374/4545)
5
Train Loss: 0.603 | Acc: 79.824 (3628/4545)
Train Loss: 0.253 | Acc: 90.077 (4094/4545)
6
Train Loss: 0.324 | Acc: 88.493 (4022/4545)
Train Loss: 0.000 | Acc: 100.000 (4545/4545)
7
Train Loss: 0.995 | Acc: 72.695 (3304/4545)
Train Loss: 0.078 | Acc: 97.360 (4425/4545)
8
Train Loss: 0.227 | Acc: 91.661 (4166/4545)
Train Loss: 0.000 | Acc: 100.000 (4545/4545)
9
Train Loss: 0.688 | Acc: 77.998 (3545/4545)
Train Loss: 0.193 | Acc: 92.673 (4212/4545)
10
Train Loss: 0.934 | Acc: 72.607 (3300/4545)
Train Loss: 0.090 | Acc: 97.096 (4413/4545)
linear
layer1.1
layer3.0
layer4.1
layer2.0
layer1.0
1.conv1
layer2.1
1.bn1
layer4.0
layer3.1
Test Loss: 3.341 | Acc: 10.000 (1000/10000)
mseloss[1]:0.901604413986206, 0.951788067817688, 1.374826431274414, 0.20287801325321198
mseloss[2]:0.8723804950714111, 0.7360478639602661, 0.5855798721313477, 0.18127121031284332
mseloss[3]:0.8794520497322083, 0.7237647175788879, 0.5916634202003479, 0.37075111269950867
mseloss[4]:0.867299497127533, 0.7444918155670166, 0.5779625773429871, 0.19287411868572235
mseloss[5]:0.9105501770973206, 0.988964855670929, 1.2540184259414673, 0.20028719305992126
mseloss[6]:0.857749342918396, 0.6831801533699036, 0.5085527300834656, 0.15246370434761047
mseloss[7]:0.8695692420005798, 0.8543722033500671, 0.8662051558494568, 0.24844418466091156
mseloss[8]:0.8205402493476868, 0.627370297908783, 0.5398591160774231, 0.4192533791065216
mseloss[9]:0.9105703234672546, 1.0121231079101562, 1.5209823846817017, 0.23901021480560303
Epoch:58
0
Train Loss: 0.529 | Acc: 79.692 (3622/4545)
Train Loss: 0.309 | Acc: 86.381 (3926/4545)
1
Train Loss: 1.267 | Acc: 69.439 (3156/4545)
Train Loss: 0.078 | Acc: 97.250 (4420/4545)
2
Train Loss: 0.587 | Acc: 80.506 (3659/4545)
Train Loss: 0.058 | Acc: 97.844 (4447/4545)
3
Train Loss: 0.435 | Acc: 85.435 (3883/4545)
Train Loss: 0.000 | Acc: 100.000 (4545/4545)
4
Train Loss: 0.782 | Acc: 76.722 (3487/4545)
Train Loss: 0.259 | Acc: 90.253 (4102/4545)
5
Train Loss: 0.629 | Acc: 79.846 (3629/4545)
Train Loss: 0.093 | Acc: 96.612 (4391/4545)
6
Train Loss: 0.472 | Acc: 84.092 (3822/4545)
Train Loss: 0.089 | Acc: 97.184 (4417/4545)
7
Train Loss: 0.698 | Acc: 75.336 (3424/4545)
Train Loss: 0.229 | Acc: 91.903 (4177/4545)
8
Train Loss: 0.467 | Acc: 84.180 (3826/4545)
Train Loss: 0.058 | Acc: 98.130 (4460/4545)
9
Train Loss: 0.564 | Acc: 80.902 (3677/4545)
Train Loss: 0.184 | Acc: 93.201 (4236/4545)
10
Train Loss: 0.866 | Acc: 78.196 (3554/4545)
Train Loss: 0.000 | Acc: 100.000 (4545/4545)
layer3.0
layer2.1
1.conv1
1.bn1
linear
layer2.0
layer4.1
layer1.1
layer1.0
layer3.1
layer4.0
Test Loss: 3.208 | Acc: 14.870 (1487/10000)
mseloss[1]:0.8798433542251587, 0.8218651413917542, 0.8370550870895386, 0.31719455122947693
mseloss[2]:0.8893409371376038, 0.7389804720878601, 0.5304487943649292, 0.3405902087688446
mseloss[3]:0.8354583978652954, 0.6142051815986633, 0.48233485221862793, 0.311356782913208
mseloss[4]:0.920133650302887, 0.9852890968322754, 1.152543306350708, 0.27618688344955444
mseloss[5]:0.8733029961585999, 0.7686191201210022, 0.5786559581756592, 0.2440231293439865
mseloss[6]:0.861415445804596, 0.8381038308143616, 0.9233096837997437, 0.2679964601993561
mseloss[7]:0.919895589351654, 0.9331179261207581, 1.1239354610443115, 0.27525779604911804
mseloss[8]:0.8788907527923584, 0.7080078125, 0.5887091159820557, 0.35268712043762207
mseloss[9]:0.9218913316726685, 1.0375945568084717, 1.2302517890930176, 0.3095650374889374
Epoch:59
0
Train Loss: 0.485 | Acc: 82.156 (3734/4545)
Train Loss: 0.239 | Acc: 91.243 (4147/4545)
1
Train Loss: 0.500 | Acc: 82.222 (3737/4545)
Train Loss: 0.218 | Acc: 91.859 (4175/4545)
2
Train Loss: 0.690 | Acc: 79.692 (3622/4545)
Train Loss: 0.001 | Acc: 100.000 (4545/4545)
3
Train Loss: 0.815 | Acc: 71.837 (3265/4545)
Train Loss: 0.193 | Acc: 93.091 (4231/4545)
4
Train Loss: 0.785 | Acc: 78.482 (3567/4545)
Train Loss: 0.000 | Acc: 100.000 (4545/4545)
5
Train Loss: 0.621 | Acc: 79.318 (3605/4545)
Train Loss: 0.105 | Acc: 96.898 (4404/4545)
6
Train Loss: 1.043 | Acc: 72.167 (3280/4545)
Train Loss: 0.060 | Acc: 97.866 (4448/4545)
7
Train Loss: 0.613 | Acc: 80.572 (3662/4545)
Train Loss: 0.056 | Acc: 97.976 (4453/4545)
8
Train Loss: 0.677 | Acc: 77.360 (3516/4545)
Train Loss: 0.095 | Acc: 96.700 (4395/4545)
9
Train Loss: 0.770 | Acc: 72.893 (3313/4545)
Train Loss: 0.311 | Acc: 86.535 (3933/4545)
10
Train Loss: 1.226 | Acc: 69.703 (3168/4545)
Train Loss: 0.079 | Acc: 96.942 (4406/4545)
layer1.0
linear
1.conv1
layer3.1
1.bn1
layer1.1
layer2.0
layer4.0
layer3.0
layer2.1
layer4.1
Test Loss: 4.147 | Acc: 18.460 (1846/10000)
mseloss[1]:0.8715010285377502, 0.7821197509765625, 0.6446700692176819, 0.13437528908252716
mseloss[2]:0.8531304001808167, 0.8947789072990417, 1.118912696838379, 0.3249414265155792
mseloss[3]:0.8894031047821045, 0.8223862051963806, 0.6271172761917114, 0.11085179448127747
mseloss[4]:0.8461755514144897, 0.8296063542366028, 1.0465712547302246, 0.3697540760040283
mseloss[5]:0.826033353805542, 0.7841160893440247, 0.7387738823890686, 0.18061557412147522
mseloss[6]:0.8449515104293823, 0.8406506776809692, 1.0094243288040161, 0.3420327305793762
mseloss[7]:0.8611461520195007, 0.8849311470985413, 0.9684553742408752, 0.31614139676094055
mseloss[8]:0.8341405987739563, 0.7936115860939026, 0.7732774019241333, 0.2540285587310791
mseloss[9]:0.8761189579963684, 0.8547157049179077, 0.8443742990493774, 0.31544238328933716
Epoch:60
0
Train Loss: 0.757 | Acc: 73.069 (3321/4545)
Train Loss: 0.246 | Acc: 90.451 (4111/4545)
1
Train Loss: 0.173 | Acc: 95.534 (4342/4545)
Train Loss: 0.042 | Acc: 98.658 (4484/4545)
2
Train Loss: 0.386 | Acc: 84.994 (3863/4545)
Train Loss: 0.000 | Acc: 100.000 (4545/4545)
3
Train Loss: 0.805 | Acc: 72.827 (3310/4545)
Train Loss: 0.221 | Acc: 91.969 (4180/4545)
4
Train Loss: 0.437 | Acc: 85.567 (3889/4545)
Train Loss: 0.084 | Acc: 96.832 (4401/4545)
5
Train Loss: 0.711 | Acc: 78.306 (3559/4545)
Train Loss: 0.191 | Acc: 93.201 (4236/4545)
6
Train Loss: 0.741 | Acc: 78.416 (3564/4545)
Train Loss: 0.075 | Acc: 97.294 (4422/4545)
7
Train Loss: 0.761 | Acc: 70.627 (3210/4545)
Train Loss: 0.295 | Acc: 87.437 (3974/4545)
8
Train Loss: 0.396 | Acc: 88.031 (4001/4545)
Train Loss: 0.000 | Acc: 100.000 (4545/4545)
9
Train Loss: 0.925 | Acc: 77.470 (3521/4545)
Train Loss: 0.108 | Acc: 96.722 (4396/4545)
10
Train Loss: 0.432 | Acc: 85.545 (3888/4545)
Train Loss: 0.043 | Acc: 98.350 (4470/4545)
linear
layer2.1
layer2.0
1.conv1
layer3.1
layer1.1
1.bn1
layer4.0
layer4.1
layer1.0
layer3.0
Test Loss: 7.000 | Acc: 10.220 (1022/10000)
mseloss[1]:0.8470487594604492, 0.8347305059432983, 0.9493124485015869, 0.3686830997467041
mseloss[2]:0.8351613879203796, 0.8096420168876648, 1.0982602834701538, 0.45253196358680725
mseloss[3]:0.857350766658783, 0.7969875335693359, 0.6677904725074768, 0.15772733092308044
mseloss[4]:0.8246803283691406, 0.7954272031784058, 0.9194303750991821, 0.3767693042755127
mseloss[5]:0.8767701387405396, 0.7903379201889038, 0.48455458879470825, 0.1271144300699234
mseloss[6]:0.8468689918518066, 0.8141039609909058, 0.8694996237754822, 0.37538182735443115
mseloss[7]:0.8733071088790894, 0.8345930576324463, 0.9089774489402771, 0.5229474902153015
mseloss[8]:0.8543974161148071, 0.8437523245811462, 1.1564775705337524, 0.42363986372947693
mseloss[9]:0.8265783786773682, 0.7628782987594604, 0.6401286721229553, 0.2029493749141693
Epoch:61
0
Train Loss: 0.959 | Acc: 75.072 (3412/4545)
Train Loss: 0.090 | Acc: 96.568 (4389/4545)
1
Train Loss: 0.638 | Acc: 78.988 (3590/4545)
Train Loss: 0.246 | Acc: 90.561 (4116/4545)
2
Train Loss: 2.674 | Acc: 56.348 (2561/4545)
Train Loss: 0.201 | Acc: 93.135 (4233/4545)
3
Train Loss: 1.205 | Acc: 70.495 (3204/4545)
Train Loss: 0.080 | Acc: 96.766 (4398/4545)
4
Train Loss: 1.561 | Acc: 70.979 (3226/4545)
Train Loss: 0.235 | Acc: 91.463 (4157/4545)
5
Train Loss: 0.724 | Acc: 78.526 (3569/4545)
Train Loss: 0.000 | Acc: 100.000 (4545/4545)
6
Train Loss: 0.838 | Acc: 76.326 (3469/4545)
Train Loss: 0.054 | Acc: 98.042 (4456/4545)
7
Train Loss: 0.590 | Acc: 78.526 (3569/4545)
Train Loss: 0.300 | Acc: 86.953 (3952/4545)
8
Train Loss: 0.596 | Acc: 80.132 (3642/4545)
Train Loss: 0.047 | Acc: 98.416 (4473/4545)
9
Train Loss: 2.015 | Acc: 64.004 (2909/4545)
Train Loss: 0.116 | Acc: 96.678 (4394/4545)
10
Train Loss: 0.794 | Acc: 80.418 (3655/4545)
Train Loss: 0.000 | Acc: 100.000 (4545/4545)
layer2.0
layer1.1
layer3.0
layer1.0
1.conv1
layer4.1
linear
1.bn1
layer2.1
layer3.1
layer4.0
Test Loss: 5.344 | Acc: 11.180 (1118/10000)
mseloss[1]:0.8470796942710876, 0.8604349493980408, 1.0335363149642944, 0.28964874148368835
mseloss[2]:0.9096603393554688, 1.0701180696487427, 1.4060277938842773, 0.3826046288013458
mseloss[3]:0.833490252494812, 0.7888776063919067, 0.7586302757263184, 0.311096727848053
mseloss[4]:0.8690161108970642, 0.9965225458145142, 1.0417311191558838, 0.29558730125427246
mseloss[5]:0.8268334269523621, 0.8431252241134644, 0.8491041660308838, 0.21955989301204681
mseloss[6]:0.8457592725753784, 0.8004353642463684, 0.5166263580322266, 0.24522699415683746
mseloss[7]:0.8670744895935059, 0.7790237665176392, 0.5631750226020813, 0.32729241251945496
mseloss[8]:0.8364579677581787, 0.7822816967964172, 0.8306117057800293, 0.33407577872276306
mseloss[9]:0.872546911239624, 1.0812948942184448, 1.1478586196899414, 0.3206004202365875
Epoch:62
0
Train Loss: 1.090 | Acc: 63.168 (2871/4545)
Train Loss: 0.318 | Acc: 86.447 (3929/4545)
1
Train Loss: 1.376 | Acc: 68.075 (3094/4545)
Train Loss: 0.194 | Acc: 93.553 (4252/4545)
2
Train Loss: 0.891 | Acc: 68.933 (3133/4545)
Train Loss: 0.260 | Acc: 89.703 (4077/4545)
3
Train Loss: 0.570 | Acc: 80.528 (3660/4545)
Train Loss: 0.000 | Acc: 100.000 (4545/4545)
4
Train Loss: 0.648 | Acc: 79.120 (3596/4545)
Train Loss: 0.047 | Acc: 98.460 (4475/4545)
5
Train Loss: 0.195 | Acc: 93.619 (4255/4545)
Train Loss: 0.049 | Acc: 98.240 (4465/4545)
6
Train Loss: 0.712 | Acc: 77.272 (3512/4545)
Train Loss: 0.084 | Acc: 96.986 (4408/4545)
7
Train Loss: 1.368 | Acc: 65.325 (2969/4545)
Train Loss: 0.231 | Acc: 91.551 (4161/4545)
8
Train Loss: 0.957 | Acc: 71.573 (3253/4545)
Train Loss: 0.089 | Acc: 96.876 (4403/4545)
9
Train Loss: 1.001 | Acc: 79.846 (3629/4545)
Train Loss: 0.095 | Acc: 97.228 (4419/4545)
10
Train Loss: 0.914 | Acc: 75.028 (3410/4545)
Train Loss: 0.001 | Acc: 100.000 (4545/4545)
1.bn1
layer3.0
layer1.0
layer4.0
layer3.1
layer4.1
linear
1.conv1
layer2.1
layer2.0
layer1.1
Test Loss: 4.464 | Acc: 10.000 (1000/10000)
mseloss[1]:0.8886107802391052, 1.0179474353790283, 1.5371079444885254, 0.3319227993488312
mseloss[2]:0.8909623622894287, 0.9466080665588379, 1.3751428127288818, 0.2768457233905792
mseloss[3]:0.834145188331604, 0.7646521925926208, 0.6664289236068726, 0.2537972331047058
mseloss[4]:0.874481201171875, 0.8164095282554626, 0.8561525940895081, 0.24362368881702423
mseloss[5]:0.8724409937858582, 0.880090594291687, 0.8127602934837341, 0.275896817445755
mseloss[6]:0.8837141990661621, 0.8587245345115662, 0.813941478729248, 0.2486044317483902
mseloss[7]:0.8760546445846558, 0.9452776908874512, 1.2397516965866089, 0.2773958146572113
mseloss[8]:0.8676973581314087, 0.8888176083564758, 1.0751495361328125, 0.31723669171333313
mseloss[9]:0.8590319156646729, 0.9298555850982666, 1.1605221033096313, 0.28185394406318665
Epoch:63
0
Train Loss: 0.750 | Acc: 80.660 (3666/4545)
Train Loss: 0.085 | Acc: 97.646 (4438/4545)
1
Train Loss: 0.826 | Acc: 75.710 (3441/4545)
Train Loss: 0.048 | Acc: 98.306 (4468/4545)
2
Train Loss: 0.241 | Acc: 93.707 (4259/4545)
Train Loss: 0.081 | Acc: 97.228 (4419/4545)
3
Train Loss: 1.188 | Acc: 67.877 (3085/4545)
Train Loss: 0.093 | Acc: 96.832 (4401/4545)
4
Train Loss: 1.057 | Acc: 65.259 (2966/4545)
Train Loss: 0.277 | Acc: 89.505 (4068/4545)
5
Train Loss: 0.532 | Acc: 80.000 (3636/4545)
Train Loss: 0.002 | Acc: 100.000 (4545/4545)
6
Train Loss: 0.881 | Acc: 71.881 (3267/4545)
Train Loss: 0.218 | Acc: 91.925 (4178/4545)
7
Train Loss: 1.143 | Acc: 62.662 (2848/4545)
Train Loss: 0.335 | Acc: 85.699 (3895/4545)
8
Train Loss: 0.801 | Acc: 75.952 (3452/4545)
Train Loss: 0.193 | Acc: 93.245 (4238/4545)
9
Train Loss: 0.489 | Acc: 82.904 (3768/4545)
Train Loss: 0.058 | Acc: 97.888 (4449/4545)
10
Train Loss: 0.638 | Acc: 78.812 (3582/4545)
Train Loss: 0.001 | Acc: 100.000 (4545/4545)
layer1.0
layer1.1
layer4.0
linear
layer2.1
1.conv1
layer4.1
layer2.0
layer3.0
layer3.1
1.bn1
Test Loss: 2.391 | Acc: 21.310 (2131/10000)
mseloss[1]:0.8461092710494995, 0.9737704992294312, 1.5637468099594116, 0.30355313420295715
mseloss[2]:0.8680980801582336, 0.9227150082588196, 0.954179048538208, 0.255248099565506
mseloss[3]:0.8742994666099548, 0.9889378547668457, 1.227323293685913, 0.2756842374801636
mseloss[4]:0.8558300137519836, 0.8667849898338318, 0.7287518978118896, 0.17888383567333221
mseloss[5]:0.8778533935546875, 1.0795443058013916, 1.6543364524841309, 0.27814343571662903
mseloss[6]:0.8532942533493042, 0.7302877902984619, 0.38907793164253235, 0.1179819330573082
mseloss[7]:0.8746218085289001, 0.9242221117019653, 1.1359049081802368, 0.23708125948905945
mseloss[8]:0.8930667638778687, 0.8260297179222107, 0.6862282156944275, 0.1357947289943695
mseloss[9]:0.8618420958518982, 0.9437223076820374, 1.2733088731765747, 0.26295724511146545
Epoch:64
0
Train Loss: 0.518 | Acc: 81.056 (3684/4545)
Train Loss: 0.001 | Acc: 100.000 (4545/4545)
1
Train Loss: 0.393 | Acc: 85.303 (3877/4545)
Train Loss: 0.083 | Acc: 97.074 (4412/4545)
2
Train Loss: 0.910 | Acc: 73.553 (3343/4545)
Train Loss: 0.001 | Acc: 100.000 (4545/4545)
3
Train Loss: 0.631 | Acc: 81.452 (3702/4545)
Train Loss: 0.066 | Acc: 98.042 (4456/4545)
4
Train Loss: 0.971 | Acc: 73.069 (3321/4545)
Train Loss: 0.192 | Acc: 93.487 (4249/4545)
5
Train Loss: 0.663 | Acc: 77.492 (3522/4545)
Train Loss: 0.203 | Acc: 92.651 (4211/4545)
6
Train Loss: 0.489 | Acc: 81.606 (3709/4545)
Train Loss: 0.077 | Acc: 97.250 (4420/4545)
7
Train Loss: 1.423 | Acc: 56.568 (2571/4545)
Train Loss: 0.336 | Acc: 86.513 (3932/4545)
8
Train Loss: 1.003 | Acc: 74.103 (3368/4545)
Train Loss: 0.055 | Acc: 98.306 (4468/4545)
9
Train Loss: 0.989 | Acc: 73.267 (3330/4545)
Train Loss: 0.086 | Acc: 97.778 (4444/4545)
10
Train Loss: 0.884 | Acc: 70.407 (3200/4545)
Train Loss: 0.261 | Acc: 90.099 (4095/4545)
1.conv1
layer3.1
layer4.0
layer2.1
layer1.1
layer3.0
layer4.1
linear
1.bn1
layer1.0
layer2.0
Test Loss: 4.389 | Acc: 11.570 (1157/10000)
mseloss[1]:0.8329270482063293, 0.9360895156860352, 1.32440185546875, 0.20144888758659363
mseloss[2]:0.8283993601799011, 0.9265867471694946, 1.082022786140442, 0.22882770001888275
mseloss[3]:0.8448584675788879, 0.9678280353546143, 1.3922690153121948, 0.26603934168815613
mseloss[4]:0.9204116463661194, 1.1137150526046753, 1.8798846006393433, 0.2660256326198578
mseloss[5]:0.8839228749275208, 1.0909713506698608, 1.769792914390564, 0.2728039622306824
mseloss[6]:0.8335158228874207, 0.8932064771652222, 1.0355955362319946, 0.22982417047023773
mseloss[7]:0.8586331605911255, 0.8558292388916016, 0.8542768955230713, 0.1844923198223114
mseloss[8]:0.8765661120414734, 0.941400945186615, 1.0212668180465698, 0.19956262409687042
mseloss[9]:0.8657578825950623, 1.099517583847046, 1.7211294174194336, 0.2773295044898987
Epoch:65
0
Train Loss: 1.063 | Acc: 73.091 (3322/4545)
Train Loss: 0.076 | Acc: 97.976 (4453/4545)
1
Train Loss: 0.222 | Acc: 92.893 (4222/4545)
Train Loss: 0.002 | Acc: 100.000 (4545/4545)
2
Train Loss: 1.048 | Acc: 70.385 (3199/4545)
Train Loss: 0.086 | Acc: 96.920 (4405/4545)
3
Train Loss: 0.858 | Acc: 75.512 (3432/4545)
Train Loss: 0.066 | Acc: 98.042 (4456/4545)
4
Train Loss: 1.078 | Acc: 71.771 (3262/4545)
Train Loss: 0.188 | Acc: 93.377 (4244/4545)
5
Train Loss: 0.929 | Acc: 75.446 (3429/4545)
Train Loss: 0.001 | Acc: 100.000 (4545/4545)
6
Train Loss: 0.737 | Acc: 75.754 (3443/4545)
Train Loss: 0.228 | Acc: 91.485 (4158/4545)
7
Train Loss: 0.317 | Acc: 88.119 (4005/4545)
Train Loss: 0.079 | Acc: 97.228 (4419/4545)
8
Train Loss: 0.515 | Acc: 82.024 (3728/4545)
Train Loss: 0.050 | Acc: 98.372 (4471/4545)
9
Train Loss: 0.720 | Acc: 70.407 (3200/4545)
Train Loss: 0.292 | Acc: 87.877 (3994/4545)
10
Train Loss: 1.122 | Acc: 69.109 (3141/4545)
Train Loss: 0.206 | Acc: 92.629 (4210/4545)
layer4.1
layer2.1
layer4.0
layer1.1
linear
layer3.0
1.bn1
1.conv1
layer3.1
layer2.0
layer1.0
Test Loss: 2.097 | Acc: 22.870 (2287/10000)
mseloss[1]:0.8459944128990173, 1.011277437210083, 1.6721502542495728, 0.2508719563484192
mseloss[2]:0.8496384620666504, 0.9415045380592346, 1.0702110528945923, 0.21153375506401062
mseloss[3]:0.8434516191482544, 0.9697376489639282, 1.23155677318573, 0.3265903890132904
mseloss[4]:0.8659924864768982, 0.814407229423523, 0.699932873249054, 0.1383046805858612
mseloss[5]:0.8496701717376709, 1.1104847192764282, 1.5148686170578003, 0.2626793682575226
mseloss[6]:0.8266577124595642, 0.8209986090660095, 0.7325904965400696, 0.1688765585422516
mseloss[7]:0.8533571362495422, 0.9879224300384521, 1.2874157428741455, 0.4405856430530548
mseloss[8]:0.835860013961792, 0.9971879124641418, 1.3344024419784546, 0.34945374727249146
mseloss[9]:0.8402590155601501, 0.9794858694076538, 1.0995302200317383, 0.33022236824035645
Epoch:66
0
Train Loss: 0.481 | Acc: 83.058 (3775/4545)
Train Loss: 0.043 | Acc: 98.592 (4481/4545)
1
Train Loss: 0.314 | Acc: 89.417 (4064/4545)
Train Loss: 0.070 | Acc: 97.866 (4448/4545)
2
Train Loss: 0.687 | Acc: 80.990 (3681/4545)
Train Loss: 0.001 | Acc: 100.000 (4545/4545)
3
Train Loss: 1.004 | Acc: 71.881 (3267/4545)
Train Loss: 0.202 | Acc: 93.135 (4233/4545)
4
Train Loss: 0.586 | Acc: 75.754 (3443/4545)
Train Loss: 0.267 | Acc: 89.241 (4056/4545)
5
Train Loss: 0.857 | Acc: 77.844 (3538/4545)
Train Loss: 0.069 | Acc: 97.866 (4448/4545)
6
Train Loss: 0.536 | Acc: 82.750 (3761/4545)
Train Loss: 0.001 | Acc: 100.000 (4545/4545)
7
Train Loss: 0.773 | Acc: 75.314 (3423/4545)
Train Loss: 0.211 | Acc: 92.123 (4187/4545)
8
Train Loss: 0.731 | Acc: 76.700 (3486/4545)
Train Loss: 0.169 | Acc: 93.839 (4265/4545)
9
Train Loss: 0.530 | Acc: 84.972 (3862/4545)
Train Loss: 0.048 | Acc: 98.460 (4475/4545)
10
Train Loss: 0.361 | Acc: 90.583 (4117/4545)
Train Loss: 0.080 | Acc: 97.030 (4410/4545)
layer3.0
layer3.1
layer2.1
layer2.0
linear
layer1.0
layer4.0
1.bn1
layer4.1
1.conv1
layer1.1
Test Loss: 2.553 | Acc: 13.740 (1374/10000)
mseloss[1]:0.8486282825469971, 0.9050997495651245, 0.8888533711433411, 0.43893343210220337
mseloss[2]:0.8482539653778076, 0.9073657989501953, 0.7008095383644104, 0.3193322718143463
mseloss[3]:0.8847984671592712, 1.091127634048462, 1.149187445640564, 0.40970778465270996
mseloss[4]:0.8806943893432617, 0.8642435073852539, 0.6121955513954163, 0.30321168899536133
mseloss[5]:0.845287024974823, 1.0526401996612549, 1.036333680152893, 0.3965977132320404
mseloss[6]:0.8743438720703125, 0.9643825888633728, 0.7960329651832581, 0.2952173054218292
mseloss[7]:0.8570006489753723, 0.9490992426872253, 0.9169005751609802, 0.35152021050453186
mseloss[8]:0.8900064826011658, 1.0218945741653442, 1.1386988162994385, 0.3957294821739197
mseloss[9]:0.8624783158302307, 0.8611165881156921, 0.7939373254776001, 0.3288789689540863
Epoch:67
0
Train Loss: 0.759 | Acc: 79.076 (3594/4545)
Train Loss: 0.001 | Acc: 100.000 (4545/4545)
1
Train Loss: 0.974 | Acc: 72.695 (3304/4545)
Train Loss: 0.171 | Acc: 94.037 (4274/4545)
2
Train Loss: 0.632 | Acc: 77.778 (3535/4545)
Train Loss: 0.070 | Acc: 97.316 (4423/4545)
3
Train Loss: 0.274 | Acc: 90.341 (4106/4545)
Train Loss: 0.037 | Acc: 98.812 (4491/4545)
4
Train Loss: 0.852 | Acc: 76.942 (3497/4545)
Train Loss: 0.221 | Acc: 91.859 (4175/4545)
5
Train Loss: 0.655 | Acc: 79.054 (3593/4545)
Train Loss: 0.080 | Acc: 96.876 (4403/4545)
6
Train Loss: 0.421 | Acc: 82.816 (3764/4545)
Train Loss: 0.269 | Acc: 88.801 (4036/4545)
7
Train Loss: 0.832 | Acc: 77.866 (3539/4545)
Train Loss: 0.071 | Acc: 97.954 (4452/4545)
8
Train Loss: 0.798 | Acc: 76.392 (3472/4545)
Train Loss: 0.177 | Acc: 93.729 (4260/4545)
9
Train Loss: 0.614 | Acc: 80.726 (3669/4545)
Train Loss: 0.002 | Acc: 100.000 (4545/4545)
10
Train Loss: 0.667 | Acc: 79.912 (3632/4545)
Train Loss: 0.058 | Acc: 98.064 (4457/4545)
layer3.1
layer1.1
layer4.0
layer1.0
layer2.1
linear
1.bn1
1.conv1
layer2.0
layer4.1
layer3.0
Test Loss: 2.831 | Acc: 18.700 (1870/10000)
mseloss[1]:0.8760007619857788, 1.1955639123916626, 1.1645234823226929, 0.35879576206207275
mseloss[2]:0.8336618542671204, 1.016554832458496, 0.8919559121131897, 0.28321588039398193
mseloss[3]:0.8309442400932312, 0.8030372262001038, 0.5122426748275757, 0.27853477001190186
mseloss[4]:0.854781985282898, 1.1742628812789917, 1.0907652378082275, 0.36225274205207825
mseloss[5]:0.8021550178527832, 0.9241321086883545, 0.8212769627571106, 0.2620486915111542
mseloss[6]:0.837799072265625, 0.8235220313072205, 0.59982830286026, 0.3739762008190155
mseloss[7]:0.8333498239517212, 1.2293647527694702, 1.0451490879058838, 0.3256356418132782
mseloss[8]:0.8610459566116333, 1.1610738039016724, 1.143751859664917, 0.3084697425365448
mseloss[9]:0.7993836998939514, 0.8675153255462646, 0.6813130378723145, 0.26752448081970215
Epoch:68
0
Train Loss: 1.035 | Acc: 71.353 (3243/4545)
Train Loss: 0.167 | Acc: 94.367 (4289/4545)
1
Train Loss: 1.187 | Acc: 60.990 (2772/4545)
Train Loss: 0.307 | Acc: 87.195 (3963/4545)
2
Train Loss: 0.651 | Acc: 80.660 (3666/4545)
Train Loss: 0.067 | Acc: 98.394 (4472/4545)
3
Train Loss: 0.534 | Acc: 85.061 (3866/4545)
Train Loss: 0.064 | Acc: 98.152 (4461/4545)
4
Train Loss: 0.587 | Acc: 79.274 (3603/4545)
Train Loss: 0.045 | Acc: 98.504 (4477/4545)
5
Train Loss: 0.229 | Acc: 93.311 (4241/4545)
Train Loss: 0.080 | Acc: 97.052 (4411/4545)
6
Train Loss: 0.769 | Acc: 73.289 (3331/4545)
Train Loss: 0.084 | Acc: 96.942 (4406/4545)
7
Train Loss: 0.708 | Acc: 77.514 (3523/4545)
Train Loss: 0.001 | Acc: 100.000 (4545/4545)
8
Train Loss: 1.265 | Acc: 63.366 (2880/4545)
Train Loss: 0.257 | Acc: 90.671 (4121/4545)
9
Train Loss: 0.716 | Acc: 78.284 (3558/4545)
Train Loss: 0.186 | Acc: 93.795 (4263/4545)
10
Train Loss: 0.491 | Acc: 82.640 (3756/4545)
Train Loss: 0.001 | Acc: 100.000 (4545/4545)
layer4.1
layer3.1
layer2.0
layer1.0
1.bn1
1.conv1
layer4.0
linear
layer1.1
layer2.1
layer3.0
Test Loss: 2.407 | Acc: 19.570 (1957/10000)
mseloss[1]:0.843036413192749, 1.1139127016067505, 0.7254763245582581, 0.31456097960472107
mseloss[2]:0.7937009334564209, 0.7031204104423523, 0.3081299364566803, 0.1533176153898239
mseloss[3]:0.8453027009963989, 1.1340676546096802, 0.7859579920768738, 0.306283563375473
mseloss[4]:0.8400580883026123, 1.193647027015686, 0.9231680631637573, 0.4073063135147095
mseloss[5]:0.8301754593849182, 1.0388301610946655, 0.7057209014892578, 0.24819685518741608
mseloss[6]:0.849957287311554, 1.1008009910583496, 0.815925121307373, 0.34247884154319763
mseloss[7]:0.8570368885993958, 1.3717982769012451, 1.0540742874145508, 0.2582020163536072
mseloss[8]:0.8246443867683411, 0.930932879447937, 0.5136834979057312, 0.18253323435783386
mseloss[9]:0.8377711176872253, 0.9028851985931396, 0.5365220904350281, 0.1372673660516739
Epoch:69
0
Train Loss: 0.063 | Acc: 99.824 (4537/4545)
Train Loss: 0.002 | Acc: 100.000 (4545/4545)
1
Train Loss: 0.930 | Acc: 71.243 (3238/4545)
Train Loss: 0.091 | Acc: 96.524 (4387/4545)
2
Train Loss: 0.499 | Acc: 82.640 (3756/4545)
Train Loss: 0.044 | Acc: 98.570 (4480/4545)
3
Train Loss: 0.850 | Acc: 76.634 (3483/4545)
Train Loss: 0.066 | Acc: 98.240 (4465/4545)
4
Train Loss: 0.716 | Acc: 78.284 (3558/4545)
Train Loss: 0.176 | Acc: 93.927 (4269/4545)
5
Train Loss: 1.041 | Acc: 63.036 (2865/4545)
Train Loss: 0.306 | Acc: 86.513 (3932/4545)
6
Train Loss: 0.940 | Acc: 70.297 (3195/4545)
Train Loss: 0.228 | Acc: 91.749 (4170/4545)
7
Train Loss: 0.738 | Acc: 78.416 (3564/4545)
Train Loss: 0.063 | Acc: 98.130 (4460/4545)
8
Train Loss: 0.432 | Acc: 85.963 (3907/4545)
Train Loss: 0.002 | Acc: 100.000 (4545/4545)
9
Train Loss: 0.909 | Acc: 72.563 (3298/4545)
Train Loss: 0.175 | Acc: 93.861 (4266/4545)
10
Train Loss: 0.612 | Acc: 78.658 (3575/4545)
Train Loss: 0.087 | Acc: 96.964 (4407/4545)
layer2.0
1.conv1
layer4.1
layer4.0
linear
layer3.1
layer1.0
layer3.0
1.bn1
layer1.1
layer2.1
Test Loss: 2.628 | Acc: 21.460 (2146/10000)
mseloss[1]:0.8006228804588318, 1.0452063083648682, 0.5990009307861328, 0.26222652196884155
mseloss[2]:0.8193540573120117, 0.962814450263977, 0.4818767309188843, 0.2927097976207733
mseloss[3]:0.8176407814025879, 1.4002302885055542, 0.7547901272773743, 0.3185141086578369
mseloss[4]:0.856417715549469, 1.309472918510437, 0.871845543384552, 0.29614534974098206
mseloss[5]:0.8073685169219971, 0.8550477027893066, 0.42011207342147827, 0.3084752857685089
mseloss[6]:0.8380393981933594, 1.3722478151321411, 0.708324670791626, 0.3236267566680908
mseloss[7]:0.7968453168869019, 1.16847562789917, 0.6862797737121582, 0.40206581354141235
mseloss[8]:0.7945184707641602, 0.8905420303344727, 0.46051692962646484, 0.21751418709754944
mseloss[9]:0.8406696319580078, 1.3360539674758911, 0.8423516154289246, 0.3080286681652069
Epoch:70
0
Train Loss: 0.384 | Acc: 86.161 (3916/4545)
Train Loss: 0.163 | Acc: 94.433 (4292/4545)
1
Train Loss: 0.389 | Acc: 87.437 (3974/4545)
Train Loss: 0.041 | Acc: 98.702 (4486/4545)
2
Train Loss: 0.673 | Acc: 76.722 (3487/4545)
Train Loss: 0.082 | Acc: 97.184 (4417/4545)
3
Train Loss: 0.859 | Acc: 74.873 (3403/4545)
Train Loss: 0.166 | Acc: 94.411 (4291/4545)
4
Train Loss: 0.313 | Acc: 91.375 (4153/4545)
Train Loss: 0.062 | Acc: 98.262 (4466/4545)
5
Train Loss: 0.793 | Acc: 76.590 (3481/4545)
Train Loss: 0.092 | Acc: 96.898 (4404/4545)
6
Train Loss: 0.806 | Acc: 76.832 (3492/4545)
Train Loss: 0.001 | Acc: 100.000 (4545/4545)
7
Train Loss: 0.640 | Acc: 80.968 (3680/4545)
Train Loss: 0.001 | Acc: 100.000 (4545/4545)
8
Train Loss: 1.185 | Acc: 66.315 (3014/4545)
Train Loss: 0.218 | Acc: 92.145 (4188/4545)
9
Train Loss: 0.783 | Acc: 68.075 (3094/4545)
Train Loss: 0.304 | Acc: 87.151 (3961/4545)
10
Train Loss: 0.339 | Acc: 89.835 (4083/4545)
Train Loss: 0.053 | Acc: 98.328 (4469/4545)
layer4.0
layer1.1
layer3.1
layer2.0
linear
1.conv1
layer4.1
layer1.0
layer3.0
1.bn1
layer2.1
Test Loss: 2.047 | Acc: 23.430 (2343/10000)
mseloss[1]:0.8556721806526184, 1.2377113103866577, 0.6731622219085693, 0.4060888886451721
mseloss[2]:0.870808482170105, 1.1976488828659058, 0.7234508991241455, 0.40925857424736023
mseloss[3]:0.8399311304092407, 0.8554111123085022, 0.3291264474391937, 0.13420815765857697
mseloss[4]:0.8377284407615662, 0.8297380805015564, 0.3487902581691742, 0.1696266531944275
mseloss[5]:0.8481605648994446, 1.0446531772613525, 0.61867755651474, 0.3141004741191864
mseloss[6]:0.8500075340270996, 1.34512197971344, 0.7419281005859375, 0.2592781186103821
mseloss[7]:0.8879555463790894, 1.4352951049804688, 0.7074732780456543, 0.35404539108276367
mseloss[8]:0.8352366089820862, 0.7641717791557312, 0.32460522651672363, 0.17291539907455444
mseloss[9]:0.8432831764221191, 1.293306589126587, 0.6446524262428284, 0.4986251890659332
Epoch:71
0
Train Loss: 0.772 | Acc: 70.099 (3186/4545)
Train Loss: 0.291 | Acc: 87.921 (3996/4545)
1
Train Loss: 0.316 | Acc: 89.967 (4089/4545)
Train Loss: 0.165 | Acc: 94.147 (4279/4545)
2
Train Loss: 0.347 | Acc: 89.197 (4054/4545)
Train Loss: 0.059 | Acc: 98.218 (4464/4545)
3
Train Loss: 1.078 | Acc: 71.067 (3230/4545)
Train Loss: 0.083 | Acc: 97.074 (4412/4545)
4
Train Loss: 1.180 | Acc: 66.491 (3022/4545)
Train Loss: 0.205 | Acc: 92.827 (4219/4545)
5
Train Loss: 0.723 | Acc: 75.600 (3436/4545)
Train Loss: 0.143 | Acc: 95.182 (4326/4545)
6
Train Loss: 0.873 | Acc: 75.688 (3440/4545)
Train Loss: 0.001 | Acc: 100.000 (4545/4545)
7
Train Loss: 0.624 | Acc: 80.902 (3677/4545)
Train Loss: 0.001 | Acc: 100.000 (4545/4545)
8
Train Loss: 0.880 | Acc: 73.399 (3336/4545)
Train Loss: 0.090 | Acc: 96.678 (4394/4545)
9
Train Loss: 0.437 | Acc: 84.862 (3857/4545)
Train Loss: 0.040 | Acc: 98.746 (4488/4545)
10
Train Loss: 0.296 | Acc: 91.287 (4149/4545)
Train Loss: 0.047 | Acc: 98.416 (4473/4545)
1.conv1
layer4.1
layer2.0
1.bn1
layer1.0
layer3.0
layer4.0
layer3.1
linear
layer2.1
layer1.1
Test Loss: 3.101 | Acc: 10.270 (1027/10000)
mseloss[1]:0.84386146068573, 1.2897922992706299, 0.5670920610427856, 0.44264546036720276
mseloss[2]:0.8209729194641113, 1.1023927927017212, 0.44920992851257324, 0.3942432105541229
mseloss[3]:0.8405542373657227, 1.066469430923462, 0.5648540258407593, 0.33166182041168213
mseloss[4]:0.8533107042312622, 1.3053138256072998, 0.547667920589447, 0.35664185881614685
mseloss[5]:0.8489058613777161, 1.148514747619629, 0.5363700985908508, 0.3838375210762024
mseloss[6]:0.8207095861434937, 0.7875442504882812, 0.4485425651073456, 0.3105469346046448
mseloss[7]:0.8405413031578064, 0.8578450083732605, 0.40087375044822693, 0.30623239278793335
mseloss[8]:0.8395045399665833, 1.0322438478469849, 0.5530959963798523, 0.2773379981517792
mseloss[9]:0.8391258716583252, 0.9071829915046692, 0.3584446310997009, 0.3194257318973541
Epoch:72
0
Train Loss: 0.657 | Acc: 77.690 (3531/4545)
Train Loss: 0.039 | Acc: 98.900 (4495/4545)
1
Train Loss: 0.182 | Acc: 94.697 (4304/4545)
Train Loss: 0.069 | Acc: 97.492 (4431/4545)
2
Train Loss: 0.713 | Acc: 76.766 (3489/4545)
Train Loss: 0.001 | Acc: 100.000 (4545/4545)
3
Train Loss: 1.080 | Acc: 69.923 (3178/4545)
Train Loss: 0.143 | Acc: 95.226 (4328/4545)
4
Train Loss: 0.455 | Acc: 84.422 (3837/4545)
Train Loss: 0.173 | Acc: 93.905 (4268/4545)
5
Train Loss: 0.924 | Acc: 69.439 (3156/4545)
Train Loss: 0.190 | Acc: 93.069 (4230/4545)
6
Train Loss: 1.224 | Acc: 61.012 (2773/4545)
Train Loss: 0.281 | Acc: 87.877 (3994/4545)
7
Train Loss: 0.430 | Acc: 85.149 (3870/4545)
Train Loss: 0.061 | Acc: 98.130 (4460/4545)
8
Train Loss: 0.628 | Acc: 78.834 (3583/4545)
Train Loss: 0.054 | Acc: 98.196 (4463/4545)
9
Train Loss: 0.566 | Acc: 79.670 (3621/4545)
Train Loss: 0.002 | Acc: 100.000 (4545/4545)
10
Train Loss: 0.844 | Acc: 73.245 (3329/4545)
Train Loss: 0.102 | Acc: 96.436 (4383/4545)
layer3.0
layer1.1
layer4.1
layer2.1
layer1.0
1.bn1
layer3.1
layer4.0
1.conv1
layer2.0
linear
Test Loss: 3.514 | Acc: 19.300 (1930/10000)
mseloss[1]:0.8095176815986633, 0.9059748649597168, 0.6235265731811523, 0.3262767493724823
mseloss[2]:0.8522316217422485, 1.0041075944900513, 0.5417373180389404, 0.3312132656574249
mseloss[3]:0.849113941192627, 1.2132675647735596, 0.7045566439628601, 0.361629843711853
mseloss[4]:0.8489366173744202, 1.1568291187286377, 0.7449310421943665, 0.3649848997592926
mseloss[5]:0.8201262354850769, 1.0995556116104126, 0.6620276570320129, 0.30649229884147644
mseloss[6]:0.8314594626426697, 0.8681174516677856, 0.4371660649776459, 0.2823525071144104
mseloss[7]:0.7929206490516663, 1.0352907180786133, 0.6193608045578003, 0.3243580162525177
mseloss[8]:0.8111916780471802, 0.8942622542381287, 0.599943220615387, 0.3807014524936676
mseloss[9]:0.8087051510810852, 0.8347520232200623, 0.43660059571266174, 0.2282230705022812
Epoch:73
0
Train Loss: 1.721 | Acc: 59.494 (2704/4545)
Train Loss: 0.150 | Acc: 94.851 (4311/4545)
1
Train Loss: 0.641 | Acc: 78.262 (3557/4545)
Train Loss: 0.000 | Acc: 100.000 (4545/4545)
2
Train Loss: 0.552 | Acc: 82.134 (3733/4545)
Train Loss: 0.037 | Acc: 98.790 (4490/4545)
3
Train Loss: 1.221 | Acc: 66.425 (3019/4545)
Train Loss: 0.201 | Acc: 92.805 (4218/4545)
4
Train Loss: 0.317 | Acc: 88.691 (4031/4545)
Train Loss: 0.040 | Acc: 98.592 (4481/4545)
5
Train Loss: 1.017 | Acc: 72.387 (3290/4545)
Train Loss: 0.167 | Acc: 94.191 (4281/4545)
6
Train Loss: 0.346 | Acc: 86.293 (3922/4545)
Train Loss: 0.074 | Acc: 97.096 (4413/4545)
7
Train Loss: 0.887 | Acc: 67.327 (3060/4545)
Train Loss: 0.285 | Acc: 88.097 (4004/4545)
8
Train Loss: 0.335 | Acc: 89.219 (4055/4545)
Train Loss: 0.089 | Acc: 96.766 (4398/4545)
9
Train Loss: 0.751 | Acc: 77.272 (3512/4545)
Train Loss: 0.057 | Acc: 98.196 (4463/4545)
10
Train Loss: 0.765 | Acc: 74.499 (3386/4545)
Train Loss: 0.001 | Acc: 100.000 (4545/4545)
layer1.0
layer1.1
layer3.0
layer2.1
1.bn1
1.conv1
linear
layer3.1
layer4.1
layer4.0
layer2.0
Test Loss: 3.422 | Acc: 14.680 (1468/10000)
mseloss[1]:0.8413859605789185, 1.2939144372940063, 0.686107337474823, 0.32632574439048767
mseloss[2]:0.8379721641540527, 1.2075129747390747, 0.6330189108848572, 0.3663647770881653
mseloss[3]:0.8236189484596252, 0.9062111973762512, 0.3481791615486145, 0.16127273440361023
mseloss[4]:0.8345026969909668, 1.1443771123886108, 0.5478110909461975, 0.36478254199028015
mseloss[5]:0.82268226146698, 0.8403344750404358, 0.32482871413230896, 0.14004187285900116
mseloss[6]:0.8350487351417542, 1.0834282636642456, 0.5821018815040588, 0.43895223736763
mseloss[7]:0.8247514963150024, 1.1309443712234497, 0.4771215319633484, 0.37914159893989563
mseloss[8]:0.8383306860923767, 1.1166616678237915, 0.563969075679779, 0.31298840045928955
mseloss[9]:0.7921540141105652, 0.6571711897850037, 0.27911263704299927, 0.18338435888290405
Epoch:74
0
Train Loss: 1.121 | Acc: 62.574 (2844/4545)
Train Loss: 0.290 | Acc: 87.877 (3994/4545)
1
Train Loss: 0.280 | Acc: 89.769 (4080/4545)
Train Loss: 0.077 | Acc: 96.854 (4402/4545)
2
Train Loss: 0.893 | Acc: 71.661 (3257/4545)
Train Loss: 0.037 | Acc: 98.856 (4493/4545)
3
Train Loss: 0.378 | Acc: 84.334 (3833/4545)
Train Loss: 0.055 | Acc: 98.460 (4475/4545)
4
Train Loss: 0.768 | Acc: 74.477 (3385/4545)
Train Loss: 0.001 | Acc: 100.000 (4545/4545)
5
Train Loss: 1.027 | Acc: 68.559 (3116/4545)
Train Loss: 0.132 | Acc: 95.710 (4350/4545)
6
Train Loss: 0.910 | Acc: 71.067 (3230/4545)
Train Loss: 0.095 | Acc: 96.612 (4391/4545)
7
Train Loss: 0.965 | Acc: 72.277 (3285/4545)
Train Loss: 0.002 | Acc: 100.000 (4545/4545)
8
Train Loss: 0.361 | Acc: 86.623 (3937/4545)
Train Loss: 0.042 | Acc: 98.746 (4488/4545)
9
Train Loss: 0.532 | Acc: 82.530 (3751/4545)
Train Loss: 0.156 | Acc: 94.257 (4284/4545)
10
Train Loss: 1.095 | Acc: 67.635 (3074/4545)
Train Loss: 0.196 | Acc: 93.223 (4237/4545)
linear
1.conv1
1.bn1
layer4.0
layer2.1
layer3.0
layer1.1
layer2.0
layer4.1
layer1.0
layer3.1
Test Loss: 3.811 | Acc: 13.290 (1329/10000)
mseloss[1]:0.8252604603767395, 0.9422745704650879, 0.3307831883430481, 0.2677009105682373
mseloss[2]:0.8269010186195374, 0.9931967854499817, 0.35597285628318787, 0.23687459528446198
mseloss[3]:0.8010431528091431, 1.218809723854065, 0.4290492832660675, 0.30054357647895813
mseloss[4]:0.8150210976600647, 0.8348901271820068, 0.3482834994792938, 0.25737348198890686
mseloss[5]:0.8272435069084167, 1.1892517805099487, 0.4142356216907501, 0.23809914290905
mseloss[6]:0.829465925693512, 1.1358160972595215, 0.5285482406616211, 0.3125689923763275
mseloss[7]:0.8039075136184692, 0.8638790249824524, 0.38344573974609375, 0.2528260052204132
mseloss[8]:0.8198888897895813, 0.9709783792495728, 0.32697924971580505, 0.2510744631290436
mseloss[9]:0.8268713355064392, 1.4112509489059448, 0.5860880017280579, 0.31988686323165894
Epoch:75
0
Train Loss: 0.513 | Acc: 79.802 (3627/4545)
Train Loss: 0.280 | Acc: 88.405 (4018/4545)
1
Train Loss: 0.562 | Acc: 80.374 (3653/4545)
Train Loss: 0.155 | Acc: 94.477 (4294/4545)
2
Train Loss: 0.367 | Acc: 86.425 (3928/4545)
Train Loss: 0.037 | Acc: 98.966 (4498/4545)
3
Train Loss: 0.678 | Acc: 79.692 (3622/4545)
Train Loss: 0.198 | Acc: 92.849 (4220/4545)
4
Train Loss: 0.739 | Acc: 74.939 (3406/4545)
Train Loss: 0.090 | Acc: 96.964 (4407/4545)
5
Train Loss: 0.792 | Acc: 74.015 (3364/4545)
Train Loss: 0.133 | Acc: 95.776 (4353/4545)
6
Train Loss: 0.654 | Acc: 79.560 (3616/4545)
Train Loss: 0.003 | Acc: 100.000 (4545/4545)
7
Train Loss: 0.607 | Acc: 80.154 (3643/4545)
Train Loss: 0.048 | Acc: 98.438 (4474/4545)
8
Train Loss: 0.399 | Acc: 87.657 (3984/4545)
Train Loss: 0.060 | Acc: 98.152 (4461/4545)
9
Train Loss: 1.153 | Acc: 69.879 (3176/4545)
Train Loss: 0.003 | Acc: 100.000 (4545/4545)
10
Train Loss: 0.607 | Acc: 78.570 (3571/4545)
Train Loss: 0.081 | Acc: 96.920 (4405/4545)
layer2.0
layer1.0
layer3.1
linear
layer3.0
layer1.1
1.conv1
layer4.0
1.bn1
layer4.1
layer2.1
Test Loss: 3.217 | Acc: 18.010 (1801/10000)
mseloss[1]:0.826747715473175, 1.4339929819107056, 0.6898368000984192, 0.37390273809432983
mseloss[2]:0.82423996925354, 1.0162086486816406, 0.38062021136283875, 0.2722134590148926
mseloss[3]:0.8407962322235107, 1.5058207511901855, 0.6021125912666321, 0.3110677897930145
mseloss[4]:0.8273391723632812, 1.1456034183502197, 0.5703514218330383, 0.3459777534008026
mseloss[5]:0.8277053833007812, 1.2253152132034302, 0.5026834607124329, 0.29386135935783386
mseloss[6]:0.8376885056495667, 0.8824188709259033, 0.48565903306007385, 0.33615633845329285
mseloss[7]:0.8203495144844055, 1.0104495286941528, 0.3798193633556366, 0.2598068416118622
mseloss[8]:0.8036483526229858, 1.2593449354171753, 0.5178582072257996, 0.3458503782749176
mseloss[9]:0.8133561611175537, 0.909600019454956, 0.44865909218788147, 0.3037430942058563
Epoch:76
0
Train Loss: 0.700 | Acc: 78.218 (3555/4545)
Train Loss: 0.004 | Acc: 100.000 (4545/4545)
1
Train Loss: 0.753 | Acc: 73.333 (3333/4545)
Train Loss: 0.205 | Acc: 92.409 (4200/4545)
2
Train Loss: 0.500 | Acc: 83.542 (3797/4545)
Train Loss: 0.089 | Acc: 96.876 (4403/4545)
3
Train Loss: 0.872 | Acc: 77.074 (3503/4545)
Train Loss: 0.150 | Acc: 94.807 (4309/4545)
4
Train Loss: 1.101 | Acc: 69.615 (3164/4545)
Train Loss: 0.167 | Acc: 94.125 (4278/4545)
5
Train Loss: 0.692 | Acc: 74.587 (3390/4545)
Train Loss: 0.275 | Acc: 88.361 (4016/4545)
6
Train Loss: 0.630 | Acc: 79.648 (3620/4545)
Train Loss: 0.046 | Acc: 98.724 (4487/4545)
7
Train Loss: 0.536 | Acc: 82.046 (3729/4545)
Train Loss: 0.001 | Acc: 100.000 (4545/4545)
8
Train Loss: 0.939 | Acc: 74.191 (3372/4545)
Train Loss: 0.074 | Acc: 97.844 (4447/4545)
9
Train Loss: 0.610 | Acc: 81.166 (3689/4545)
Train Loss: 0.053 | Acc: 98.504 (4477/4545)
10
Train Loss: 0.366 | Acc: 88.779 (4035/4545)
Train Loss: 0.086 | Acc: 96.832 (4401/4545)
layer1.0
1.bn1
layer1.1
layer4.1
layer4.0
layer3.1
layer2.0
layer2.1
linear
layer3.0
1.conv1
Test Loss: 3.218 | Acc: 13.320 (1332/10000)
mseloss[1]:0.8261172771453857, 1.3214774131774902, 0.7890684604644775, 0.26572689414024353
mseloss[2]:0.8042395710945129, 1.052067518234253, 0.7529035210609436, 0.21753615140914917
mseloss[3]:0.8384721875190735, 1.3790987730026245, 0.8963489532470703, 0.27066168189048767
mseloss[4]:0.827181875705719, 1.2740837335586548, 1.0058029890060425, 0.26500317454338074
mseloss[5]:0.8119326829910278, 0.8683716058731079, 0.4398828446865082, 0.26764819025993347
mseloss[6]:0.7980427742004395, 0.8028503656387329, 0.3972632884979248, 0.19612650573253632
mseloss[7]:0.8072008490562439, 0.945580005645752, 0.5716692805290222, 0.19929304718971252
mseloss[8]:0.8175687193870544, 1.362626075744629, 0.8428459167480469, 0.26006436347961426
mseloss[9]:0.798362135887146, 0.93680340051651, 0.5514474511146545, 0.2547943890094757
Epoch:77
0
Train Loss: 0.762 | Acc: 74.565 (3389/4545)
Train Loss: 0.089 | Acc: 96.986 (4408/4545)
1
Train Loss: 0.797 | Acc: 70.913 (3223/4545)
Train Loss: 0.273 | Acc: 88.867 (4039/4545)
2
Train Loss: 0.762 | Acc: 75.820 (3446/4545)
Train Loss: 0.157 | Acc: 94.389 (4290/4545)
3
Train Loss: 0.820 | Acc: 73.509 (3341/4545)
Train Loss: 0.042 | Acc: 98.746 (4488/4545)
4
Train Loss: 0.367 | Acc: 89.857 (4084/4545)
Train Loss: 0.044 | Acc: 98.702 (4486/4545)
5
Train Loss: 0.737 | Acc: 74.609 (3391/4545)
Train Loss: 0.153 | Acc: 94.477 (4294/4545)
6
Train Loss: 0.548 | Acc: 80.044 (3638/4545)
Train Loss: 0.207 | Acc: 92.035 (4183/4545)
7
Train Loss: 0.340 | Acc: 90.033 (4092/4545)
Train Loss: 0.059 | Acc: 98.196 (4463/4545)
8
Train Loss: 0.557 | Acc: 80.242 (3647/4545)
Train Loss: 0.081 | Acc: 96.920 (4405/4545)
9
Train Loss: 1.161 | Acc: 69.219 (3146/4545)
Train Loss: 0.003 | Acc: 100.000 (4545/4545)
10
Train Loss: 0.391 | Acc: 86.469 (3930/4545)
Train Loss: 0.001 | Acc: 100.000 (4545/4545)
layer1.1
linear
layer3.1
layer4.1
layer2.1
layer3.0
1.bn1
layer2.0
1.conv1
layer1.0
layer4.0
Test Loss: 4.178 | Acc: 14.450 (1445/10000)
mseloss[1]:0.832594633102417, 0.9298704266548157, 0.49522387981414795, 0.28373533487319946
mseloss[2]:0.8225582242012024, 0.966412365436554, 0.6140131950378418, 0.34807464480400085
mseloss[3]:0.8062352538108826, 0.9526669383049011, 0.5595577359199524, 0.32087182998657227
mseloss[4]:0.8215493559837341, 0.9601761698722839, 0.6020928025245667, 0.30889642238616943
mseloss[5]:0.8356249332427979, 1.0560448169708252, 0.5848388671875, 0.33067798614501953
mseloss[6]:0.8318967223167419, 0.9613409042358398, 0.5349007248878479, 0.3278147280216217
mseloss[7]:0.8226900696754456, 1.0177762508392334, 0.5482918620109558, 0.3133130669593811
mseloss[8]:0.7982432842254639, 0.8524012565612793, 0.5465076565742493, 0.2606593370437622
mseloss[9]:0.8012070655822754, 0.9290380477905273, 0.5855688452720642, 0.2158806174993515
Epoch:78
0
Train Loss: 0.386 | Acc: 85.765 (3898/4545)
Train Loss: 0.002 | Acc: 100.000 (4545/4545)
1
Train Loss: 0.745 | Acc: 78.394 (3563/4545)
Train Loss: 0.048 | Acc: 98.438 (4474/4545)
2
Train Loss: 0.573 | Acc: 80.088 (3640/4545)
Train Loss: 0.075 | Acc: 97.184 (4417/4545)
3
Train Loss: 0.588 | Acc: 76.304 (3468/4545)
Train Loss: 0.273 | Acc: 88.603 (4027/4545)
4
Train Loss: 0.567 | Acc: 80.572 (3662/4545)
Train Loss: 0.158 | Acc: 94.477 (4294/4545)
5
Train Loss: 0.426 | Acc: 85.523 (3887/4545)
Train Loss: 0.066 | Acc: 98.218 (4464/4545)
6
Train Loss: 0.589 | Acc: 79.714 (3623/4545)
Train Loss: 0.040 | Acc: 98.900 (4495/4545)
7
Train Loss: 0.741 | Acc: 75.028 (3410/4545)
Train Loss: 0.162 | Acc: 94.499 (4295/4545)
8
Train Loss: 1.093 | Acc: 66.843 (3038/4545)
Train Loss: 0.109 | Acc: 96.436 (4383/4545)
9
Train Loss: 0.691 | Acc: 73.949 (3361/4545)
Train Loss: 0.223 | Acc: 91.749 (4170/4545)
10
Train Loss: 1.292 | Acc: 65.501 (2977/4545)
Train Loss: 0.006 | Acc: 100.000 (4545/4545)
1.bn1
layer1.1
layer2.0
1.conv1
layer3.1
layer1.0
layer4.1
layer3.0
layer4.0
linear
layer2.1
Test Loss: 3.485 | Acc: 16.670 (1667/10000)
mseloss[1]:0.8125749230384827, 1.023102045059204, 0.716000497341156, 0.3080118000507355
mseloss[2]:0.8039280772209167, 0.9720604419708252, 0.6085404753684998, 0.23699115216732025
mseloss[3]:0.8246598243713379, 0.7944172024726868, 0.5299274325370789, 0.28967592120170593
mseloss[4]:0.8686738014221191, 1.2229355573654175, 0.894342303276062, 0.3377971649169922
mseloss[5]:0.836423933506012, 1.1679176092147827, 0.8317121267318726, 0.34574416279792786
mseloss[6]:0.8397217988967896, 0.8849112391471863, 0.5574937462806702, 0.23584479093551636
mseloss[7]:0.8583618402481079, 1.205183982849121, 0.8174170255661011, 0.3307186961174011
mseloss[8]:0.8114197850227356, 0.8803316354751587, 0.5712389349937439, 0.20948973298072815
mseloss[9]:0.8643313050270081, 1.1858106851577759, 0.7862917184829712, 0.32852107286453247
Epoch:79
0
Train Loss: 0.718 | Acc: 70.759 (3216/4545)
Train Loss: 0.273 | Acc: 88.801 (4036/4545)
1
Train Loss: 0.468 | Acc: 87.657 (3984/4545)
Train Loss: 0.104 | Acc: 96.744 (4397/4545)
2
Train Loss: 0.891 | Acc: 70.319 (3196/4545)
Train Loss: 0.072 | Acc: 97.294 (4422/4545)
3
Train Loss: 0.833 | Acc: 74.235 (3374/4545)
Train Loss: 0.007 | Acc: 100.000 (4545/4545)
4
Train Loss: 0.675 | Acc: 77.470 (3521/4545)
Train Loss: 0.170 | Acc: 94.279 (4285/4545)
5
Train Loss: 0.888 | Acc: 72.607 (3300/4545)
Train Loss: 0.004 | Acc: 100.000 (4545/4545)
6
Train Loss: 0.593 | Acc: 80.946 (3679/4545)
Train Loss: 0.160 | Acc: 94.653 (4302/4545)
7
Train Loss: 1.297 | Acc: 63.916 (2905/4545)
Train Loss: 0.059 | Acc: 98.262 (4466/4545)
8
Train Loss: 0.581 | Acc: 84.840 (3856/4545)
Train Loss: 0.072 | Acc: 98.042 (4456/4545)
9
Train Loss: 0.736 | Acc: 75.644 (3438/4545)
Train Loss: 0.045 | Acc: 98.768 (4489/4545)
10
Train Loss: 0.587 | Acc: 79.362 (3607/4545)
Train Loss: 0.229 | Acc: 91.727 (4169/4545)
layer4.0
layer2.1
layer1.1
layer2.0
layer1.0
linear
layer4.1
1.conv1
layer3.0
1.bn1
layer3.1
Test Loss: 3.106 | Acc: 22.030 (2203/10000)
mseloss[1]:0.8293551802635193, 0.8149381875991821, 0.5387060046195984, 0.31762948632240295
mseloss[2]:0.8219801783561707, 0.7499118447303772, 0.4613889753818512, 0.2961540222167969
mseloss[3]:0.7934005260467529, 0.6933760643005371, 0.44663307070732117, 0.3292788863182068
mseloss[4]:0.830405056476593, 0.981041669845581, 0.7798169851303101, 0.4175158441066742
mseloss[5]:0.8195226192474365, 0.7522832155227661, 0.5288054347038269, 0.338887482881546
mseloss[6]:0.8377364277839661, 0.9142410159111023, 0.6083288192749023, 0.35579633712768555
mseloss[7]:0.821351170539856, 0.7725921869277954, 0.4749603867530823, 0.3128476142883301
mseloss[8]:0.8001569509506226, 0.8439692854881287, 0.5966789722442627, 0.35416871309280396
mseloss[9]:0.832625150680542, 0.7564687728881836, 0.4509676694869995, 0.29097551107406616
Epoch:80
0
Train Loss: 0.468 | Acc: 86.227 (3919/4545)
Train Loss: 0.069 | Acc: 98.152 (4461/4545)
1
Train Loss: 1.622 | Acc: 62.464 (2839/4545)
Train Loss: 0.009 | Acc: 100.000 (4545/4545)
2
Train Loss: 0.781 | Acc: 73.311 (3332/4545)
Train Loss: 0.048 | Acc: 98.856 (4493/4545)
3
Train Loss: 1.011 | Acc: 72.343 (3288/4545)
Train Loss: 0.057 | Acc: 98.350 (4470/4545)
4
Train Loss: 0.445 | Acc: 87.789 (3990/4545)
Train Loss: 0.164 | Acc: 94.675 (4303/4545)
5
Train Loss: 0.381 | Acc: 88.031 (4001/4545)
Train Loss: 0.003 | Acc: 100.000 (4545/4545)
6
Train Loss: 0.827 | Acc: 67.063 (3048/4545)
Train Loss: 0.273 | Acc: 88.581 (4026/4545)
7
Train Loss: 1.592 | Acc: 58.306 (2650/4545)
Train Loss: 0.087 | Acc: 97.030 (4410/4545)
8
Train Loss: 0.908 | Acc: 71.111 (3232/4545)
Train Loss: 0.169 | Acc: 94.235 (4283/4545)
9
Train Loss: 0.560 | Acc: 80.836 (3674/4545)
Train Loss: 0.230 | Acc: 91.485 (4158/4545)
10
Train Loss: 1.874 | Acc: 52.277 (2376/4545)
Train Loss: 0.130 | Acc: 95.908 (4359/4545)
1.bn1
layer3.1
linear
layer2.1
layer2.0
layer1.1
layer3.0
layer4.1
1.conv1
layer4.0
layer1.0
Test Loss: 3.622 | Acc: 15.020 (1502/10000)
mseloss[1]:0.7975914478302002, 1.022154688835144, 0.7697837948799133, 0.26987627148628235
mseloss[2]:0.7884759306907654, 0.954988956451416, 0.5980508327484131, 0.31142061948776245
mseloss[3]:0.7953017950057983, 0.8861994743347168, 0.5287052989006042, 0.317947119474411
mseloss[4]:0.8014670014381409, 0.7035126686096191, 0.36651429533958435, 0.20227955281734467
mseloss[5]:0.8215348720550537, 1.1069847345352173, 0.8162230253219604, 0.35733622312545776
mseloss[6]:0.7865319848060608, 0.8880952000617981, 0.49178582429885864, 0.3534291684627533
mseloss[7]:0.8041073679924011, 0.8606685400009155, 0.572693407535553, 0.27942267060279846
mseloss[8]:0.7814819812774658, 0.617330014705658, 0.2818486988544464, 0.17614507675170898
mseloss[9]:0.7807446718215942, 0.7164487838745117, 0.36311525106430054, 0.2280730903148651
Epoch:81
0
Train Loss: 1.594 | Acc: 58.834 (2674/4545)
Train Loss: 0.013 | Acc: 100.000 (4545/4545)
1
Train Loss: 0.792 | Acc: 76.084 (3458/4545)
Train Loss: 0.159 | Acc: 94.719 (4305/4545)
2
Train Loss: 0.533 | Acc: 80.330 (3651/4545)
Train Loss: 0.223 | Acc: 91.881 (4176/4545)
3
Train Loss: 0.497 | Acc: 84.004 (3818/4545)
Train Loss: 0.143 | Acc: 95.820 (4355/4545)
4
Train Loss: 2.102 | Acc: 49.967 (2271/4545)
Train Loss: 0.094 | Acc: 96.590 (4390/4545)
5
Train Loss: 1.309 | Acc: 61.496 (2795/4545)
Train Loss: 0.135 | Acc: 95.820 (4355/4545)
6
Train Loss: 1.384 | Acc: 61.342 (2788/4545)
Train Loss: 0.058 | Acc: 98.416 (4473/4545)
7
Train Loss: 0.635 | Acc: 75.094 (3413/4545)
Train Loss: 0.050 | Acc: 98.658 (4484/4545)
8
Train Loss: 1.251 | Acc: 64.884 (2949/4545)
Train Loss: 0.006 | Acc: 100.000 (4545/4545)
9
Train Loss: 0.952 | Acc: 68.119 (3096/4545)
Train Loss: 0.082 | Acc: 97.756 (4443/4545)
10
Train Loss: 0.736 | Acc: 70.253 (3193/4545)
Train Loss: 0.271 | Acc: 88.977 (4044/4545)
layer3.0
layer4.1
1.conv1
layer1.0
1.bn1
layer4.0
linear
layer1.1
layer2.0
layer3.1
layer2.1
Test Loss: 2.205 | Acc: 24.190 (2419/10000)
mseloss[1]:0.8192305564880371, 1.062325358390808, 0.9750359058380127, 0.2566365897655487
mseloss[2]:0.8103475570678711, 1.1197383403778076, 0.9166355729103088, 0.33074474334716797
mseloss[3]:0.8305679559707642, 1.1467459201812744, 0.9220280647277832, 0.2719564735889435
mseloss[4]:0.7644740343093872, 0.8275877237319946, 0.6287962794303894, 0.2402428537607193
mseloss[5]:0.7935482263565063, 0.8989726901054382, 0.797178328037262, 0.17363105714321136
mseloss[6]:0.786417543888092, 0.8067345023155212, 0.5454583764076233, 0.2498830109834671
mseloss[7]:0.7893241047859192, 0.6857441067695618, 0.33581286668777466, 0.18174506723880768
mseloss[8]:0.8075805902481079, 0.8761845231056213, 0.6479480266571045, 0.21072953939437866
mseloss[9]:0.8049786686897278, 1.111006259918213, 0.8812218904495239, 0.28667473793029785
Epoch:82
0
Train Loss: 0.907 | Acc: 71.111 (3232/4545)
Train Loss: 0.147 | Acc: 95.820 (4355/4545)
1
Train Loss: 0.838 | Acc: 69.681 (3167/4545)
Train Loss: 0.003 | Acc: 100.000 (4545/4545)
2
Train Loss: 0.510 | Acc: 84.224 (3828/4545)
Train Loss: 0.051 | Acc: 98.702 (4486/4545)
3
Train Loss: 0.733 | Acc: 76.810 (3491/4545)
Train Loss: 0.016 | Acc: 100.000 (4545/4545)
4
Train Loss: 0.944 | Acc: 68.163 (3098/4545)
Train Loss: 0.089 | Acc: 96.546 (4388/4545)
5
Train Loss: 0.622 | Acc: 77.558 (3525/4545)
Train Loss: 0.055 | Acc: 98.482 (4476/4545)
6
Train Loss: 1.244 | Acc: 59.912 (2723/4545)
Train Loss: 0.246 | Acc: 91.155 (4143/4545)
7
Train Loss: 0.557 | Acc: 84.400 (3836/4545)
Train Loss: 0.072 | Acc: 97.844 (4447/4545)
8
Train Loss: 0.632 | Acc: 81.232 (3692/4545)
Train Loss: 0.129 | Acc: 96.216 (4373/4545)
9
Train Loss: 1.123 | Acc: 59.648 (2711/4545)
Train Loss: 0.298 | Acc: 87.987 (3999/4545)
10
Train Loss: 1.038 | Acc: 68.427 (3110/4545)
Train Loss: 0.168 | Acc: 94.521 (4296/4545)
layer2.1
layer4.1
linear
1.conv1
layer1.0
layer2.0
layer3.0
layer1.1
1.bn1
layer3.1
layer4.0
Test Loss: 2.543 | Acc: 17.830 (1783/10000)
mseloss[1]:0.8560404777526855, 1.2426841259002686, 1.027909278869629, 0.3201032876968384
mseloss[2]:0.8321482539176941, 1.017061710357666, 0.6677825450897217, 0.2730709910392761
mseloss[3]:0.8308271169662476, 1.1878485679626465, 1.0463300943374634, 0.2824349105358124
mseloss[4]:0.8184174299240112, 0.9512140154838562, 0.6694433093070984, 0.32557976245880127
mseloss[5]:0.8331512212753296, 1.1050424575805664, 0.8680922389030457, 0.33325228095054626
mseloss[6]:0.8148887157440186, 0.816318929195404, 0.4187813401222229, 0.15780149400234222
mseloss[7]:0.7881029844284058, 0.6119318604469299, 0.2730258107185364, 0.13778339326381683
mseloss[8]:0.832818329334259, 1.0018954277038574, 0.7784541249275208, 0.2831019461154938
mseloss[9]:0.8292663097381592, 1.0294536352157593, 0.6706741452217102, 0.30244025588035583
Epoch:83
0
Train Loss: 1.226 | Acc: 64.004 (2909/4545)
Train Loss: 0.085 | Acc: 96.832 (4401/4545)
1
Train Loss: 1.167 | Acc: 65.479 (2976/4545)
Train Loss: 0.122 | Acc: 96.282 (4376/4545)
2
Train Loss: 0.364 | Acc: 90.671 (4121/4545)
Train Loss: 0.155 | Acc: 94.785 (4308/4545)
3
Train Loss: 0.519 | Acc: 81.430 (3701/4545)
Train Loss: 0.141 | Acc: 95.798 (4354/4545)
4
Train Loss: 0.904 | Acc: 68.207 (3100/4545)
Train Loss: 0.051 | Acc: 98.636 (4483/4545)
5
Train Loss: 0.887 | Acc: 67.789 (3081/4545)
Train Loss: 0.228 | Acc: 91.991 (4181/4545)
6
Train Loss: 1.040 | Acc: 62.024 (2819/4545)
Train Loss: 0.281 | Acc: 88.647 (4029/4545)
7
Train Loss: 0.801 | Acc: 71.529 (3251/4545)
Train Loss: 0.048 | Acc: 98.856 (4493/4545)
8
Train Loss: 0.784 | Acc: 73.047 (3320/4545)
Train Loss: 0.006 | Acc: 100.000 (4545/4545)
9
Train Loss: 0.518 | Acc: 84.378 (3835/4545)
Train Loss: 0.068 | Acc: 98.262 (4466/4545)
10
Train Loss: 2.186 | Acc: 48.053 (2184/4545)
Train Loss: 0.022 | Acc: 100.000 (4545/4545)
1.conv1
layer1.0
layer2.1
layer3.1
linear
layer3.0
layer4.1
layer2.0
layer4.0
1.bn1
layer1.1
Test Loss: 4.504 | Acc: 17.020 (1702/10000)
mseloss[1]:0.7966084480285645, 0.859077513217926, 0.7068148255348206, 0.2634616792201996
mseloss[2]:0.8496842980384827, 1.0218721628189087, 0.8409774899482727, 0.3265221118927002
mseloss[3]:0.8199275732040405, 0.9113945960998535, 0.600125253200531, 0.2912004888057709
mseloss[4]:0.8082911372184753, 0.7355989813804626, 0.4247142970561981, 0.25244617462158203
mseloss[5]:0.814764678478241, 1.0385366678237915, 0.7369210124015808, 0.3044874966144562
mseloss[6]:0.8202406764030457, 0.7982906699180603, 0.45960599184036255, 0.2526995837688446
mseloss[7]:0.802696943283081, 0.8725749850273132, 0.5783558487892151, 0.2865457236766815
mseloss[8]:0.8021723628044128, 0.993066668510437, 0.6422561407089233, 0.2782800793647766
mseloss[9]:0.8204612731933594, 0.8769734501838684, 0.4941321015357971, 0.266256183385849
Epoch:84
0
Train Loss: 1.410 | Acc: 57.228 (2601/4545)
Train Loss: 0.136 | Acc: 96.238 (4374/4545)
1
Train Loss: 0.959 | Acc: 68.229 (3101/4545)
Train Loss: 0.053 | Acc: 98.834 (4492/4545)
2
Train Loss: 0.726 | Acc: 76.502 (3477/4545)
Train Loss: 0.228 | Acc: 92.123 (4187/4545)
3
Train Loss: 0.436 | Acc: 90.715 (4123/4545)
Train Loss: 0.162 | Acc: 94.521 (4296/4545)
4
Train Loss: 2.178 | Acc: 47.459 (2157/4545)
Train Loss: 0.029 | Acc: 100.000 (4545/4545)
5
Train Loss: 0.432 | Acc: 88.889 (4040/4545)
Train Loss: 0.007 | Acc: 100.000 (4545/4545)
6
Train Loss: 0.928 | Acc: 65.039 (2956/4545)
Train Loss: 0.091 | Acc: 96.898 (4404/4545)
7
Train Loss: 0.691 | Acc: 74.521 (3387/4545)
Train Loss: 0.051 | Acc: 98.416 (4473/4545)
8
Train Loss: 0.541 | Acc: 84.994 (3863/4545)
Train Loss: 0.076 | Acc: 98.130 (4460/4545)
9
Train Loss: 0.983 | Acc: 62.618 (2846/4545)
Train Loss: 0.291 | Acc: 87.987 (3999/4545)
10
Train Loss: 0.883 | Acc: 71.661 (3257/4545)
Train Loss: 0.181 | Acc: 95.006 (4318/4545)
layer2.0
layer4.0
1.conv1
layer3.0
linear
layer1.0
layer4.1
1.bn1
layer3.1
layer2.1
layer1.1
Test Loss: 2.904 | Acc: 25.070 (2507/10000)
mseloss[1]:0.7921473979949951, 0.9139229655265808, 0.7346859574317932, 0.3111570477485657
mseloss[2]:0.818937361240387, 0.9255605936050415, 0.6637685298919678, 0.29085496068000793
mseloss[3]:0.8097102642059326, 0.8496537208557129, 0.6485961675643921, 0.25060150027275085
mseloss[4]:0.7877905368804932, 0.8979002237319946, 0.7476144433021545, 0.17761191725730896
mseloss[5]:0.7868977189064026, 0.8484150171279907, 0.6189597845077515, 0.29474008083343506
mseloss[6]:0.787971019744873, 0.834617018699646, 0.7029133439064026, 0.2709724009037018
mseloss[7]:0.8068789839744568, 0.8552377223968506, 0.6938028931617737, 0.24348725378513336
mseloss[8]:0.8108715415000916, 0.9120770692825317, 0.6900047063827515, 0.26489755511283875
mseloss[9]:0.8110547065734863, 0.8915089964866638, 0.6150375604629517, 0.3467838764190674
Epoch:85
0
Train Loss: 0.777 | Acc: 76.392 (3472/4545)
Train Loss: 0.178 | Acc: 94.961 (4316/4545)
1
Train Loss: 0.944 | Acc: 69.197 (3145/4545)
Train Loss: 0.236 | Acc: 92.475 (4203/4545)
2
Train Loss: 0.820 | Acc: 74.147 (3370/4545)
Train Loss: 0.059 | Acc: 98.570 (4480/4545)
3
Train Loss: 0.586 | Acc: 80.726 (3669/4545)
Train Loss: 0.055 | Acc: 98.768 (4489/4545)
4
Train Loss: 0.553 | Acc: 79.560 (3616/4545)
Train Loss: 0.015 | Acc: 100.000 (4545/4545)
5
Train Loss: 1.010 | Acc: 61.298 (2786/4545)
Train Loss: 0.297 | Acc: 88.031 (4001/4545)
6
Train Loss: 0.902 | Acc: 69.153 (3143/4545)
Train Loss: 0.090 | Acc: 97.954 (4452/4545)
7
Train Loss: 0.658 | Acc: 83.168 (3780/4545)
Train Loss: 0.174 | Acc: 94.829 (4310/4545)
8
Train Loss: 1.029 | Acc: 68.625 (3119/4545)
Train Loss: 0.013 | Acc: 100.000 (4545/4545)
9
Train Loss: 1.283 | Acc: 63.454 (2884/4545)
Train Loss: 0.136 | Acc: 95.996 (4363/4545)
10
Train Loss: 1.355 | Acc: 57.734 (2624/4545)
Train Loss: 0.115 | Acc: 96.238 (4374/4545)
layer1.0
layer4.1
1.conv1
layer4.0
layer1.1
layer2.0
layer2.1
1.bn1
linear
layer3.0
layer3.1
Test Loss: 2.513 | Acc: 23.890 (2389/10000)
mseloss[1]:0.8066749572753906, 0.775833010673523, 0.41670870780944824, 0.1463223248720169
mseloss[2]:0.8271273374557495, 0.9973403811454773, 0.6700800657272339, 0.25288689136505127
mseloss[3]:0.8204556703567505, 1.0710985660552979, 0.787473738193512, 0.30403390526771545
mseloss[4]:0.8256776332855225, 1.0973867177963257, 0.897560715675354, 0.230073481798172
mseloss[5]:0.8222413063049316, 0.9907442331314087, 0.6141743659973145, 0.2763429880142212
mseloss[6]:0.7774659395217896, 0.5699887871742249, 0.2920619547367096, 0.12925608456134796
mseloss[7]:0.8071069121360779, 0.71602863073349, 0.4615679085254669, 0.1125943586230278
mseloss[8]:0.8415756225585938, 1.1588512659072876, 0.9678255319595337, 0.2350936084985733
mseloss[9]:0.8208967447280884, 0.9369286298751831, 0.6666901707649231, 0.2180350422859192
Epoch:86
0
Train Loss: 1.023 | Acc: 64.906 (2950/4545)
Train Loss: 0.111 | Acc: 96.392 (4381/4545)
1
Train Loss: 1.010 | Acc: 69.461 (3157/4545)
Train Loss: 0.070 | Acc: 98.394 (4472/4545)
2
Train Loss: 1.716 | Acc: 50.011 (2273/4545)
Train Loss: 0.150 | Acc: 95.952 (4361/4545)
3
Train Loss: 1.151 | Acc: 61.188 (2781/4545)
Train Loss: 0.259 | Acc: 91.815 (4173/4545)
4
Train Loss: 0.896 | Acc: 65.523 (2978/4545)
Train Loss: 0.278 | Acc: 88.691 (4031/4545)
5
Train Loss: 0.347 | Acc: 92.827 (4219/4545)
Train Loss: 0.010 | Acc: 100.000 (4545/4545)
6
Train Loss: 0.590 | Acc: 81.122 (3687/4545)
Train Loss: 0.016 | Acc: 100.000 (4545/4545)
7
Train Loss: 0.733 | Acc: 73.157 (3325/4545)
Train Loss: 0.062 | Acc: 98.768 (4489/4545)
8
Train Loss: 1.495 | Acc: 56.986 (2590/4545)
Train Loss: 0.220 | Acc: 94.015 (4273/4545)
9
Train Loss: 1.378 | Acc: 60.044 (2729/4545)
Train Loss: 0.191 | Acc: 94.543 (4297/4545)
10
Train Loss: 1.077 | Acc: 69.549 (3161/4545)
Train Loss: 0.095 | Acc: 98.130 (4460/4545)
layer1.1
1.conv1
1.bn1
linear
layer1.0
layer2.1
layer3.1
layer2.0
layer3.0
layer4.0
layer4.1
Test Loss: 2.892 | Acc: 12.480 (1248/10000)
mseloss[1]:0.7992954254150391, 0.7021672129631042, 0.385215163230896, 0.2510438859462738
mseloss[2]:0.7912262678146362, 0.9076700210571289, 0.718837320804596, 0.28717321157455444
mseloss[3]:0.8062512278556824, 1.067547082901001, 0.6973291039466858, 0.26800522208213806
mseloss[4]:0.8088915348052979, 0.7574009895324707, 0.3975844979286194, 0.2276032418012619
mseloss[5]:0.7936820387840271, 0.9721988439559937, 0.6583537459373474, 0.2168196141719818
mseloss[6]:0.7738631963729858, 0.7939344644546509, 0.5200362205505371, 0.27234068512916565
mseloss[7]:0.7887043952941895, 0.8576404452323914, 0.5530658960342407, 0.28174179792404175
mseloss[8]:0.8079116940498352, 0.8592484593391418, 0.6034803986549377, 0.27218130230903625
mseloss[9]:0.8407568335533142, 1.0289798974990845, 0.9052501320838928, 0.3297472894191742
Epoch:87
0
Train Loss: 1.487 | Acc: 57.140 (2597/4545)
Train Loss: 0.167 | Acc: 96.018 (4364/4545)
1
Train Loss: 1.102 | Acc: 65.611 (2982/4545)
Train Loss: 0.075 | Acc: 98.504 (4477/4545)
2
Train Loss: 0.819 | Acc: 72.607 (3300/4545)
Train Loss: 0.069 | Acc: 98.702 (4486/4545)
3
Train Loss: 0.502 | Acc: 86.469 (3930/4545)
Train Loss: 0.019 | Acc: 100.000 (4545/4545)
4
Train Loss: 0.986 | Acc: 64.950 (2952/4545)
Train Loss: 0.268 | Acc: 91.441 (4156/4545)
5
Train Loss: 1.624 | Acc: 48.141 (2188/4545)
Train Loss: 0.015 | Acc: 100.000 (4545/4545)
6
Train Loss: 0.761 | Acc: 78.196 (3554/4545)
Train Loss: 0.200 | Acc: 94.345 (4288/4545)
7
Train Loss: 1.062 | Acc: 61.958 (2816/4545)
Train Loss: 0.278 | Acc: 88.955 (4043/4545)
8
Train Loss: 0.710 | Acc: 79.296 (3604/4545)
Train Loss: 0.196 | Acc: 94.719 (4305/4545)
9
Train Loss: 0.660 | Acc: 79.384 (3608/4545)
Train Loss: 0.100 | Acc: 98.086 (4458/4545)
10
Train Loss: 2.249 | Acc: 38.504 (1750/4545)
Train Loss: 0.120 | Acc: 96.656 (4393/4545)
layer4.0
layer2.1
layer3.0
layer4.1
layer3.1
1.conv1
layer1.0
layer1.1
1.bn1
linear
layer2.0
Test Loss: 3.190 | Acc: 24.490 (2449/10000)
mseloss[1]:0.8026791214942932, 0.8937656283378601, 0.6012443900108337, 0.2616554796695709
mseloss[2]:0.7882674336433411, 0.9054394364356995, 0.6175740361213684, 0.3175913989543915
mseloss[3]:0.7882918119430542, 0.8769607543945312, 0.5547785758972168, 0.18436367809772491
mseloss[4]:0.8120900392532349, 0.8488990068435669, 0.5042223334312439, 0.23676587641239166
mseloss[5]:0.7853529453277588, 0.7940123677253723, 0.4319887161254883, 0.15734907984733582
mseloss[6]:0.8194804787635803, 0.9087631702423096, 0.5699754953384399, 0.23229701817035675
mseloss[7]:0.8026053309440613, 0.8102773427963257, 0.4892602860927582, 0.280905544757843
mseloss[8]:0.8064119815826416, 0.8207323551177979, 0.6140149831771851, 0.25857990980148315
mseloss[9]:0.8107128739356995, 0.8501291871070862, 0.5664517879486084, 0.27483510971069336
Epoch:88
0
Train Loss: 1.519 | Acc: 52.123 (2369/4545)
Train Loss: 0.110 | Acc: 96.656 (4393/4545)
1
Train Loss: 2.855 | Acc: 36.458 (1657/4545)
Train Loss: 0.272 | Acc: 93.245 (4238/4545)
2
Train Loss: 1.520 | Acc: 61.562 (2798/4545)
Train Loss: 0.112 | Acc: 97.756 (4443/4545)
3
Train Loss: 2.299 | Acc: 46.491 (2113/4545)
Train Loss: 0.330 | Acc: 92.563 (4207/4545)
4
Train Loss: 0.600 | Acc: 83.806 (3809/4545)
Train Loss: 0.026 | Acc: 100.000 (4545/4545)
5
Train Loss: 1.054 | Acc: 59.472 (2703/4545)
Train Loss: 0.283 | Acc: 88.911 (4041/4545)
6
Train Loss: 0.862 | Acc: 66.953 (3043/4545)
Train Loss: 0.010 | Acc: 100.000 (4545/4545)
7
Train Loss: 1.121 | Acc: 61.848 (2811/4545)
Train Loss: 0.274 | Acc: 90.803 (4127/4545)
8
Train Loss: 0.878 | Acc: 71.529 (3251/4545)
Train Loss: 0.078 | Acc: 98.636 (4483/4545)
9
Train Loss: 0.869 | Acc: 78.460 (3566/4545)
Train Loss: 0.168 | Acc: 95.490 (4340/4545)
10
Train Loss: 0.837 | Acc: 71.925 (3269/4545)
Train Loss: 0.067 | Acc: 98.548 (4479/4545)
layer2.1
1.bn1
layer4.0
layer2.0
layer4.1
layer3.1
layer3.0
linear
layer1.1
layer1.0
1.conv1
Test Loss: 3.724 | Acc: 13.940 (1394/10000)
mseloss[1]:0.8474517464637756, 0.9563833475112915, 0.7519416809082031, 0.3674408495426178
mseloss[2]:0.8143752813339233, 0.7530552744865417, 0.43222033977508545, 0.27779123187065125
mseloss[3]:0.8122135400772095, 0.8238153457641602, 0.5243015289306641, 0.31055787205696106
mseloss[4]:0.774458646774292, 0.7423135638237, 0.4065130352973938, 0.21791212260723114
mseloss[5]:0.8072314858436584, 0.6939026117324829, 0.34981635212898254, 0.25511085987091064
mseloss[6]:0.7957060933113098, 0.8702221512794495, 0.5348554253578186, 0.26152753829956055
mseloss[7]:0.810004472732544, 0.9112809896469116, 0.5532079339027405, 0.291177898645401
mseloss[8]:0.7949520349502563, 0.7670381665229797, 0.43048009276390076, 0.26174798607826233
mseloss[9]:0.7979344725608826, 0.8284041881561279, 0.5664653778076172, 0.24543322622776031
Epoch:89
0
Train Loss: 1.420 | Acc: 55.600 (2527/4545)
Train Loss: 0.122 | Acc: 96.722 (4396/4545)
1
Train Loss: 1.174 | Acc: 69.351 (3152/4545)
Train Loss: 0.105 | Acc: 97.580 (4435/4545)
2
Train Loss: 1.699 | Acc: 48.713 (2214/4545)
Train Loss: 0.116 | Acc: 98.240 (4465/4545)
3
Train Loss: 0.888 | Acc: 69.153 (3143/4545)
Train Loss: 0.281 | Acc: 90.583 (4117/4545)
4
Train Loss: 2.158 | Acc: 55.160 (2507/4545)
Train Loss: 0.382 | Acc: 90.561 (4116/4545)
5
Train Loss: 0.475 | Acc: 87.371 (3971/4545)
Train Loss: 0.018 | Acc: 100.000 (4545/4545)
6
Train Loss: 0.663 | Acc: 78.174 (3553/4545)
Train Loss: 0.074 | Acc: 98.790 (4490/4545)
7
Train Loss: 1.420 | Acc: 51.397 (2336/4545)
Train Loss: 0.315 | Acc: 88.031 (4001/4545)
8
Train Loss: 3.355 | Acc: 29.439 (1338/4545)
Train Loss: 0.381 | Acc: 90.891 (4131/4545)
9
Train Loss: 1.786 | Acc: 46.887 (2131/4545)
Train Loss: 0.227 | Acc: 95.072 (4321/4545)
10
Train Loss: 1.084 | Acc: 64.554 (2934/4545)
Train Loss: 0.040 | Acc: 100.000 (4545/4545)
layer2.0
1.conv1
1.bn1
linear
layer3.0
layer2.1
layer1.1
layer4.1
layer1.0
layer4.0
layer3.1
Test Loss: 3.443 | Acc: 17.040 (1704/10000)
mseloss[1]:0.814959704875946, 0.741247296333313, 0.40612658858299255, 0.2755703926086426
mseloss[2]:0.7925689816474915, 0.7450142502784729, 0.41063758730888367, 0.2761702835559845
mseloss[3]:0.8063730597496033, 0.8799129128456116, 0.511368453502655, 0.2997360825538635
mseloss[4]:0.8101518750190735, 0.8186221718788147, 0.46981775760650635, 0.3101865351200104
mseloss[5]:0.7956059575080872, 0.8782779574394226, 0.5161938667297363, 0.21819132566452026
mseloss[6]:0.7995336651802063, 0.6681119799613953, 0.30969536304473877, 0.24114151298999786
mseloss[7]:0.8070554733276367, 0.6877167820930481, 0.3222940266132355, 0.23594345152378082
mseloss[8]:0.8458438515663147, 0.986773669719696, 0.6711664199829102, 0.38556912541389465
mseloss[9]:0.7931532263755798, 0.8184321522712708, 0.528213381767273, 0.21770071983337402
Epoch:90
0
Train Loss: 2.312 | Acc: 50.649 (2302/4545)
Train Loss: 0.463 | Acc: 89.681 (4076/4545)
1
Train Loss: 1.391 | Acc: 51.133 (2324/4545)
Train Loss: 0.145 | Acc: 97.734 (4442/4545)
2
Train Loss: 1.771 | Acc: 49.571 (2253/4545)
Train Loss: 0.346 | Acc: 92.299 (4195/4545)
3
Train Loss: 1.106 | Acc: 64.026 (2910/4545)
Train Loss: 0.111 | Acc: 98.328 (4469/4545)
4
Train Loss: 1.184 | Acc: 61.452 (2793/4545)
Train Loss: 0.065 | Acc: 99.978 (4544/4545)
5
Train Loss: 0.849 | Acc: 73.509 (3341/4545)
Train Loss: 0.035 | Acc: 100.000 (4545/4545)
6
Train Loss: 0.945 | Acc: 72.717 (3305/4545)
Train Loss: 0.130 | Acc: 97.514 (4432/4545)
7
Train Loss: 1.490 | Acc: 52.739 (2397/4545)
Train Loss: 0.141 | Acc: 96.744 (4397/4545)
8
Train Loss: 0.720 | Acc: 80.946 (3679/4545)
Train Loss: 0.292 | Acc: 89.725 (4078/4545)
9
Train Loss: 1.221 | Acc: 63.938 (2906/4545)
Train Loss: 0.245 | Acc: 95.006 (4318/4545)
10
Train Loss: 1.078 | Acc: 63.168 (2871/4545)
Train Loss: 0.338 | Acc: 87.855 (3993/4545)
layer2.0
layer3.1
1.conv1
layer4.0
layer1.1
layer2.1
linear
1.bn1
layer1.0
layer3.0
layer4.1
Test Loss: 2.928 | Acc: 17.890 (1789/10000)
mseloss[1]:0.8195043802261353, 0.9296383857727051, 0.6419985294342041, 0.30267301201820374
mseloss[2]:0.8049863576889038, 0.6729133129119873, 0.3730543255805969, 0.12307305634021759
mseloss[3]:0.8214884996414185, 0.8827501535415649, 0.5756617784500122, 0.2990764081478119
mseloss[4]:0.8169705867767334, 0.9848515391349792, 0.6932710409164429, 0.2643578052520752
mseloss[5]:0.829547107219696, 0.9942987561225891, 0.7267470359802246, 0.295449823141098
mseloss[6]:0.7743364572525024, 0.5727144479751587, 0.26199930906295776, 0.13804206252098083
mseloss[7]:0.8009902834892273, 0.818662703037262, 0.5497338175773621, 0.31940123438835144
mseloss[8]:0.8002451062202454, 0.7223485708236694, 0.39833390712738037, 0.171721413731575
mseloss[9]:0.8172972202301025, 0.8719030618667603, 0.6429175138473511, 0.29254552721977234
Epoch:91
0
Train Loss: 1.668 | Acc: 46.139 (2097/4545)
Train Loss: 0.455 | Acc: 90.407 (4109/4545)
1
Train Loss: 1.161 | Acc: 69.043 (3138/4545)
Train Loss: 0.272 | Acc: 95.402 (4336/4545)
2
Train Loss: 1.876 | Acc: 40.198 (1827/4545)
Train Loss: 0.215 | Acc: 96.436 (4383/4545)
3
Train Loss: 1.645 | Acc: 48.757 (2216/4545)
Train Loss: 0.230 | Acc: 96.260 (4375/4545)
4
Train Loss: 2.300 | Acc: 40.066 (1821/4545)
Train Loss: 0.466 | Acc: 90.099 (4095/4545)
5
Train Loss: 1.075 | Acc: 64.972 (2953/4545)
Train Loss: 0.052 | Acc: 100.000 (4545/4545)
6
Train Loss: 0.679 | Acc: 84.994 (3863/4545)
Train Loss: 0.132 | Acc: 97.228 (4419/4545)
7
Train Loss: 1.386 | Acc: 52.937 (2406/4545)
Train Loss: 0.374 | Acc: 86.403 (3927/4545)
8
Train Loss: 0.940 | Acc: 71.089 (3231/4545)
Train Loss: 0.336 | Acc: 89.131 (4051/4545)
9
Train Loss: 0.759 | Acc: 81.672 (3712/4545)
Train Loss: 0.099 | Acc: 98.350 (4470/4545)
10
Train Loss: 1.842 | Acc: 40.198 (1827/4545)
Train Loss: 0.166 | Acc: 99.868 (4539/4545)
1.conv1
layer1.1
linear
layer3.1
layer2.0
layer2.1
layer4.0
layer4.1
layer3.0
layer1.0
1.bn1
Test Loss: 2.571 | Acc: 24.200 (2420/10000)
mseloss[1]:0.8179429173469543, 0.8513904213905334, 0.7004719972610474, 0.2925679683685303
mseloss[2]:0.8011883497238159, 0.7876313328742981, 0.5751327276229858, 0.30274108052253723
mseloss[3]:0.8165616989135742, 0.9248554110527039, 0.7384009957313538, 0.3108077943325043
mseloss[4]:0.803799569606781, 0.6760207414627075, 0.3866053521633148, 0.11418423056602478
mseloss[5]:0.8285205364227295, 0.9937827587127686, 0.8295650482177734, 0.29340675473213196
mseloss[6]:0.7737648487091064, 0.5561546683311462, 0.2665625810623169, 0.12439645826816559
mseloss[7]:0.8115099668502808, 0.8554360866546631, 0.575002133846283, 0.3101671636104584
mseloss[8]:0.7989510893821716, 0.7070729732513428, 0.40843304991722107, 0.1466473489999771
mseloss[9]:0.8200510144233704, 0.8599978089332581, 0.62555330991745, 0.30957815051078796
Epoch:92
0
Train Loss: 1.591 | Acc: 53.289 (2422/4545)
Train Loss: 0.416 | Acc: 95.072 (4321/4545)
1
Train Loss: 0.907 | Acc: 72.871 (3312/4545)
Train Loss: 0.362 | Acc: 86.799 (3945/4545)
2
Train Loss: 2.657 | Acc: 32.233 (1465/4545)
Train Loss: 0.590 | Acc: 87.547 (3979/4545)
3
Train Loss: 1.179 | Acc: 61.386 (2790/4545)
Train Loss: 0.182 | Acc: 96.480 (4385/4545)
4
Train Loss: 0.901 | Acc: 73.289 (3331/4545)
Train Loss: 0.359 | Acc: 89.109 (4050/4545)
5
Train Loss: 2.911 | Acc: 11.793 (536/4545)
Train Loss: 0.514 | Acc: 95.116 (4323/4545)
6
Train Loss: 1.078 | Acc: 64.994 (2954/4545)
Train Loss: 0.144 | Acc: 97.888 (4449/4545)
7
Train Loss: 1.598 | Acc: 42.376 (1926/4545)
Train Loss: 0.169 | Acc: 99.076 (4503/4545)
8
Train Loss: 1.565 | Acc: 43.608 (1982/4545)
Train Loss: 0.315 | Acc: 94.631 (4301/4545)
9
Train Loss: 2.203 | Acc: 47.679 (2167/4545)
Train Loss: 0.610 | Acc: 86.931 (3951/4545)
10
Train Loss: 1.213 | Acc: 60.506 (2750/4545)
Train Loss: 0.179 | Acc: 96.700 (4395/4545)
layer3.0
layer3.1
layer1.1
layer1.0
layer4.1
layer2.0
layer2.1
1.conv1
linear
layer4.0
1.bn1
Test Loss: 2.211 | Acc: 31.230 (3123/10000)
mseloss[1]:0.8092249035835266, 0.8239182829856873, 0.4969484806060791, 0.2855215072631836
mseloss[2]:0.8093246221542358, 0.8072675466537476, 0.6228594183921814, 0.2978719174861908
mseloss[3]:0.7892484068870544, 0.7982525825500488, 0.5605787038803101, 0.2267458438873291
mseloss[4]:0.8121845722198486, 0.8495935201644897, 0.585748016834259, 0.27182820439338684
mseloss[5]:0.7889909148216248, 0.8714634776115417, 0.5677199363708496, 0.17223824560642242
mseloss[6]:0.8057195544242859, 0.8076871037483215, 0.5321850776672363, 0.21911035478115082
mseloss[7]:0.7893502712249756, 0.7944467067718506, 0.5022653937339783, 0.18627654016017914
mseloss[8]:0.7928107380867004, 0.8383121490478516, 0.5870475769042969, 0.2849366068840027
mseloss[9]:0.8201115131378174, 0.8860575556755066, 0.6689945459365845, 0.28630536794662476
Epoch:93
0
Train Loss: 1.846 | Acc: 46.777 (2126/4545)
Train Loss: 0.332 | Acc: 95.336 (4333/4545)
1
Train Loss: 0.818 | Acc: 81.452 (3702/4545)
Train Loss: 0.102 | Acc: 99.956 (4543/4545)
2
Train Loss: 1.333 | Acc: 58.570 (2662/4545)
Train Loss: 0.307 | Acc: 96.546 (4388/4545)
3
Train Loss: 1.204 | Acc: 63.366 (2880/4545)
Train Loss: 0.241 | Acc: 97.184 (4417/4545)
4
Train Loss: 2.233 | Acc: 20.440 (929/4545)
Train Loss: 0.509 | Acc: 96.106 (4368/4545)
5
Train Loss: 1.121 | Acc: 61.034 (2774/4545)
Train Loss: 0.260 | Acc: 96.194 (4372/4545)
6
Train Loss: 1.473 | Acc: 50.407 (2291/4545)
Train Loss: 0.500 | Acc: 84.510 (3841/4545)
7
Train Loss: 2.852 | Acc: 27.921 (1269/4545)
Train Loss: 0.667 | Acc: 87.063 (3957/4545)
8
Train Loss: 1.203 | Acc: 65.017 (2955/4545)
Train Loss: 0.494 | Acc: 88.207 (4009/4545)
9
Train Loss: 1.450 | Acc: 55.358 (2516/4545)
Train Loss: 0.508 | Acc: 93.553 (4252/4545)
10
Train Loss: 3.031 | Acc: 13.795 (627/4545)
Train Loss: 0.667 | Acc: 85.039 (3865/4545)
layer4.1
1.bn1
layer2.1
layer3.0
layer2.0
1.conv1
layer3.1
layer1.0
linear
layer4.0
layer1.1
Test Loss: 2.025 | Acc: 30.940 (3094/10000)
mseloss[1]:0.8165562748908997, 1.0713709592819214, 0.6782251596450806, 0.2737853229045868
mseloss[2]:0.7880082130432129, 0.9700564742088318, 0.5614580512046814, 0.23567257821559906
mseloss[3]:0.7922673225402832, 0.8574657440185547, 0.4597942531108856, 0.25144436955451965
mseloss[4]:0.7967222332954407, 1.0212570428848267, 0.6158820390701294, 0.22184674441814423
mseloss[5]:0.8095605373382568, 0.7846804857254028, 0.4216083288192749, 0.24802683293819427
mseloss[6]:0.7860859632492065, 0.9088234901428223, 0.46768873929977417, 0.25420641899108887
mseloss[7]:0.774020254611969, 0.5331429243087769, 0.20839203894138336, 0.10822983086109161
mseloss[8]:0.7746549844741821, 0.6553575396537781, 0.3070889413356781, 0.14485110342502594
mseloss[9]:0.8131770491600037, 0.888739824295044, 0.5525047183036804, 0.2425653338432312
Epoch:94
0
Train Loss: 1.329 | Acc: 64.466 (2930/4545)
Train Loss: 0.555 | Acc: 92.849 (4220/4545)
1
Train Loss: 1.285 | Acc: 58.856 (2675/4545)
Train Loss: 0.375 | Acc: 95.160 (4325/4545)
2
Train Loss: 1.303 | Acc: 56.194 (2554/4545)
Train Loss: 0.532 | Acc: 84.312 (3832/4545)
3
Train Loss: 1.028 | Acc: 67.327 (3060/4545)
Train Loss: 0.460 | Acc: 88.075 (4003/4545)
4
Train Loss: 1.529 | Acc: 44.466 (2021/4545)
Train Loss: 0.489 | Acc: 92.937 (4224/4545)
5
Train Loss: 1.024 | Acc: 69.417 (3155/4545)
Train Loss: 0.332 | Acc: 95.160 (4325/4545)
6
Train Loss: 1.820 | Acc: 32.783 (1490/4545)
Train Loss: 0.386 | Acc: 97.140 (4415/4545)
7
Train Loss: 2.874 | Acc: 4.554 (207/4545)
Train Loss: 1.057 | Acc: 74.917 (3405/4545)
8
Train Loss: 4.215 | Acc: 1.584 (72/4545)
Train Loss: 1.399 | Acc: 56.216 (2555/4545)
9
Train Loss: 2.744 | Acc: 41.738 (1897/4545)
Train Loss: 0.954 | Acc: 76.898 (3495/4545)
10
Train Loss: 2.221 | Acc: 30.803 (1400/4545)
Train Loss: 0.535 | Acc: 89.923 (4087/4545)
layer2.0
1.conv1
layer1.0
layer3.0
1.bn1
linear
layer1.1
layer4.1
layer4.0
layer2.1
layer3.1
Test Loss: 2.428 | Acc: 16.760 (1676/10000)
mseloss[1]:0.8060879111289978, 0.8064878582954407, 0.4867485761642456, 0.19439594447612762
mseloss[2]:0.8103068470954895, 0.853819727897644, 0.45101189613342285, 0.23120273649692535
mseloss[3]:0.8132367134094238, 0.8607059121131897, 0.5060779452323914, 0.23633328080177307
mseloss[4]:0.7899350523948669, 0.8188960552215576, 0.4846903085708618, 0.1769952028989792
mseloss[5]:0.7927165031433105, 0.8367483019828796, 0.5137779712677002, 0.22308562695980072
mseloss[6]:0.790401041507721, 0.7831313014030457, 0.40459632873535156, 0.15279965102672577
mseloss[7]:0.7887692451477051, 0.8528357744216919, 0.5025321245193481, 0.1617167890071869
mseloss[8]:0.8119211792945862, 0.8114161491394043, 0.49876320362091064, 0.2595255374908447
mseloss[9]:0.8208422064781189, 0.8727218508720398, 0.5392491221427917, 0.25080743432044983
Epoch:95
0
Train Loss: 2.165 | Acc: 26.689 (1213/4545)
Train Loss: 0.972 | Acc: 78.328 (3560/4545)
1
Train Loss: 3.405 | Acc: 0.484 (22/4545)
Train Loss: 1.767 | Acc: 33.201 (1509/4545)
2
Train Loss: 2.404 | Acc: 12.563 (571/4545)
Train Loss: 1.198 | Acc: 65.369 (2971/4545)
3
Train Loss: 1.783 | Acc: 30.187 (1372/4545)
Train Loss: 0.791 | Acc: 83.036 (3774/4545)
4
Train Loss: 0.953 | Acc: 72.915 (3314/4545)
Train Loss: 0.533 | Acc: 87.811 (3991/4545)
5
Train Loss: 1.421 | Acc: 36.722 (1669/4545)
Train Loss: 0.556 | Acc: 90.165 (4098/4545)
6
Train Loss: 1.125 | Acc: 71.287 (3240/4545)
Train Loss: 0.646 | Acc: 85.765 (3898/4545)
7
Train Loss: 1.143 | Acc: 57.690 (2622/4545)
Train Loss: 0.450 | Acc: 91.661 (4166/4545)
8
Train Loss: 1.402 | Acc: 53.949 (2452/4545)
Train Loss: 0.722 | Acc: 81.386 (3699/4545)
9
Train Loss: 2.012 | Acc: 18.284 (831/4545)
Train Loss: 1.080 | Acc: 66.117 (3005/4545)
10
Train Loss: 2.750 | Acc: 6.887 (313/4545)
Train Loss: 1.100 | Acc: 72.651 (3302/4545)
layer3.1
layer1.1
layer2.1
layer3.0
layer4.0
layer4.1
linear
layer1.0
1.conv1
1.bn1
layer2.0
Test Loss: 2.178 | Acc: 30.930 (3093/10000)
mseloss[1]:0.7887586355209351, 0.8646391034126282, 0.4880855977535248, 0.18161912262439728
mseloss[2]:0.7882607579231262, 0.8332991600036621, 0.4924921989440918, 0.20647910237312317
mseloss[3]:0.8057804107666016, 0.8129115700721741, 0.47695374488830566, 0.21445263922214508
mseloss[4]:0.8122774362564087, 0.8474463224411011, 0.4725460112094879, 0.24477629363536835
mseloss[5]:0.7911708950996399, 0.8553832173347473, 0.5061516165733337, 0.2448703944683075
mseloss[6]:0.8204361796379089, 0.8718409538269043, 0.5200846791267395, 0.26745060086250305
mseloss[7]:0.8143193125724792, 0.8922621607780457, 0.47972479462623596, 0.25329282879829407
mseloss[8]:0.8103675246238708, 0.8186332583427429, 0.49730223417282104, 0.2789773941040039
mseloss[9]:0.808505117893219, 0.8695377707481384, 0.43381813168525696, 0.2270018309354782
Epoch:96
0
Train Loss: 2.106 | Acc: 14.367 (653/4545)
Train Loss: 1.464 | Acc: 49.021 (2228/4545)
1
Train Loss: 1.329 | Acc: 58.966 (2680/4545)
Train Loss: 0.807 | Acc: 79.538 (3615/4545)
2
Train Loss: 3.532 | Acc: 0.286 (13/4545)
Train Loss: 2.342 | Acc: 10.055 (457/4545)
3
Train Loss: 2.751 | Acc: 2.530 (115/4545)
Train Loss: 1.585 | Acc: 44.576 (2026/4545)
4
Train Loss: 1.367 | Acc: 51.595 (2345/4545)
Train Loss: 0.908 | Acc: 74.807 (3400/4545)
5
Train Loss: 1.043 | Acc: 71.947 (3270/4545)
Train Loss: 0.710 | Acc: 83.806 (3809/4545)
6
Train Loss: 0.958 | Acc: 65.875 (2994/4545)
Train Loss: 0.554 | Acc: 87.987 (3999/4545)
7
Train Loss: 2.149 | Acc: 13.531 (615/4545)
Train Loss: 1.342 | Acc: 57.184 (2599/4545)
8
Train Loss: 1.838 | Acc: 38.658 (1757/4545)
Train Loss: 1.069 | Acc: 75.512 (3432/4545)
9
Train Loss: 1.608 | Acc: 29.945 (1361/4545)
Train Loss: 0.930 | Acc: 77.866 (3539/4545)
10
Train Loss: 2.458 | Acc: 13.377 (608/4545)
Train Loss: 1.663 | Acc: 42.442 (1929/4545)
1.bn1
1.conv1
layer2.0
layer1.1
linear
layer2.1
layer3.0
layer3.1
layer1.0
layer4.1
layer4.0
Test Loss: 2.014 | Acc: 29.430 (2943/10000)
mseloss[1]:0.8147868514060974, 1.0904282331466675, 0.5643589496612549, 0.20840615034103394
mseloss[2]:0.775661051273346, 0.6417989730834961, 0.2622394263744354, 0.12091219425201416
mseloss[3]:0.7910611033439636, 0.6596285104751587, 0.2749236524105072, 0.13036812841892242
mseloss[4]:0.8284766674041748, 1.140633225440979, 0.5291283130645752, 0.19050252437591553
mseloss[5]:0.8132143616676331, 0.9406720399856567, 0.44179946184158325, 0.15927740931510925
mseloss[6]:0.7826398015022278, 0.9155205488204956, 0.4180991053581238, 0.1692747324705124
mseloss[7]:0.8043739795684814, 0.7740078568458557, 0.32420477271080017, 0.1446661502122879
mseloss[8]:0.8061712384223938, 0.8915995359420776, 0.47552570700645447, 0.20902061462402344
mseloss[9]:0.8093705773353577, 0.796909511089325, 0.3392248749732971, 0.14665569365024567
Epoch:97
0
Train Loss: 2.164 | Acc: 24.972 (1135/4545)
Train Loss: 1.586 | Acc: 52.607 (2391/4545)
1
Train Loss: 3.435 | Acc: 0.022 (1/4545)
Train Loss: 2.781 | Acc: 0.814 (37/4545)
2
Train Loss: 1.421 | Acc: 60.154 (2734/4545)
Train Loss: 1.104 | Acc: 71.419 (3246/4545)
3
Train Loss: 1.779 | Acc: 20.000 (909/4545)
Train Loss: 1.326 | Acc: 51.705 (2350/4545)
4
Train Loss: 2.363 | Acc: 12.805 (582/4545)
Train Loss: 1.892 | Acc: 30.825 (1401/4545)
5
Train Loss: 2.131 | Acc: 14.653 (666/4545)
Train Loss: 1.763 | Acc: 32.981 (1499/4545)
6
Train Loss: 2.671 | Acc: 1.958 (89/4545)
Train Loss: 2.064 | Acc: 14.565 (662/4545)
7
Train Loss: 1.282 | Acc: 61.584 (2799/4545)
Train Loss: 1.026 | Acc: 75.732 (3442/4545)
8
Train Loss: 1.606 | Acc: 50.627 (2301/4545)
Train Loss: 1.178 | Acc: 66.161 (3007/4545)
9
Train Loss: 1.859 | Acc: 30.759 (1398/4545)
Train Loss: 1.435 | Acc: 55.204 (2509/4545)
10
Train Loss: 1.038 | Acc: 75.600 (3436/4545)
Train Loss: 0.729 | Acc: 87.085 (3958/4545)
1.conv1
linear
layer1.0
layer4.1
layer1.1
layer2.0
layer2.1
1.bn1
layer3.0
layer3.1
layer4.0
Test Loss: 1.912 | Acc: 34.110 (3411/10000)
mseloss[1]:0.7859060168266296, 0.8642862439155579, 0.5179920792579651, 0.20395439863204956
mseloss[2]:0.8173021674156189, 0.8789315819740295, 0.5035417079925537, 0.22205781936645508
mseloss[3]:0.7889542579650879, 0.8692799806594849, 0.5353925228118896, 0.22470255196094513
mseloss[4]:0.7845030426979065, 0.8478285074234009, 0.5225985050201416, 0.2094617635011673
mseloss[5]:0.806081235408783, 0.9137780070304871, 0.4701700508594513, 0.2008298635482788
mseloss[6]:0.7834601402282715, 0.8161529302597046, 0.41346919536590576, 0.1849658191204071
mseloss[7]:0.8088321685791016, 0.8875084519386292, 0.49668121337890625, 0.20815442502498627
mseloss[8]:0.8088126182556152, 0.8244680762290955, 0.4695051908493042, 0.2284231185913086
mseloss[9]:0.8035714626312256, 0.8092686533927917, 0.5087063908576965, 0.2143065184354782
Epoch:98
0
Train Loss: 3.486 | Acc: 0.044 (2/4545)
Train Loss: 3.205 | Acc: 0.088 (4/4545)
1
Train Loss: 2.389 | Acc: 16.810 (764/4545)
Train Loss: 2.108 | Acc: 27.393 (1245/4545)
2
Train Loss: 2.284 | Acc: 13.905 (632/4545)
Train Loss: 2.082 | Acc: 22.288 (1013/4545)
3
Train Loss: 2.313 | Acc: 7.965 (362/4545)
Train Loss: 2.150 | Acc: 13.531 (615/4545)
4
Train Loss: 1.942 | Acc: 14.983 (681/4545)
Train Loss: 1.732 | Acc: 25.215 (1146/4545)
5
Train Loss: 1.559 | Acc: 53.663 (2439/4545)
Train Loss: 1.398 | Acc: 59.934 (2724/4545)
6
Train Loss: 1.653 | Acc: 49.307 (2241/4545)
Train Loss: 1.446 | Acc: 57.470 (2612/4545)
7
Train Loss: 0.928 | Acc: 78.680 (3576/4545)
Train Loss: 0.807 | Acc: 83.168 (3780/4545)
8
Train Loss: 2.850 | Acc: 0.858 (39/4545)
Train Loss: 2.587 | Acc: 2.970 (135/4545)
9
Train Loss: 1.456 | Acc: 46.777 (2126/4545)
Train Loss: 1.331 | Acc: 55.116 (2505/4545)
10
Train Loss: 1.954 | Acc: 28.691 (1304/4545)
Train Loss: 1.755 | Acc: 38.174 (1735/4545)
layer1.1
layer3.0
layer3.1
layer4.0
layer2.0
linear
layer4.1
layer2.1
layer1.0
1.bn1
1.conv1
Test Loss: 1.795 | Acc: 37.280 (3728/10000)
mseloss[1]:0.7862384915351868, 0.861966073513031, 0.5189835429191589, 0.21293261647224426
mseloss[2]:0.7635560035705566, 0.7992798089981079, 0.3856567144393921, 0.12197580188512802
mseloss[3]:0.7755845189094543, 0.649462878704071, 0.24842588603496552, 0.09727419167757034
mseloss[4]:0.7729511857032776, 0.6511922478675842, 0.2585581839084625, 0.09778665751218796
mseloss[5]:0.8124105334281921, 1.0292316675186157, 0.5316230058670044, 0.1615837961435318
mseloss[6]:0.8072400689125061, 1.0300359725952148, 0.5405259728431702, 0.1615946739912033
mseloss[7]:0.7934735417366028, 1.0109943151474, 0.5117260217666626, 0.16294491291046143
mseloss[8]:0.7723174095153809, 0.6710121631622314, 0.271230012178421, 0.10052642971277237
mseloss[9]:0.7912926077842712, 1.0726823806762695, 0.5462449193000793, 0.15361258387565613
Epoch:99
0
Train Loss: 2.215 | Acc: 24.048 (1093/4545)
Train Loss: 2.161 | Acc: 26.359 (1198/4545)
1
Train Loss: 2.050 | Acc: 36.920 (1678/4545)
Train Loss: 1.993 | Acc: 38.636 (1756/4545)
2
Train Loss: 2.242 | Acc: 11.199 (509/4545)
Train Loss: 2.211 | Acc: 12.607 (573/4545)
3
Train Loss: 1.209 | Acc: 68.823 (3128/4545)
Train Loss: 1.172 | Acc: 71.089 (3231/4545)
4
Train Loss: 1.799 | Acc: 23.498 (1068/4545)
Train Loss: 1.759 | Acc: 25.171 (1144/4545)
5
Train Loss: 2.743 | Acc: 0.770 (35/4545)
Train Loss: 2.691 | Acc: 1.056 (48/4545)
6
Train Loss: 1.462 | Acc: 52.893 (2404/4545)
Train Loss: 1.437 | Acc: 54.895 (2495/4545)
7
Train Loss: 3.315 | Acc: 0.022 (1/4545)
Train Loss: 3.261 | Acc: 0.066 (3/4545)
8
Train Loss: 1.852 | Acc: 35.578 (1617/4545)
Train Loss: 1.814 | Acc: 37.382 (1699/4545)
9
Train Loss: 2.210 | Acc: 18.856 (857/4545)
Train Loss: 2.172 | Acc: 20.198 (918/4545)
10
Train Loss: 1.837 | Acc: 47.283 (2149/4545)
Train Loss: 1.794 | Acc: 48.823 (2219/4545)
layer2.0
layer4.1
layer2.1
layer3.1
linear
layer1.0
layer3.0
layer4.0
1.bn1
layer1.1
1.conv1
Test Loss: 1.944 | Acc: 33.520 (3352/10000)
mseloss[1]:0.8084261417388916, 0.8141242861747742, 0.4382186233997345, 0.20105722546577454
mseloss[2]:0.806227445602417, 0.9124087691307068, 0.47518080472946167, 0.2035527378320694
mseloss[3]:0.8127775192260742, 0.9065199494361877, 0.47813844680786133, 0.19513051211833954
mseloss[4]:0.78907310962677, 0.8690391182899475, 0.5438098907470703, 0.23009370267391205
mseloss[5]:0.7830381393432617, 0.8080190420150757, 0.3992946445941925, 0.18963108956813812
mseloss[6]:0.8078253269195557, 0.8838427066802979, 0.49478960037231445, 0.20089887082576752
mseloss[7]:0.7861868739128113, 0.859474241733551, 0.5133129954338074, 0.214617520570755
mseloss[8]:0.8042041659355164, 0.8059284090995789, 0.5119246244430542, 0.21692585945129395
mseloss[9]:0.7846276164054871, 0.8469799160957336, 0.5193099975585938, 0.21451199054718018
Epoch:100
0
Train Loss: 1.834 | Acc: 47.547 (2161/4545)
Train Loss: 1.825 | Acc: 47.789 (2172/4545)
1
Train Loss: 2.091 | Acc: 35.314 (1605/4545)
Train Loss: 2.079 | Acc: 35.688 (1622/4545)
2
Train Loss: 1.242 | Acc: 66.381 (3017/4545)
Train Loss: 1.235 | Acc: 66.777 (3035/4545)
3
Train Loss: 3.362 | Acc: 0.022 (1/4545)
Train Loss: 3.352 | Acc: 0.022 (1/4545)
4
Train Loss: 1.831 | Acc: 21.496 (977/4545)
Train Loss: 1.823 | Acc: 22.024 (1001/4545)
5
Train Loss: 2.225 | Acc: 23.784 (1081/4545)
Train Loss: 2.215 | Acc: 24.224 (1101/4545)
6
Train Loss: 2.258 | Acc: 16.942 (770/4545)
Train Loss: 2.251 | Acc: 17.184 (781/4545)
7
Train Loss: 2.786 | Acc: 0.616 (28/4545)
Train Loss: 2.776 | Acc: 0.616 (28/4545)
8
Train Loss: 2.250 | Acc: 10.869 (494/4545)
Train Loss: 2.244 | Acc: 11.023 (501/4545)
9
Train Loss: 1.876 | Acc: 33.751 (1534/4545)
Train Loss: 1.869 | Acc: 34.103 (1550/4545)
10
Train Loss: 1.472 | Acc: 52.189 (2372/4545)
Train Loss: 1.467 | Acc: 52.475 (2385/4545)
layer1.0
layer4.0
layer1.1
layer2.0
1.bn1
1.conv1
linear
layer3.1
layer2.1
layer4.1
layer3.0
Test Loss: 1.941 | Acc: 35.080 (3508/10000)
mseloss[1]:0.8036186695098877, 0.6461780071258545, 0.2349110245704651, 0.11270149797201157
mseloss[2]:0.7722092866897583, 0.515940248966217, 0.14454925060272217, 0.08032546192407608
mseloss[3]:0.811931848526001, 1.0244375467300415, 0.515046238899231, 0.1560899317264557
mseloss[4]:0.813815176486969, 1.0228108167648315, 0.5277643799781799, 0.15931089222431183
mseloss[5]:0.816723108291626, 0.8701086640357971, 0.47951775789260864, 0.20162589848041534
mseloss[6]:0.7938073873519897, 0.8034380674362183, 0.3515765368938446, 0.11733521521091461
mseloss[7]:0.8228551745414734, 1.0663219690322876, 0.5076027512550354, 0.1595013588666916
mseloss[8]:0.8126531839370728, 0.9555609822273254, 0.41449347138404846, 0.12370312213897705
mseloss[9]:0.8208625912666321, 0.9008350968360901, 0.4171057343482971, 0.13842961192131042
Epoch:101
0
Train Loss: 2.743 | Acc: 0.792 (36/4545)
Train Loss: 2.612 | Acc: 1.870 (85/4545)
1
Train Loss: 1.808 | Acc: 48.515 (2205/4545)
Train Loss: 1.702 | Acc: 51.991 (2363/4545)
2
Train Loss: 1.805 | Acc: 23.432 (1065/4545)
Train Loss: 1.707 | Acc: 28.603 (1300/4545)
3
Train Loss: 1.452 | Acc: 53.839 (2447/4545)
Train Loss: 1.390 | Acc: 58.350 (2652/4545)
4
Train Loss: 2.059 | Acc: 35.490 (1613/4545)
Train Loss: 1.914 | Acc: 40.880 (1858/4545)
5
Train Loss: 2.225 | Acc: 11.309 (514/4545)
Train Loss: 2.149 | Acc: 14.653 (666/4545)
6
Train Loss: 1.854 | Acc: 34.081 (1549/4545)
Train Loss: 1.761 | Acc: 38.922 (1769/4545)
7
Train Loss: 3.349 | Acc: 0.044 (2/4545)
Train Loss: 3.212 | Acc: 0.066 (3/4545)
8
Train Loss: 2.197 | Acc: 24.444 (1111/4545)
Train Loss: 2.067 | Acc: 30.539 (1388/4545)
9
Train Loss: 2.222 | Acc: 18.460 (839/4545)
Train Loss: 2.126 | Acc: 22.090 (1004/4545)
10
Train Loss: 1.234 | Acc: 66.293 (3013/4545)
Train Loss: 1.139 | Acc: 72.035 (3274/4545)
layer3.1
1.bn1
layer1.1
layer4.0
1.conv1
linear
layer2.0
layer4.1
layer3.0
layer1.0
layer2.1
Test Loss: 1.802 | Acc: 35.710 (3571/10000)
mseloss[1]:0.8232836127281189, 1.0680023431777954, 0.5145739316940308, 0.16221337020397186
mseloss[2]:0.8119418621063232, 0.7679294347763062, 0.30702564120292664, 0.11121483892202377
mseloss[3]:0.8263131380081177, 1.1536864042282104, 0.5440648198127747, 0.15916992723941803
mseloss[4]:0.8416632413864136, 1.1064695119857788, 0.5348878502845764, 0.1688651442527771
mseloss[5]:0.7899507284164429, 0.6642506718635559, 0.23940972983837128, 0.09370140731334686
mseloss[6]:0.7830098271369934, 0.9151840806007385, 0.4509689509868622, 0.1523752510547638
mseloss[7]:0.7718805074691772, 0.6698350310325623, 0.2652592658996582, 0.0992947593331337
mseloss[8]:0.7832165956497192, 0.808624267578125, 0.40022924542427063, 0.18812203407287598
mseloss[9]:0.7845583558082581, 0.9550174474716187, 0.45499396324157715, 0.13856849074363708
Epoch:102
0
Train Loss: 3.203 | Acc: 0.066 (3/4545)
Train Loss: 2.792 | Acc: 1.034 (47/4545)
1
Train Loss: 2.141 | Acc: 14.829 (674/4545)
Train Loss: 1.907 | Acc: 26.051 (1184/4545)
2
Train Loss: 1.682 | Acc: 52.431 (2383/4545)
Train Loss: 1.394 | Acc: 62.772 (2853/4545)
3
Train Loss: 1.777 | Acc: 38.482 (1749/4545)
Train Loss: 1.508 | Acc: 53.025 (2410/4545)
4
Train Loss: 1.346 | Acc: 61.232 (2783/4545)
Train Loss: 1.165 | Acc: 71.727 (3260/4545)
5
Train Loss: 1.721 | Acc: 26.733 (1215/4545)
Train Loss: 1.440 | Acc: 47.481 (2158/4545)
6
Train Loss: 1.979 | Acc: 35.424 (1610/4545)
Train Loss: 1.576 | Acc: 52.673 (2394/4545)
7
Train Loss: 1.120 | Acc: 69.659 (3166/4545)
Train Loss: 0.887 | Acc: 80.968 (3680/4545)
8
Train Loss: 2.259 | Acc: 21.408 (973/4545)
Train Loss: 1.856 | Acc: 40.638 (1847/4545)
9
Train Loss: 2.536 | Acc: 2.024 (92/4545)
Train Loss: 2.137 | Acc: 10.825 (492/4545)
10
Train Loss: 2.145 | Acc: 21.804 (991/4545)
Train Loss: 1.862 | Acc: 34.653 (1575/4545)
layer3.0
1.conv1
layer2.1
layer2.0
1.bn1
layer1.1
layer4.0
layer4.1
linear
layer3.1
layer1.0
Test Loss: 1.810 | Acc: 36.120 (3612/10000)
mseloss[1]:0.775683581829071, 0.6484204530715942, 0.24897338449954987, 0.09919491410255432
mseloss[2]:0.8126742243766785, 1.0298702716827393, 0.5359405279159546, 0.16618642210960388
mseloss[3]:0.778317391872406, 0.7343811988830566, 0.3392787277698517, 0.1237516850233078
mseloss[4]:0.79173743724823, 1.0699845552444458, 0.539842963218689, 0.15407079458236694
mseloss[5]:0.7730152606964111, 0.6506900191307068, 0.2562834322452545, 0.09832403063774109
mseloss[6]:0.8074002861976624, 1.029503583908081, 0.5456373691558838, 0.16772086918354034
mseloss[7]:0.7937169075012207, 1.01171875, 0.5180959701538086, 0.16817769408226013
mseloss[8]:0.7862029075622559, 0.8611997365951538, 0.5202221870422363, 0.20696285367012024
mseloss[9]:0.7724369764328003, 0.6712559461593628, 0.2746151387691498, 0.09820298105478287
Epoch:103
0
Train Loss: 2.044 | Acc: 18.548 (843/4545)
Train Loss: 1.590 | Acc: 44.048 (2002/4545)
1
Train Loss: 1.466 | Acc: 59.912 (2723/4545)
Train Loss: 1.013 | Acc: 74.719 (3396/4545)
2
Train Loss: 2.921 | Acc: 1.276 (58/4545)
Train Loss: 2.165 | Acc: 16.722 (760/4545)
3
Train Loss: 2.101 | Acc: 11.727 (533/4545)
Train Loss: 1.388 | Acc: 58.592 (2663/4545)
4
Train Loss: 1.659 | Acc: 37.976 (1726/4545)
Train Loss: 1.186 | Acc: 70.693 (3213/4545)
5
Train Loss: 1.858 | Acc: 35.424 (1610/4545)
Train Loss: 1.375 | Acc: 59.274 (2694/4545)
6
Train Loss: 1.357 | Acc: 65.853 (2993/4545)
Train Loss: 0.997 | Acc: 79.934 (3633/4545)
7
Train Loss: 1.687 | Acc: 45.677 (2076/4545)
Train Loss: 1.221 | Acc: 70.253 (3193/4545)
8
Train Loss: 1.317 | Acc: 65.831 (2992/4545)
Train Loss: 0.776 | Acc: 86.359 (3925/4545)
9
Train Loss: 2.002 | Acc: 40.484 (1840/4545)
Train Loss: 1.211 | Acc: 67.635 (3074/4545)
10
Train Loss: 1.665 | Acc: 52.079 (2367/4545)
Train Loss: 1.176 | Acc: 77.294 (3513/4545)
layer1.1
layer3.0
linear
layer2.1
1.bn1
layer1.0
layer2.0
1.conv1
layer4.0
layer4.1
layer3.1
Test Loss: 1.886 | Acc: 31.530 (3153/10000)
mseloss[1]:0.8133291602134705, 0.9482711553573608, 0.4317035377025604, 0.14507271349430084
mseloss[2]:0.7761515974998474, 0.6442552804946899, 0.2569305896759033, 0.10741093754768372
mseloss[3]:0.7907025814056396, 0.6612392663955688, 0.26572585105895996, 0.11271774768829346
mseloss[4]:0.8090880513191223, 0.7996349930763245, 0.34232452511787415, 0.13511338829994202
mseloss[5]:0.801123857498169, 0.7382125854492188, 0.29820722341537476, 0.11574464291334152
mseloss[6]:0.8286082148551941, 1.1607707738876343, 0.5455621480941772, 0.17658333480358124
mseloss[7]:0.8041080236434937, 0.773845374584198, 0.32373473048210144, 0.13606767356395721
mseloss[8]:0.7824889421463013, 0.9225201606750488, 0.41971734166145325, 0.15350329875946045
mseloss[9]:0.8148389458656311, 1.1059051752090454, 0.5659112334251404, 0.1930207908153534
Epoch:104
0
Train Loss: 0.963 | Acc: 75.380 (3426/4545)
Train Loss: 0.464 | Acc: 91.639 (4165/4545)
1
Train Loss: 1.999 | Acc: 29.945 (1361/4545)
Train Loss: 1.177 | Acc: 69.153 (3143/4545)
2
Train Loss: 1.462 | Acc: 54.411 (2473/4545)
Train Loss: 0.807 | Acc: 85.171 (3871/4545)
3
Train Loss: 1.806 | Acc: 35.402 (1609/4545)
Train Loss: 0.786 | Acc: 89.417 (4064/4545)
4
Train Loss: 1.718 | Acc: 49.329 (2242/4545)
Train Loss: 0.939 | Acc: 85.567 (3889/4545)
5
Train Loss: 1.294 | Acc: 64.620 (2937/4545)
Train Loss: 0.778 | Acc: 84.092 (3822/4545)
6
Train Loss: 1.518 | Acc: 43.982 (1999/4545)
Train Loss: 0.830 | Acc: 82.068 (3730/4545)
7
Train Loss: 1.759 | Acc: 47.415 (2155/4545)
Train Loss: 0.809 | Acc: 80.660 (3666/4545)
8
Train Loss: 2.078 | Acc: 18.856 (857/4545)
Train Loss: 1.379 | Acc: 56.766 (2580/4545)
9
Train Loss: 2.085 | Acc: 23.256 (1057/4545)
Train Loss: 1.171 | Acc: 67.767 (3080/4545)
10
Train Loss: 1.422 | Acc: 63.344 (2879/4545)
Train Loss: 0.772 | Acc: 82.112 (3732/4545)
layer1.1
layer2.0
layer1.0
layer2.1
linear
1.bn1
1.conv1
layer3.1
layer4.0
layer4.1
layer3.0
Test Loss: 1.908 | Acc: 32.320 (3232/10000)
mseloss[1]:0.8037115335464478, 0.7784645557403564, 0.37474626302719116, 0.15865536034107208
mseloss[2]:0.7904804348945618, 0.846462070941925, 0.42561718821525574, 0.20897501707077026
mseloss[3]:0.8109416365623474, 1.0671460628509521, 0.6030598282814026, 0.21866706013679504
mseloss[4]:0.810306966304779, 0.8927323818206787, 0.529680073261261, 0.24489575624465942
mseloss[5]:0.7725260853767395, 0.6519864201545715, 0.28360262513160706, 0.13427969813346863
mseloss[6]:0.7835336327552795, 0.9703909158706665, 0.5392321348190308, 0.2101626843214035
mseloss[7]:0.8034055233001709, 0.6141587495803833, 0.24905180931091309, 0.13349972665309906
mseloss[8]:0.7808585166931152, 0.8986959457397461, 0.4419185221195221, 0.18939770758152008
mseloss[9]:0.7924803495407104, 0.9955266118049622, 0.5676179528236389, 0.20220229029655457
Epoch:105
0
Train Loss: 1.741 | Acc: 31.925 (1451/4545)
Train Loss: 0.614 | Acc: 88.031 (4001/4545)
1
Train Loss: 2.637 | Acc: 11.133 (506/4545)
Train Loss: 1.053 | Acc: 70.803 (3218/4545)
2
Train Loss: 0.857 | Acc: 76.326 (3469/4545)
Train Loss: 0.485 | Acc: 89.659 (4075/4545)
3
Train Loss: 2.051 | Acc: 31.661 (1439/4545)
Train Loss: 0.688 | Acc: 89.109 (4050/4545)
4
Train Loss: 1.120 | Acc: 59.890 (2722/4545)
Train Loss: 0.532 | Acc: 87.085 (3958/4545)
5
Train Loss: 0.903 | Acc: 69.373 (3153/4545)
Train Loss: 0.332 | Acc: 93.267 (4239/4545)
6
Train Loss: 2.098 | Acc: 19.824 (901/4545)
Train Loss: 0.868 | Acc: 80.176 (3644/4545)
7
Train Loss: 2.466 | Acc: 13.223 (601/4545)
Train Loss: 1.042 | Acc: 73.289 (3331/4545)
8
Train Loss: 0.780 | Acc: 80.352 (3652/4545)
Train Loss: 0.417 | Acc: 91.265 (4148/4545)
9
Train Loss: 2.379 | Acc: 6.029 (274/4545)
Train Loss: 1.128 | Acc: 62.310 (2832/4545)
10
Train Loss: 2.296 | Acc: 17.712 (805/4545)
Train Loss: 0.745 | Acc: 89.769 (4080/4545)
layer1.0
linear
1.conv1
layer2.1
layer2.0
layer3.1
layer4.1
1.bn1
layer1.1
layer4.0
layer3.0
Test Loss: 1.980 | Acc: 28.320 (2832/10000)
mseloss[1]:0.772682785987854, 0.6275138258934021, 0.28668493032455444, 0.13117103278636932
mseloss[2]:0.8147373199462891, 0.9550478458404541, 0.625174880027771, 0.2370368093252182
mseloss[3]:0.7881979942321777, 0.8243793249130249, 0.5718636512756348, 0.23212628066539764
mseloss[4]:0.7941861152648926, 0.9486798048019409, 0.5607272386550903, 0.21767368912696838
mseloss[5]:0.7825309038162231, 0.8938279747962952, 0.5373116135597229, 0.2323528528213501
mseloss[6]:0.7967389225959778, 0.7670917510986328, 0.4584328532218933, 0.2047795057296753
mseloss[7]:0.783177375793457, 0.8089473843574524, 0.5084591507911682, 0.2090282440185547
mseloss[8]:0.8219090104103088, 0.9651731252670288, 0.6689059734344482, 0.24349693953990936
mseloss[9]:0.804736852645874, 0.7222968935966492, 0.3592517673969269, 0.19306497275829315
Epoch:106
0
Train Loss: 0.871 | Acc: 81.166 (3689/4545)
Train Loss: 0.241 | Acc: 96.282 (4376/4545)
1
Train Loss: 1.445 | Acc: 61.122 (2778/4545)
Train Loss: 0.426 | Acc: 94.411 (4291/4545)
2
Train Loss: 1.240 | Acc: 57.976 (2635/4545)
Train Loss: 0.506 | Acc: 89.153 (4052/4545)
3
Train Loss: 1.417 | Acc: 53.113 (2414/4545)
Train Loss: 0.313 | Acc: 95.776 (4353/4545)
4
Train Loss: 1.575 | Acc: 44.752 (2034/4545)
Train Loss: 0.561 | Acc: 83.608 (3800/4545)
5
Train Loss: 1.694 | Acc: 45.875 (2085/4545)
Train Loss: 0.345 | Acc: 98.548 (4479/4545)
6
Train Loss: 1.036 | Acc: 72.651 (3302/4545)
Train Loss: 0.433 | Acc: 88.757 (4034/4545)
7
Train Loss: 1.154 | Acc: 67.547 (3070/4545)
Train Loss: 0.173 | Acc: 99.868 (4539/4545)
8
Train Loss: 2.113 | Acc: 38.438 (1747/4545)
Train Loss: 0.566 | Acc: 87.393 (3972/4545)
9
Train Loss: 1.787 | Acc: 35.072 (1594/4545)
Train Loss: 0.582 | Acc: 88.427 (4019/4545)
10
Train Loss: 1.512 | Acc: 46.623 (2119/4545)
Train Loss: 0.394 | Acc: 94.103 (4277/4545)
layer4.1
1.bn1
layer4.0
layer3.0
layer2.0
1.conv1
layer2.1
layer1.0
linear
layer3.1
layer1.1
Test Loss: 1.925 | Acc: 31.140 (3114/10000)
mseloss[1]:0.7893585562705994, 0.7940306663513184, 0.4806867241859436, 0.258785605430603
mseloss[2]:0.7722102403640747, 0.5194997787475586, 0.21379585564136505, 0.12849347293376923
mseloss[3]:0.7829499244689941, 0.8742759823799133, 0.5495563745498657, 0.2653096616268158
mseloss[4]:0.7797235250473022, 0.8137232065200806, 0.4632509648799896, 0.268778532743454
mseloss[5]:0.7914783358573914, 0.9223934412002563, 0.6236982941627502, 0.2501446008682251
mseloss[6]:0.7737278938293457, 0.6320056915283203, 0.3242167830467224, 0.17658600211143494
mseloss[7]:0.8104503154754639, 0.9638789296150208, 0.6828567385673523, 0.2878916263580322
mseloss[8]:0.8023139238357544, 0.6147727370262146, 0.3122580349445343, 0.15469114482402802
mseloss[9]:0.806974470615387, 0.8303267359733582, 0.6000695824623108, 0.2773926258087158
Epoch:107
0
Train Loss: 0.650 | Acc: 84.730 (3851/4545)
Train Loss: 0.081 | Acc: 99.956 (4543/4545)
1
Train Loss: 0.868 | Acc: 71.529 (3251/4545)
Train Loss: 0.146 | Acc: 98.064 (4457/4545)
2
Train Loss: 1.124 | Acc: 70.319 (3196/4545)
Train Loss: 0.352 | Acc: 92.123 (4187/4545)
3
Train Loss: 1.464 | Acc: 46.447 (2111/4545)
Train Loss: 0.444 | Acc: 85.061 (3866/4545)
4
Train Loss: 1.808 | Acc: 35.864 (1630/4545)
Train Loss: 0.289 | Acc: 94.675 (4303/4545)
5
Train Loss: 1.364 | Acc: 56.876 (2585/4545)
Train Loss: 0.312 | Acc: 93.333 (4242/4545)
6
Train Loss: 1.553 | Acc: 51.529 (2342/4545)
Train Loss: 0.287 | Acc: 95.666 (4348/4545)
7
Train Loss: 0.974 | Acc: 68.845 (3129/4545)
Train Loss: 0.382 | Acc: 89.373 (4062/4545)
8
Train Loss: 1.365 | Acc: 60.264 (2739/4545)
Train Loss: 0.380 | Acc: 93.421 (4246/4545)
9
Train Loss: 1.552 | Acc: 47.547 (2161/4545)
Train Loss: 0.232 | Acc: 95.292 (4331/4545)
10
Train Loss: 2.117 | Acc: 28.405 (1291/4545)
Train Loss: 0.237 | Acc: 98.966 (4498/4545)
layer2.0
layer1.0
layer3.0
1.conv1
1.bn1
layer4.0
layer4.1
layer2.1
layer3.1
linear
layer1.1
Test Loss: 2.023 | Acc: 28.590 (2859/10000)
mseloss[1]:0.7737396359443665, 0.6161171793937683, 0.3054031431674957, 0.2057575285434723
mseloss[2]:0.8173501491546631, 0.9590865969657898, 0.687140941619873, 0.287424772977829
mseloss[3]:0.7746292352676392, 0.5829575657844543, 0.334603875875473, 0.3014993667602539
mseloss[4]:0.7658673524856567, 0.7050216794013977, 0.42999082803726196, 0.21191814541816711
mseloss[5]:0.8086537718772888, 0.942620038986206, 0.7041212916374207, 0.2869857847690582
mseloss[6]:0.7824171781539917, 0.6739044785499573, 0.36703789234161377, 0.2088785022497177
mseloss[7]:0.7985667586326599, 0.9167839884757996, 0.6081642508506775, 0.29884061217308044
mseloss[8]:0.785293459892273, 0.8037868142127991, 0.5695658922195435, 0.18476803600788116
mseloss[9]:0.792924702167511, 0.8613489270210266, 0.5671603083610535, 0.2736758589744568
Epoch:108
0
Train Loss: 1.898 | Acc: 39.252 (1784/4545)
Train Loss: 0.127 | Acc: 99.846 (4538/4545)
1
Train Loss: 1.915 | Acc: 36.062 (1639/4545)
Train Loss: 0.225 | Acc: 95.776 (4353/4545)
2
Train Loss: 0.800 | Acc: 73.707 (3350/4545)
Train Loss: 0.132 | Acc: 97.140 (4415/4545)
3
Train Loss: 0.988 | Acc: 69.703 (3168/4545)
Train Loss: 0.351 | Acc: 89.813 (4082/4545)
4
Train Loss: 1.267 | Acc: 60.484 (2749/4545)
Train Loss: 0.163 | Acc: 97.690 (4440/4545)
5
Train Loss: 1.133 | Acc: 62.794 (2854/4545)
Train Loss: 0.140 | Acc: 97.998 (4454/4545)
6
Train Loss: 1.353 | Acc: 62.024 (2819/4545)
Train Loss: 0.304 | Acc: 95.028 (4319/4545)
7
Train Loss: 0.770 | Acc: 82.618 (3755/4545)
Train Loss: 0.290 | Acc: 93.069 (4230/4545)
8
Train Loss: 1.428 | Acc: 52.849 (2402/4545)
Train Loss: 0.109 | Acc: 99.978 (4544/4545)
9
Train Loss: 0.701 | Acc: 80.044 (3638/4545)
Train Loss: 0.242 | Acc: 94.147 (4279/4545)
10
Train Loss: 1.781 | Acc: 37.030 (1683/4545)
Train Loss: 0.422 | Acc: 85.897 (3904/4545)
layer3.0
layer2.1
linear
layer1.1
layer2.0
layer3.1
1.bn1
layer4.1
layer4.0
1.conv1
layer1.0
Test Loss: 2.359 | Acc: 18.430 (1843/10000)
mseloss[1]:0.7832343578338623, 0.7714056372642517, 0.5463560819625854, 0.25638774037361145
mseloss[2]:0.808128833770752, 0.8577614426612854, 0.6799293756484985, 0.344156414270401
mseloss[3]:0.8318070769309998, 0.9290589690208435, 0.6829215288162231, 0.2965078055858612
mseloss[4]:0.7866675853729248, 0.7624151110649109, 0.5723358392715454, 0.27169305086135864
mseloss[5]:0.8123610019683838, 0.6920998096466064, 0.4812504053115845, 0.29915350675582886
mseloss[6]:0.77781742811203, 0.6861079335212708, 0.46645867824554443, 0.18222878873348236
mseloss[7]:0.8267749547958374, 0.8985901474952698, 0.7745559215545654, 0.31585296988487244
mseloss[8]:0.7697433233261108, 0.5895995497703552, 0.41497913002967834, 0.19881926476955414
mseloss[9]:0.8397146463394165, 0.9432709813117981, 0.8611603379249573, 0.3426642119884491
Epoch:109
0
Train Loss: 0.421 | Acc: 93.663 (4257/4545)
Train Loss: 0.041 | Acc: 100.000 (4545/4545)
1
Train Loss: 1.762 | Acc: 39.142 (1779/4545)
Train Loss: 0.396 | Acc: 86.777 (3944/4545)
2
Train Loss: 1.413 | Acc: 47.129 (2142/4545)
Train Loss: 0.240 | Acc: 95.622 (4346/4545)
3
Train Loss: 1.010 | Acc: 65.809 (2991/4545)
Train Loss: 0.119 | Acc: 98.350 (4470/4545)
4
Train Loss: 0.960 | Acc: 65.655 (2984/4545)
Train Loss: 0.043 | Acc: 99.956 (4543/4545)
5
Train Loss: 1.189 | Acc: 60.352 (2743/4545)
Train Loss: 0.318 | Acc: 90.231 (4101/4545)
6
Train Loss: 1.606 | Acc: 55.336 (2515/4545)
Train Loss: 0.307 | Acc: 92.651 (4211/4545)
7
Train Loss: 1.084 | Acc: 60.198 (2736/4545)
Train Loss: 0.135 | Acc: 96.304 (4377/4545)
8
Train Loss: 1.209 | Acc: 53.135 (2415/4545)
Train Loss: 0.108 | Acc: 98.328 (4469/4545)
9
Train Loss: 1.550 | Acc: 55.886 (2540/4545)
Train Loss: 0.148 | Acc: 96.700 (4395/4545)
10
Train Loss: 2.136 | Acc: 45.875 (2085/4545)
Train Loss: 0.256 | Acc: 93.839 (4265/4545)
layer4.0
layer1.0
layer4.1
layer3.1
1.conv1
layer2.1
linear
layer3.0
1.bn1
layer2.0
layer1.1
Test Loss: 2.111 | Acc: 28.150 (2815/10000)
mseloss[1]:0.7720422744750977, 0.5697663426399231, 0.42187216877937317, 0.39665210247039795
mseloss[2]:0.7829940915107727, 0.7565256357192993, 0.6102286577224731, 0.174168199300766
mseloss[3]:0.7815694808959961, 0.6380518674850464, 0.4145765006542206, 0.24174483120441437
mseloss[4]:0.7707049250602722, 0.5887286067008972, 0.43147197365760803, 0.20774318277835846
mseloss[5]:0.8008233904838562, 0.819240927696228, 0.7494631409645081, 0.34146934747695923
mseloss[6]:0.8190383911132812, 0.8770312070846558, 0.8119418621063232, 0.31220191717147827
mseloss[7]:0.7669031023979187, 0.6574937105178833, 0.5234216451644897, 0.27007827162742615
mseloss[8]:0.7742884755134583, 0.6402462720870972, 0.40756291151046753, 0.2616041600704193
mseloss[9]:0.7904836535453796, 0.763386070728302, 0.629923403263092, 0.282450407743454
Epoch:110
0
Train Loss: 0.743 | Acc: 74.367 (3380/4545)
Train Loss: 0.032 | Acc: 100.000 (4545/4545)
1
Train Loss: 1.357 | Acc: 64.136 (2915/4545)
Train Loss: 0.251 | Acc: 93.223 (4237/4545)
2
Train Loss: 0.680 | Acc: 75.952 (3452/4545)
Train Loss: 0.106 | Acc: 96.678 (4394/4545)
3
Train Loss: 1.484 | Acc: 60.616 (2755/4545)
Train Loss: 0.117 | Acc: 97.492 (4431/4545)
4
Train Loss: 1.817 | Acc: 34.697 (1577/4545)
Train Loss: 0.216 | Acc: 95.534 (4342/4545)
5
Train Loss: 0.975 | Acc: 74.015 (3364/4545)
Train Loss: 0.094 | Acc: 98.460 (4475/4545)
6
Train Loss: 1.029 | Acc: 65.655 (2984/4545)
Train Loss: 0.269 | Acc: 90.869 (4130/4545)
7
Train Loss: 0.941 | Acc: 65.919 (2996/4545)
Train Loss: 0.074 | Acc: 98.746 (4488/4545)
8
Train Loss: 0.555 | Acc: 82.860 (3766/4545)
Train Loss: 0.027 | Acc: 100.000 (4545/4545)
9
Train Loss: 1.563 | Acc: 57.404 (2609/4545)
Train Loss: 0.190 | Acc: 94.697 (4304/4545)
10
Train Loss: 1.373 | Acc: 50.649 (2302/4545)
Train Loss: 0.318 | Acc: 87.745 (3988/4545)
layer1.1
layer1.0
layer2.0
linear
layer4.1
1.conv1
layer3.0
layer3.1
1.bn1
layer4.0
layer2.1
Test Loss: 2.697 | Acc: 18.170 (1817/10000)
mseloss[1]:0.8174589276313782, 0.8903849720954895, 0.7883040904998779, 0.32214266061782837
mseloss[2]:0.7682737112045288, 0.6740301251411438, 0.5301335453987122, 0.2823755145072937
mseloss[3]:0.7917709946632385, 0.7949866056442261, 0.6148647665977478, 0.27225610613822937
mseloss[4]:0.7854293584823608, 0.7910954356193542, 0.6167699098587036, 0.16601189970970154
mseloss[5]:0.7815057635307312, 0.6553963422775269, 0.41415831446647644, 0.22616174817085266
mseloss[6]:0.8003963828086853, 0.8533733487129211, 0.7189273238182068, 0.3575115501880646
mseloss[7]:0.7739883661270142, 0.633204460144043, 0.3881261348724365, 0.26437732577323914
mseloss[8]:0.7746741771697998, 0.6027549505233765, 0.4396936297416687, 0.20882509648799896
mseloss[9]:0.8096863627433777, 0.9175114631652832, 0.8203808069229126, 0.3090800940990448
Epoch:111
0
Train Loss: 1.254 | Acc: 64.158 (2916/4545)
Train Loss: 0.085 | Acc: 97.976 (4453/4545)
1
Train Loss: 1.274 | Acc: 62.178 (2826/4545)
Train Loss: 0.029 | Acc: 100.000 (4545/4545)
2
Train Loss: 0.739 | Acc: 74.653 (3393/4545)
Train Loss: 0.291 | Acc: 88.625 (4028/4545)
3
Train Loss: 0.615 | Acc: 79.142 (3597/4545)
Train Loss: 0.094 | Acc: 96.898 (4404/4545)
4
Train Loss: 0.752 | Acc: 77.888 (3540/4545)
Train Loss: 0.064 | Acc: 98.812 (4491/4545)
5
Train Loss: 1.247 | Acc: 68.999 (3136/4545)
Train Loss: 0.234 | Acc: 93.465 (4248/4545)
6
Train Loss: 2.002 | Acc: 44.092 (2004/4545)
Train Loss: 0.192 | Acc: 95.710 (4350/4545)
7
Train Loss: 0.533 | Acc: 82.662 (3757/4545)
Train Loss: 0.237 | Acc: 91.903 (4177/4545)
8
Train Loss: 1.677 | Acc: 54.587 (2481/4545)
Train Loss: 0.188 | Acc: 94.477 (4294/4545)
9
Train Loss: 0.835 | Acc: 69.769 (3171/4545)
Train Loss: 0.065 | Acc: 98.768 (4489/4545)
10
Train Loss: 1.097 | Acc: 65.699 (2986/4545)
Train Loss: 0.024 | Acc: 100.000 (4545/4545)
layer2.1
layer2.0
layer1.0
layer1.1
layer3.0
1.bn1
layer3.1
layer4.1
1.conv1
linear
layer4.0
Test Loss: 2.732 | Acc: 24.910 (2491/10000)
mseloss[1]:0.7894524335861206, 0.8082148432731628, 0.5764861106872559, 0.28247708082199097
mseloss[2]:0.7750453352928162, 0.6932262778282166, 0.47061610221862793, 0.488952100276947
mseloss[3]:0.7978646159172058, 0.667640745639801, 0.48267611861228943, 0.3831580579280853
mseloss[4]:0.7824463248252869, 0.7205108404159546, 0.4809044897556305, 0.3839166462421417
mseloss[5]:0.7697203755378723, 0.5230129957199097, 0.3106229901313782, 0.2056739181280136
mseloss[6]:0.8019325733184814, 0.765011191368103, 0.5787321925163269, 0.3077598810195923
mseloss[7]:0.7701860070228577, 0.6099751591682434, 0.39848560094833374, 0.28485196828842163
mseloss[8]:0.7946867942810059, 0.608241617679596, 0.3553098738193512, 0.22253115475177765
mseloss[9]:0.7748084664344788, 0.748392641544342, 0.48533201217651367, 0.3643409013748169
Epoch:112
0
Train Loss: 0.303 | Acc: 91.375 (4153/4545)
Train Loss: 0.069 | Acc: 98.152 (4461/4545)
1
Train Loss: 1.265 | Acc: 63.498 (2886/4545)
Train Loss: 0.018 | Acc: 100.000 (4545/4545)
2
Train Loss: 0.560 | Acc: 85.655 (3893/4545)
Train Loss: 0.056 | Acc: 98.856 (4493/4545)
3
Train Loss: 1.225 | Acc: 56.744 (2579/4545)
Train Loss: 0.258 | Acc: 91.243 (4147/4545)
4
Train Loss: 0.994 | Acc: 70.187 (3190/4545)
Train Loss: 0.156 | Acc: 95.578 (4344/4545)
5
Train Loss: 1.154 | Acc: 64.312 (2923/4545)
Train Loss: 0.096 | Acc: 96.876 (4403/4545)
6
Train Loss: 0.795 | Acc: 71.463 (3248/4545)
Train Loss: 0.203 | Acc: 93.773 (4262/4545)
7
Train Loss: 0.615 | Acc: 79.978 (3635/4545)
Train Loss: 0.049 | Acc: 98.878 (4494/4545)
8
Train Loss: 1.508 | Acc: 53.289 (2422/4545)
Train Loss: 0.290 | Acc: 88.493 (4022/4545)
9
Train Loss: 0.887 | Acc: 67.943 (3088/4545)
Train Loss: 0.025 | Acc: 100.000 (4545/4545)
10
Train Loss: 0.516 | Acc: 86.293 (3922/4545)
Train Loss: 0.163 | Acc: 95.072 (4321/4545)
linear
layer1.0
1.conv1
layer3.1
1.bn1
layer3.0
layer4.0
layer2.0
layer4.1
layer2.1
layer1.1
Test Loss: 3.014 | Acc: 17.350 (1735/10000)
mseloss[1]:0.809669554233551, 0.8493776917457581, 0.7102157473564148, 0.3521032929420471
mseloss[2]:0.7832249402999878, 0.7084951400756836, 0.4550219476222992, 0.36321204900741577
mseloss[3]:0.7719041109085083, 0.6220430731773376, 0.41648805141448975, 0.282998263835907
mseloss[4]:0.8025031685829163, 0.7620542645454407, 0.5650880336761475, 0.2929592728614807
mseloss[5]:0.7995932698249817, 0.6593058705329895, 0.4366808235645294, 0.33753204345703125
mseloss[6]:0.7717053294181824, 0.5364188551902771, 0.32637158036231995, 0.21520672738552094
mseloss[7]:0.7747132182121277, 0.7250034809112549, 0.48041054606437683, 0.37375184893608093
mseloss[8]:0.7757341265678406, 0.681890070438385, 0.45324409008026123, 0.43690600991249084
mseloss[9]:0.7923117876052856, 0.8086676001548767, 0.5800675749778748, 0.27423545718193054
Epoch:113
0
Train Loss: 0.557 | Acc: 81.804 (3718/4545)
Train Loss: 0.067 | Acc: 97.976 (4453/4545)
1
Train Loss: 0.395 | Acc: 89.923 (4087/4545)
Train Loss: 0.048 | Acc: 98.790 (4490/4545)
2
Train Loss: 0.402 | Acc: 87.877 (3994/4545)
Train Loss: 0.010 | Acc: 100.000 (4545/4545)
3
Train Loss: 0.628 | Acc: 83.938 (3815/4545)
Train Loss: 0.187 | Acc: 94.521 (4296/4545)
4
Train Loss: 0.749 | Acc: 75.908 (3450/4545)
Train Loss: 0.161 | Acc: 95.050 (4320/4545)
5
Train Loss: 1.451 | Acc: 59.252 (2693/4545)
Train Loss: 0.153 | Acc: 95.688 (4349/4545)
6
Train Loss: 1.334 | Acc: 63.762 (2898/4545)
Train Loss: 0.021 | Acc: 100.000 (4545/4545)
7
Train Loss: 0.560 | Acc: 82.420 (3746/4545)
Train Loss: 0.224 | Acc: 92.255 (4193/4545)
8
Train Loss: 0.841 | Acc: 70.495 (3204/4545)
Train Loss: 0.050 | Acc: 98.834 (4492/4545)
9
Train Loss: 0.933 | Acc: 67.415 (3064/4545)
Train Loss: 0.270 | Acc: 89.351 (4061/4545)
10
Train Loss: 0.926 | Acc: 69.373 (3153/4545)
Train Loss: 0.086 | Acc: 96.986 (4408/4545)
layer4.0
layer3.0
layer1.0
linear
layer2.0
1.bn1
layer3.1
layer4.1
layer2.1
1.conv1
layer1.1
Test Loss: 2.834 | Acc: 24.830 (2483/10000)
mseloss[1]:0.7815170288085938, 0.7460570931434631, 0.4384898245334625, 0.3647993206977844
mseloss[2]:0.8050292730331421, 0.9114168286323547, 0.6892949938774109, 0.3562380075454712
mseloss[3]:0.7696428894996643, 0.5372375845909119, 0.33061787486076355, 0.22229863703250885
mseloss[4]:0.7940698266029358, 0.63250732421875, 0.3573324382305145, 0.2342321127653122
mseloss[5]:0.79875648021698, 0.806181788444519, 0.5828222632408142, 0.30465322732925415
mseloss[6]:0.7888370156288147, 0.8571245670318604, 0.5571743845939636, 0.27808287739753723
mseloss[7]:0.7718783020973206, 0.6400662064552307, 0.4070475995540619, 0.2828882038593292
mseloss[8]:0.7733412981033325, 0.7859787344932556, 0.483356237411499, 0.3951799273490906
mseloss[9]:0.7762842178344727, 0.7324170470237732, 0.4572557806968689, 0.4499659538269043
Epoch:114
0
Train Loss: 0.859 | Acc: 72.255 (3284/4545)
Train Loss: 0.081 | Acc: 97.206 (4418/4545)
1
Train Loss: 0.683 | Acc: 74.389 (3381/4545)
Train Loss: 0.251 | Acc: 90.121 (4096/4545)
2
Train Loss: 0.654 | Acc: 79.120 (3596/4545)
Train Loss: 0.064 | Acc: 98.042 (4456/4545)
3
Train Loss: 0.279 | Acc: 92.431 (4201/4545)
Train Loss: 0.042 | Acc: 98.988 (4499/4545)
4
Train Loss: 0.793 | Acc: 74.521 (3387/4545)
Train Loss: 0.008 | Acc: 100.000 (4545/4545)
5
Train Loss: 0.469 | Acc: 83.674 (3803/4545)
Train Loss: 0.043 | Acc: 98.988 (4499/4545)
6
Train Loss: 1.262 | Acc: 62.244 (2829/4545)
Train Loss: 0.181 | Acc: 94.301 (4286/4545)
7
Train Loss: 1.281 | Acc: 62.728 (2851/4545)
Train Loss: 0.141 | Acc: 95.622 (4346/4545)
8
Train Loss: 0.675 | Acc: 73.663 (3348/4545)
Train Loss: 0.220 | Acc: 92.211 (4191/4545)
9
Train Loss: 1.024 | Acc: 70.011 (3182/4545)
Train Loss: 0.149 | Acc: 95.050 (4320/4545)
10
Train Loss: 0.816 | Acc: 72.805 (3309/4545)
Train Loss: 0.016 | Acc: 100.000 (4545/4545)
1.conv1
layer4.1
1.bn1
layer1.1
layer3.1
layer2.0
layer4.0
layer3.0
layer2.1
linear
layer1.0
Test Loss: 2.295 | Acc: 25.350 (2535/10000)
mseloss[1]:0.7955024242401123, 0.6372353434562683, 0.39768552780151367, 0.38595905900001526
mseloss[2]:0.8003934621810913, 0.7020111083984375, 0.45743486285209656, 0.3275236487388611
mseloss[3]:0.7897929549217224, 0.617973804473877, 0.36566466093063354, 0.307904452085495
mseloss[4]:0.7882481217384338, 0.8181235790252686, 0.5617117881774902, 0.25184494256973267
mseloss[5]:0.7796499133110046, 0.684311032295227, 0.4808759093284607, 0.3259558379650116
mseloss[6]:0.8023661971092224, 0.7638143301010132, 0.5814368724822998, 0.4029192328453064
mseloss[7]:0.7834442257881165, 0.7515970468521118, 0.6127274036407471, 0.28815755248069763
mseloss[8]:0.7944585680961609, 0.7937657237052917, 0.6039496660232544, 0.3917270600795746
mseloss[9]:0.8313953280448914, 0.8878660798072815, 0.733659565448761, 0.4176176190376282
Epoch:115
0
Train Loss: 0.784 | Acc: 72.893 (3313/4545)
Train Loss: 0.124 | Acc: 96.194 (4372/4545)
1
Train Loss: 0.942 | Acc: 70.715 (3214/4545)
Train Loss: 0.146 | Acc: 94.983 (4317/4545)
2
Train Loss: 0.432 | Acc: 89.417 (4064/4545)
Train Loss: 0.013 | Acc: 100.000 (4545/4545)
3
Train Loss: 0.925 | Acc: 66.865 (3039/4545)
Train Loss: 0.065 | Acc: 97.910 (4450/4545)
4
Train Loss: 0.450 | Acc: 86.557 (3934/4545)
Train Loss: 0.038 | Acc: 99.098 (4504/4545)
5
Train Loss: 0.846 | Acc: 69.659 (3166/4545)
Train Loss: 0.255 | Acc: 89.967 (4089/4545)
6
Train Loss: 0.778 | Acc: 76.326 (3469/4545)
Train Loss: 0.152 | Acc: 94.829 (4310/4545)
7
Train Loss: 0.841 | Acc: 71.375 (3244/4545)
Train Loss: 0.075 | Acc: 97.316 (4423/4545)
8
Train Loss: 0.528 | Acc: 85.259 (3875/4545)
Train Loss: 0.210 | Acc: 92.519 (4205/4545)
9
Train Loss: 0.693 | Acc: 77.668 (3530/4545)
Train Loss: 0.041 | Acc: 98.900 (4495/4545)
10
Train Loss: 0.277 | Acc: 94.631 (4301/4545)
Train Loss: 0.006 | Acc: 100.000 (4545/4545)
layer3.0
layer4.1
layer3.1
linear
layer2.0
1.bn1
layer1.1
layer1.0
layer2.1
1.conv1
layer4.0
Test Loss: 2.320 | Acc: 12.130 (1213/10000)
mseloss[1]:0.799220860004425, 0.7538352608680725, 0.6168590784072876, 0.32006341218948364
mseloss[2]:0.7812997698783875, 0.7918387651443481, 0.584682047367096, 0.18478241562843323
mseloss[3]:0.8009268045425415, 0.7612691521644592, 0.5226736068725586, 0.2814883291721344
mseloss[4]:0.7859204411506653, 0.7356159090995789, 0.5189681053161621, 0.33027565479278564
mseloss[5]:0.8004821538925171, 0.6913657784461975, 0.451435387134552, 0.3546893894672394
mseloss[6]:0.811285138130188, 0.7733120322227478, 0.616977870464325, 0.31250378489494324
mseloss[7]:0.7801467776298523, 0.7117498517036438, 0.541169285774231, 0.272457093000412
mseloss[8]:0.8027620911598206, 0.7170236706733704, 0.5065516829490662, 0.30007079243659973
mseloss[9]:0.7976003885269165, 0.7329367995262146, 0.5070443749427795, 0.29850122332572937
Epoch:116
0
Train Loss: 0.642 | Acc: 78.086 (3549/4545)
Train Loss: 0.072 | Acc: 97.448 (4429/4545)
1
Train Loss: 0.784 | Acc: 70.957 (3225/4545)
Train Loss: 0.252 | Acc: 89.791 (4081/4545)
2
Train Loss: 0.146 | Acc: 98.306 (4468/4545)
Train Loss: 0.005 | Acc: 100.000 (4545/4545)
3
Train Loss: 0.378 | Acc: 85.985 (3908/4545)
Train Loss: 0.032 | Acc: 99.032 (4501/4545)
4
Train Loss: 0.571 | Acc: 82.156 (3734/4545)
Train Loss: 0.057 | Acc: 98.108 (4459/4545)
5
Train Loss: 0.924 | Acc: 71.727 (3260/4545)
Train Loss: 0.151 | Acc: 95.028 (4319/4545)
6
Train Loss: 1.190 | Acc: 64.906 (2950/4545)
Train Loss: 0.127 | Acc: 95.908 (4359/4545)
7
Train Loss: 0.706 | Acc: 78.592 (3572/4545)
Train Loss: 0.011 | Acc: 100.000 (4545/4545)
8
Train Loss: 0.479 | Acc: 84.488 (3840/4545)
Train Loss: 0.033 | Acc: 99.252 (4511/4545)
9
Train Loss: 0.874 | Acc: 75.248 (3420/4545)
Train Loss: 0.148 | Acc: 95.028 (4319/4545)
10
Train Loss: 0.887 | Acc: 69.065 (3139/4545)
Train Loss: 0.211 | Acc: 92.541 (4206/4545)
1.conv1
layer4.0
layer1.1
layer3.1
layer3.0
layer2.0
layer2.1
linear
1.bn1
layer4.1
layer1.0
Test Loss: 3.419 | Acc: 14.970 (1497/10000)
mseloss[1]:0.7949906587600708, 0.6103466749191284, 0.42534738779067993, 0.3264392614364624
mseloss[2]:0.7818787693977356, 0.7190490961074829, 0.5149407982826233, 0.23789082467556
mseloss[3]:0.788646399974823, 0.6233630776405334, 0.4498063325881958, 0.3570843040943146
mseloss[4]:0.8006449937820435, 0.6708232760429382, 0.5042387843132019, 0.39042073488235474
mseloss[5]:0.8010767698287964, 0.7271814942359924, 0.5958993434906006, 0.4426107704639435
mseloss[6]:0.7835747003555298, 0.6984267234802246, 0.5666683316230774, 0.29860901832580566
mseloss[7]:0.765011727809906, 0.6624133586883545, 0.5646688938140869, 0.333762526512146
mseloss[8]:0.7805710434913635, 0.6492627859115601, 0.5378404855728149, 0.3784962594509125
mseloss[9]:0.8336573839187622, 0.7891805768013, 0.7708253264427185, 0.4811911880970001
Epoch:117
0
Train Loss: 0.155 | Acc: 95.908 (4359/4545)
Train Loss: 0.047 | Acc: 98.724 (4487/4545)
1
Train Loss: 1.362 | Acc: 66.095 (3004/4545)
Train Loss: 0.004 | Acc: 100.000 (4545/4545)
2
Train Loss: 0.915 | Acc: 68.713 (3123/4545)
Train Loss: 0.191 | Acc: 93.135 (4233/4545)
3
Train Loss: 0.398 | Acc: 89.527 (4069/4545)
Train Loss: 0.036 | Acc: 99.098 (4504/4545)
4
Train Loss: 0.747 | Acc: 73.267 (3330/4545)
Train Loss: 0.130 | Acc: 95.600 (4345/4545)
5
Train Loss: 1.216 | Acc: 68.141 (3097/4545)
Train Loss: 0.073 | Acc: 97.646 (4438/4545)
6
Train Loss: 0.843 | Acc: 68.449 (3111/4545)
Train Loss: 0.254 | Acc: 89.967 (4089/4545)
7
Train Loss: 0.457 | Acc: 85.457 (3884/4545)
Train Loss: 0.033 | Acc: 99.098 (4504/4545)
8
Train Loss: 1.826 | Acc: 53.883 (2449/4545)
Train Loss: 0.116 | Acc: 95.974 (4362/4545)
9
Train Loss: 0.491 | Acc: 81.892 (3722/4545)
Train Loss: 0.007 | Acc: 100.000 (4545/4545)
10
Train Loss: 0.752 | Acc: 77.624 (3528/4545)
Train Loss: 0.144 | Acc: 95.314 (4332/4545)
layer3.1
layer1.0
layer4.1
layer1.1
layer2.1
1.conv1
linear
1.bn1
layer4.0
layer3.0
layer2.0
Test Loss: 3.332 | Acc: 19.610 (1961/10000)
mseloss[1]:0.8176272511482239, 0.8557178974151611, 0.7134624719619751, 0.405815064907074
mseloss[2]:0.7777328491210938, 0.6388874053955078, 0.39867720007896423, 0.3097384572029114
mseloss[3]:0.7901229858398438, 0.7018113732337952, 0.4290875792503357, 0.3876233398914337
mseloss[4]:0.7759325504302979, 0.5634483695030212, 0.33903464674949646, 0.2607109546661377
mseloss[5]:0.8069088459014893, 0.6615421175956726, 0.41181042790412903, 0.29961463809013367
mseloss[6]:0.7833030223846436, 0.6618178486824036, 0.40398159623146057, 0.40460821986198425
mseloss[7]:0.7832687497138977, 0.705862283706665, 0.43172571063041687, 0.3820614814758301
mseloss[8]:0.809257984161377, 0.7733935117721558, 0.562571108341217, 0.34522539377212524
mseloss[9]:0.7962809801101685, 0.8033661842346191, 0.5639896988868713, 0.29982057213783264
Epoch:118
0
Train Loss: 1.045 | Acc: 67.591 (3072/4545)
Train Loss: 0.121 | Acc: 96.194 (4372/4545)
1
Train Loss: 0.453 | Acc: 85.039 (3865/4545)
Train Loss: 0.053 | Acc: 98.482 (4476/4545)
2
Train Loss: 0.701 | Acc: 77.624 (3528/4545)
Train Loss: 0.039 | Acc: 98.746 (4488/4545)
3
Train Loss: 0.632 | Acc: 79.164 (3598/4545)
Train Loss: 0.004 | Acc: 100.000 (4545/4545)
4
Train Loss: 0.703 | Acc: 75.908 (3450/4545)
Train Loss: 0.062 | Acc: 97.822 (4446/4545)
5
Train Loss: 0.668 | Acc: 77.338 (3515/4545)
Train Loss: 0.191 | Acc: 93.047 (4229/4545)
6
Train Loss: 0.460 | Acc: 83.696 (3804/4545)
Train Loss: 0.034 | Acc: 98.966 (4498/4545)
7
Train Loss: 0.507 | Acc: 81.694 (3713/4545)
Train Loss: 0.244 | Acc: 90.077 (4094/4545)
8
Train Loss: 0.738 | Acc: 76.348 (3470/4545)
Train Loss: 0.106 | Acc: 96.634 (4392/4545)
9
Train Loss: 0.725 | Acc: 80.066 (3639/4545)
Train Loss: 0.141 | Acc: 95.292 (4331/4545)
10
Train Loss: 0.610 | Acc: 78.812 (3582/4545)
Train Loss: 0.005 | Acc: 100.000 (4545/4545)
layer4.0
layer1.1
layer1.0
layer2.1
layer3.1
1.bn1
linear
layer2.0
1.conv1
layer4.1
layer3.0
Test Loss: 2.384 | Acc: 16.400 (1640/10000)
mseloss[1]:0.7780004143714905, 0.5779088139533997, 0.40463316440582275, 0.2526494264602661
mseloss[2]:0.8190054297447205, 0.8429527878761292, 0.6515872478485107, 0.3756035566329956
mseloss[3]:0.8377575874328613, 0.9878643155097961, 0.8519540429115295, 0.38912737369537354
mseloss[4]:0.8106455206871033, 0.8019237518310547, 0.6704565286636353, 0.4124743640422821
mseloss[5]:0.8011296391487122, 0.6921631693840027, 0.3950512707233429, 0.23446010053157806
mseloss[6]:0.8156887292861938, 0.8614656329154968, 0.7262891530990601, 0.4898163974285126
mseloss[7]:0.8143959641456604, 0.8020371198654175, 0.6164456009864807, 0.4836054742336273
mseloss[8]:0.8202909231185913, 0.8352925181388855, 0.6656250953674316, 0.30578041076660156
mseloss[9]:0.8039668202400208, 0.6409978866577148, 0.43569818139076233, 0.16083766520023346
Epoch:119
0
Train Loss: 0.790 | Acc: 74.081 (3367/4545)
Train Loss: 0.054 | Acc: 98.218 (4464/4545)
1
Train Loss: 0.370 | Acc: 86.293 (3922/4545)
Train Loss: 0.006 | Acc: 100.000 (4545/4545)
2
Train Loss: 0.866 | Acc: 73.861 (3357/4545)
Train Loss: 0.112 | Acc: 96.216 (4373/4545)
3
Train Loss: 0.543 | Acc: 82.112 (3732/4545)
Train Loss: 0.138 | Acc: 95.270 (4330/4545)
4
Train Loss: 0.501 | Acc: 83.916 (3814/4545)
Train Loss: 0.003 | Acc: 100.000 (4545/4545)
5
Train Loss: 0.347 | Acc: 90.605 (4118/4545)
Train Loss: 0.032 | Acc: 98.922 (4496/4545)
6
Train Loss: 0.977 | Acc: 69.571 (3162/4545)
Train Loss: 0.041 | Acc: 98.768 (4489/4545)
7
Train Loss: 0.794 | Acc: 71.749 (3261/4545)
Train Loss: 0.201 | Acc: 92.673 (4212/4545)
8
Train Loss: 0.919 | Acc: 67.811 (3082/4545)
Train Loss: 0.241 | Acc: 90.539 (4115/4545)
9
Train Loss: 0.473 | Acc: 84.642 (3847/4545)
Train Loss: 0.094 | Acc: 96.810 (4400/4545)
10
Train Loss: 0.733 | Acc: 75.336 (3424/4545)
Train Loss: 0.063 | Acc: 98.086 (4458/4545)
layer2.0
layer1.1
layer3.1
layer4.1
layer4.0
layer2.1
1.bn1
1.conv1
layer3.0
linear
layer1.0
Test Loss: 2.697 | Acc: 20.990 (2099/10000)
mseloss[1]:0.7694319486618042, 0.7408838272094727, 0.6272407174110413, 0.33888429403305054
mseloss[2]:0.8057565689086914, 0.8130003213882446, 0.6411343216896057, 0.3898141384124756
mseloss[3]:0.8395969271659851, 0.8484911918640137, 0.7165185213088989, 0.3991459906101227
mseloss[4]:0.7850740551948547, 0.7491856813430786, 0.5939632654190063, 0.2934377193450928
mseloss[5]:0.7850112318992615, 0.6552847027778625, 0.5577473044395447, 0.41500964760780334
mseloss[6]:0.7950555086135864, 0.6490181684494019, 0.440825492143631, 0.3571639955043793
mseloss[7]:0.8008553385734558, 0.7481263875961304, 0.6139810681343079, 0.3629598319530487
mseloss[8]:0.8037958145141602, 0.6559564471244812, 0.559790313243866, 0.4496708810329437
mseloss[9]:0.7869335412979126, 0.725387454032898, 0.6599326729774475, 0.334513396024704
Epoch:120
0
Train Loss: 0.549 | Acc: 80.660 (3666/4545)
Train Loss: 0.050 | Acc: 98.240 (4465/4545)
1
Train Loss: 0.133 | Acc: 98.284 (4467/4545)
Train Loss: 0.003 | Acc: 100.000 (4545/4545)
2
Train Loss: 0.752 | Acc: 70.407 (3200/4545)
Train Loss: 0.222 | Acc: 91.353 (4152/4545)
3
Train Loss: 1.056 | Acc: 70.583 (3208/4545)
Train Loss: 0.035 | Acc: 98.878 (4494/4545)
4
Train Loss: 1.513 | Acc: 61.870 (2812/4545)
Train Loss: 0.004 | Acc: 100.000 (4545/4545)
5
Train Loss: 0.459 | Acc: 84.532 (3842/4545)
Train Loss: 0.173 | Acc: 93.509 (4250/4545)
6
Train Loss: 0.355 | Acc: 85.105 (3868/4545)
Train Loss: 0.029 | Acc: 99.010 (4500/4545)
7
Train Loss: 1.074 | Acc: 68.009 (3091/4545)
Train Loss: 0.060 | Acc: 98.108 (4459/4545)
8
Train Loss: 0.832 | Acc: 73.751 (3352/4545)
Train Loss: 0.140 | Acc: 95.116 (4323/4545)
9
Train Loss: 0.618 | Acc: 78.614 (3573/4545)
Train Loss: 0.087 | Acc: 97.162 (4416/4545)
10
Train Loss: 0.460 | Acc: 86.733 (3942/4545)
Train Loss: 0.109 | Acc: 96.414 (4382/4545)
layer3.0
1.conv1
layer3.1
layer1.0
linear
layer2.1
layer1.1
1.bn1
layer4.1
layer2.0
layer4.0
Test Loss: 2.769 | Acc: 19.970 (1997/10000)
mseloss[1]:0.7921762466430664, 0.7376086115837097, 0.5410680770874023, 0.27287915349006653
mseloss[2]:0.8061896562576294, 0.6320563554763794, 0.49996113777160645, 0.40768662095069885
mseloss[3]:0.7986708879470825, 0.6365667581558228, 0.4850500226020813, 0.37872931361198425
mseloss[4]:0.7783747315406799, 0.7138543725013733, 0.5901103019714355, 0.34126016497612
mseloss[5]:0.8047979474067688, 0.7182533144950867, 0.6011133193969727, 0.349046915769577
mseloss[6]:0.7992573380470276, 0.6544411182403564, 0.5729403495788574, 0.4169441759586334
mseloss[7]:0.8146420121192932, 0.6624754667282104, 0.44478029012680054, 0.3243408501148224
mseloss[8]:0.8519030213356018, 0.856246292591095, 0.7480396032333374, 0.39599916338920593
mseloss[9]:0.8000414967536926, 0.7325048446655273, 0.6567040681838989, 0.3445027768611908
Epoch:121
0
Train Loss: 0.345 | Acc: 89.505 (4068/4545)
Train Loss: 0.100 | Acc: 96.942 (4406/4545)
1
Train Loss: 0.538 | Acc: 80.330 (3651/4545)
Train Loss: 0.030 | Acc: 99.054 (4502/4545)
2
Train Loss: 0.904 | Acc: 74.015 (3364/4545)
Train Loss: 0.140 | Acc: 95.314 (4332/4545)
3
Train Loss: 0.873 | Acc: 74.631 (3392/4545)
Train Loss: 0.032 | Acc: 99.010 (4500/4545)
4
Train Loss: 0.380 | Acc: 87.283 (3967/4545)
Train Loss: 0.040 | Acc: 98.724 (4487/4545)
5
Train Loss: 0.385 | Acc: 88.097 (4004/4545)
Train Loss: 0.149 | Acc: 94.807 (4309/4545)
6
Train Loss: 0.239 | Acc: 93.091 (4231/4545)
Train Loss: 0.004 | Acc: 100.000 (4545/4545)
7
Train Loss: 0.752 | Acc: 75.094 (3413/4545)
Train Loss: 0.059 | Acc: 98.130 (4460/4545)
8
Train Loss: 0.475 | Acc: 83.696 (3804/4545)
Train Loss: 0.003 | Acc: 100.000 (4545/4545)
9
Train Loss: 0.754 | Acc: 71.881 (3267/4545)
Train Loss: 0.225 | Acc: 91.111 (4141/4545)
10
Train Loss: 1.258 | Acc: 65.479 (2976/4545)
Train Loss: 0.084 | Acc: 97.206 (4418/4545)
layer1.0
layer4.1
layer1.1
layer2.0
1.conv1
layer3.1
linear
layer2.1
layer3.0
1.bn1
layer4.0
Test Loss: 2.898 | Acc: 22.390 (2239/10000)
mseloss[1]:0.8261557221412659, 0.8404759168624878, 0.7433030009269714, 0.5583432912826538
mseloss[2]:0.8083637952804565, 0.6360331177711487, 0.33345481753349304, 0.16672220826148987
mseloss[3]:0.819953441619873, 0.818740725517273, 0.624862790107727, 0.450996458530426
mseloss[4]:0.8071303367614746, 0.7761363983154297, 0.6114733219146729, 0.38131728768348694
mseloss[5]:0.8035855293273926, 0.6977129578590393, 0.41830381751060486, 0.2863040566444397
mseloss[6]:0.8298805952072144, 0.9061140418052673, 0.762285053730011, 0.35994845628738403
mseloss[7]:0.7768476605415344, 0.616960346698761, 0.4171871542930603, 0.25950151681900024
mseloss[8]:0.8197934627532959, 0.8839103579521179, 0.7062996625900269, 0.3231763243675232
mseloss[9]:0.8146730065345764, 0.7942776083946228, 0.6399163007736206, 0.4985559284687042
Epoch:122
0
Train Loss: 0.410 | Acc: 87.943 (3997/4545)
Train Loss: 0.095 | Acc: 97.074 (4412/4545)
1
Train Loss: 0.481 | Acc: 84.620 (3846/4545)
Train Loss: 0.036 | Acc: 98.768 (4489/4545)
2
Train Loss: 0.170 | Acc: 94.059 (4275/4545)
Train Loss: 0.001 | Acc: 100.000 (4545/4545)
3
Train Loss: 0.433 | Acc: 84.708 (3850/4545)
Train Loss: 0.028 | Acc: 99.076 (4503/4545)
4
Train Loss: 0.498 | Acc: 82.816 (3764/4545)
Train Loss: 0.002 | Acc: 100.000 (4545/4545)
5
Train Loss: 0.619 | Acc: 80.198 (3645/4545)
Train Loss: 0.055 | Acc: 98.306 (4468/4545)
6
Train Loss: 0.376 | Acc: 87.283 (3967/4545)
Train Loss: 0.078 | Acc: 97.492 (4431/4545)
7
Train Loss: 0.862 | Acc: 72.739 (3306/4545)
Train Loss: 0.164 | Acc: 94.015 (4273/4545)
8
Train Loss: 0.408 | Acc: 86.293 (3922/4545)
Train Loss: 0.130 | Acc: 95.622 (4346/4545)
9
Train Loss: 0.804 | Acc: 70.055 (3184/4545)
Train Loss: 0.235 | Acc: 90.913 (4132/4545)
10
Train Loss: 0.745 | Acc: 78.020 (3546/4545)
Train Loss: 0.036 | Acc: 98.922 (4496/4545)
1.conv1
layer1.0
layer2.0
linear
layer3.1
layer1.1
layer2.1
layer4.0
layer4.1
1.bn1
layer3.0
Test Loss: 3.822 | Acc: 14.790 (1479/10000)
mseloss[1]:0.8054444789886475, 0.7749744653701782, 0.6123088002204895, 0.377739280462265
mseloss[2]:0.8250169157981873, 0.9035314917564392, 0.8131226897239685, 0.41117578744888306
mseloss[3]:0.8132225275039673, 0.81930011510849, 0.6435666680335999, 0.5310956239700317
mseloss[4]:0.8193138837814331, 0.8987899422645569, 0.7406890988349915, 0.34037554264068604
mseloss[5]:0.7723174691200256, 0.5950774550437927, 0.3803447186946869, 0.25277432799339294
mseloss[6]:0.8122402429580688, 0.7795702815055847, 0.5730363130569458, 0.3115618824958801
mseloss[7]:0.8002503514289856, 0.6873100996017456, 0.3694761395454407, 0.2305845320224762
mseloss[8]:0.7965377569198608, 0.6438098549842834, 0.395040363073349, 0.16387714445590973
mseloss[9]:0.8088958859443665, 0.789807140827179, 0.6139734983444214, 0.4877834618091583
Epoch:123
0
Train Loss: 0.753 | Acc: 75.776 (3444/4545)
Train Loss: 0.165 | Acc: 94.015 (4273/4545)
1
Train Loss: 0.424 | Acc: 86.777 (3944/4545)
Train Loss: 0.097 | Acc: 97.096 (4413/4545)
2
Train Loss: 0.297 | Acc: 91.353 (4152/4545)
Train Loss: 0.069 | Acc: 97.646 (4438/4545)
3
Train Loss: 0.695 | Acc: 76.194 (3463/4545)
Train Loss: 0.149 | Acc: 94.917 (4314/4545)
4
Train Loss: 0.696 | Acc: 72.475 (3294/4545)
Train Loss: 0.228 | Acc: 90.781 (4126/4545)
5
Train Loss: 0.316 | Acc: 88.757 (4034/4545)
Train Loss: 0.003 | Acc: 100.000 (4545/4545)
6
Train Loss: 0.496 | Acc: 82.134 (3733/4545)
Train Loss: 0.001 | Acc: 100.000 (4545/4545)
7
Train Loss: 0.766 | Acc: 75.556 (3434/4545)
Train Loss: 0.057 | Acc: 98.372 (4471/4545)
8
Train Loss: 1.312 | Acc: 67.195 (3054/4545)
Train Loss: 0.050 | Acc: 98.130 (4460/4545)
9
Train Loss: 0.248 | Acc: 89.967 (4089/4545)
Train Loss: 0.031 | Acc: 99.032 (4501/4545)
10
Train Loss: 1.090 | Acc: 69.593 (3163/4545)
Train Loss: 0.036 | Acc: 98.966 (4498/4545)
1.conv1
layer2.1
1.bn1
layer3.1
linear
layer4.0
layer1.1
layer1.0
layer2.0
layer3.0
layer4.1
Test Loss: 4.001 | Acc: 14.730 (1473/10000)
mseloss[1]:0.8001483678817749, 0.708263635635376, 0.3558262586593628, 0.19837212562561035
mseloss[2]:0.8185386061668396, 0.7623081803321838, 0.5978246927261353, 0.32900795340538025
mseloss[3]:0.8189072608947754, 0.6935722827911377, 0.4294684827327728, 0.19177666306495667
mseloss[4]:0.8218016028404236, 0.7534413933753967, 0.4781341254711151, 0.39095860719680786
mseloss[5]:0.8155292272567749, 0.8815448880195618, 0.7806467413902283, 0.328369677066803
mseloss[6]:0.8401930332183838, 0.8708275556564331, 0.8061671257019043, 0.3813534677028656
mseloss[7]:0.7843465805053711, 0.6621541380882263, 0.4381342828273773, 0.3021564483642578
mseloss[8]:0.8015767931938171, 0.780544102191925, 0.6031108498573303, 0.36056190729141235
mseloss[9]:0.799594521522522, 0.7539027333259583, 0.6358474493026733, 0.44695529341697693
Epoch:124
0
Train Loss: 0.253 | Acc: 93.003 (4227/4545)
Train Loss: 0.128 | Acc: 95.644 (4347/4545)
1
Train Loss: 0.337 | Acc: 87.987 (3999/4545)
Train Loss: 0.094 | Acc: 97.074 (4412/4545)
2
Train Loss: 1.080 | Acc: 69.087 (3140/4545)
Train Loss: 0.082 | Acc: 97.426 (4428/4545)
3
Train Loss: 0.358 | Acc: 88.977 (4044/4545)
Train Loss: 0.043 | Acc: 98.658 (4484/4545)
4
Train Loss: 1.533 | Acc: 65.259 (2966/4545)
Train Loss: 0.044 | Acc: 98.416 (4473/4545)
5
Train Loss: 0.520 | Acc: 79.802 (3627/4545)
Train Loss: 0.157 | Acc: 94.367 (4289/4545)
6
Train Loss: 0.698 | Acc: 80.000 (3636/4545)
Train Loss: 0.001 | Acc: 100.000 (4545/4545)
7
Train Loss: 0.667 | Acc: 74.367 (3380/4545)
Train Loss: 0.237 | Acc: 90.583 (4117/4545)
8
Train Loss: 0.591 | Acc: 78.768 (3580/4545)
Train Loss: 0.036 | Acc: 98.724 (4487/4545)
9
Train Loss: 0.799 | Acc: 75.600 (3436/4545)
Train Loss: 0.034 | Acc: 99.032 (4501/4545)
10
Train Loss: 0.148 | Acc: 96.854 (4402/4545)
Train Loss: 0.003 | Acc: 100.000 (4545/4545)
layer3.0
layer2.1
layer3.1
layer4.1
layer1.1
layer2.0
layer1.0
1.bn1
1.conv1
layer4.0
linear
Test Loss: 2.474 | Acc: 27.160 (2716/10000)
mseloss[1]:0.8010202050209045, 0.6555498838424683, 0.3366162180900574, 0.1586240530014038
mseloss[2]:0.8162016868591309, 0.8124902844429016, 0.7021058797836304, 0.3220492899417877
mseloss[3]:0.809918999671936, 0.6765643954277039, 0.3959556519985199, 0.26867058873176575
mseloss[4]:0.8470469117164612, 0.8713370561599731, 0.7245796322822571, 0.4156772196292877
mseloss[5]:0.8146349191665649, 0.697981059551239, 0.39247214794158936, 0.19325822591781616
mseloss[6]:0.8480190634727478, 1.0008481740951538, 0.9063751101493835, 0.41527071595191956
mseloss[7]:0.8191941380500793, 0.839309573173523, 0.6924017071723938, 0.5737945437431335
mseloss[8]:0.8386402726173401, 0.8959333300590515, 0.7745577692985535, 0.5714600682258606
mseloss[9]:0.8398624062538147, 0.8815884590148926, 0.7150042653083801, 0.40201669931411743
Epoch:125
0
Train Loss: 0.400 | Acc: 85.347 (3879/4545)
Train Loss: 0.022 | Acc: 99.362 (4516/4545)
1
Train Loss: 0.437 | Acc: 82.222 (3737/4545)
Train Loss: 0.225 | Acc: 90.891 (4131/4545)
2
Train Loss: 0.677 | Acc: 80.330 (3651/4545)
Train Loss: 0.034 | Acc: 98.812 (4491/4545)
3
Train Loss: 0.295 | Acc: 88.977 (4044/4545)
Train Loss: 0.001 | Acc: 100.000 (4545/4545)
4
Train Loss: 1.256 | Acc: 70.319 (3196/4545)
Train Loss: 0.084 | Acc: 97.250 (4420/4545)
5
Train Loss: 0.934 | Acc: 74.719 (3396/4545)
Train Loss: 0.106 | Acc: 96.546 (4388/4545)
6
Train Loss: 0.403 | Acc: 87.085 (3958/4545)
Train Loss: 0.030 | Acc: 98.988 (4499/4545)
7
Train Loss: 0.654 | Acc: 77.470 (3521/4545)
Train Loss: 0.135 | Acc: 95.028 (4319/4545)
8
Train Loss: 0.776 | Acc: 78.042 (3547/4545)
Train Loss: 0.001 | Acc: 100.000 (4545/4545)
9
Train Loss: 0.600 | Acc: 81.188 (3690/4545)
Train Loss: 0.138 | Acc: 95.226 (4328/4545)
10
Train Loss: 0.254 | Acc: 92.475 (4203/4545)
Train Loss: 0.043 | Acc: 98.702 (4486/4545)
1.conv1
layer1.1
linear
1.bn1
layer1.0
layer3.1
layer3.0
layer4.1
layer2.0
layer2.1
layer4.0
Test Loss: 3.273 | Acc: 21.890 (2189/10000)
mseloss[1]:0.7995976805686951, 0.6697239875793457, 0.4974943995475769, 0.4715701639652252
mseloss[2]:0.7790176272392273, 0.6633269190788269, 0.5459556579589844, 0.46221113204956055
mseloss[3]:0.7893713712692261, 0.7877674102783203, 0.6955412030220032, 0.4121169447898865
mseloss[4]:0.8108364343643188, 0.7888508439064026, 0.7779490351676941, 0.4977041482925415
mseloss[5]:0.8282946348190308, 0.8692779541015625, 0.7759425044059753, 0.5494508147239685
mseloss[6]:0.8077428936958313, 0.7040778398513794, 0.5843088030815125, 0.49299222230911255
mseloss[7]:0.7953851222991943, 0.723240077495575, 0.6037355661392212, 0.4953342080116272
mseloss[8]:0.8176919221878052, 0.7718971967697144, 0.6746631860733032, 0.5119458436965942
mseloss[9]:0.8394473195075989, 0.9151677489280701, 0.8139236569404602, 0.5481839179992676
Epoch:126
0
Train Loss: 0.768 | Acc: 77.910 (3541/4545)
Train Loss: 0.001 | Acc: 100.000 (4545/4545)
1
Train Loss: 0.439 | Acc: 84.730 (3851/4545)
Train Loss: 0.115 | Acc: 96.018 (4364/4545)
2
Train Loss: 0.306 | Acc: 88.823 (4037/4545)
Train Loss: 0.129 | Acc: 95.578 (4344/4545)
3
Train Loss: 0.477 | Acc: 83.322 (3787/4545)
Train Loss: 0.053 | Acc: 98.020 (4455/4545)
4
Train Loss: 0.521 | Acc: 82.332 (3742/4545)
Train Loss: 0.136 | Acc: 95.248 (4329/4545)
5
Train Loss: 0.269 | Acc: 90.957 (4134/4545)
Train Loss: 0.045 | Acc: 98.746 (4488/4545)
6
Train Loss: 0.766 | Acc: 77.580 (3526/4545)
Train Loss: 0.002 | Acc: 100.000 (4545/4545)
7
Train Loss: 0.951 | Acc: 67.965 (3089/4545)
Train Loss: 0.248 | Acc: 89.791 (4081/4545)
8
Train Loss: 0.309 | Acc: 90.297 (4104/4545)
Train Loss: 0.038 | Acc: 98.746 (4488/4545)
9
Train Loss: 1.241 | Acc: 69.857 (3175/4545)
Train Loss: 0.082 | Acc: 97.250 (4420/4545)
10
Train Loss: 0.841 | Acc: 74.433 (3383/4545)
Train Loss: 0.039 | Acc: 98.790 (4490/4545)
layer2.1
1.bn1
layer2.0
layer1.0
layer3.1
layer1.1
1.conv1
layer4.1
layer3.0
layer4.0
linear
Test Loss: 6.459 | Acc: 14.150 (1415/10000)
mseloss[1]:0.8361855149269104, 0.954760730266571, 0.8433713316917419, 0.34708845615386963
mseloss[2]:0.8546371459960938, 1.02300226688385, 0.9161651730537415, 0.35125383734703064
mseloss[3]:0.787970781326294, 0.7810757160186768, 0.6253046989440918, 0.4038334786891937
mseloss[4]:0.8334957361221313, 0.8986283540725708, 0.8346011638641357, 0.3532542884349823
mseloss[5]:0.8187286257743835, 0.879386305809021, 0.7942927479743958, 0.39667004346847534
mseloss[6]:0.772810697555542, 0.7688254714012146, 0.5238097906112671, 0.27685704827308655
mseloss[7]:0.8035634756088257, 0.8224663734436035, 0.7056704163551331, 0.4657188951969147
mseloss[8]:0.7952358722686768, 0.8133651614189148, 0.7584565281867981, 0.3716498017311096
mseloss[9]:0.7897319197654724, 0.7665824294090271, 0.5828966498374939, 0.2756175696849823
Epoch:127
0
Train Loss: 1.022 | Acc: 69.263 (3148/4545)
Train Loss: 0.156 | Acc: 94.191 (4281/4545)
1
Train Loss: 0.493 | Acc: 81.474 (3703/4545)
Train Loss: 0.001 | Acc: 100.000 (4545/4545)
2
Train Loss: 0.861 | Acc: 75.314 (3423/4545)
Train Loss: 0.061 | Acc: 98.152 (4461/4545)
3
Train Loss: 0.850 | Acc: 73.839 (3356/4545)
Train Loss: 0.046 | Acc: 98.350 (4470/4545)
4
Train Loss: 0.855 | Acc: 70.847 (3220/4545)
Train Loss: 0.244 | Acc: 90.231 (4101/4545)
5
Train Loss: 0.969 | Acc: 73.707 (3350/4545)
Train Loss: 0.028 | Acc: 98.944 (4497/4545)
6
Train Loss: 0.844 | Acc: 75.754 (3443/4545)
Train Loss: 0.000 | Acc: 100.000 (4545/4545)
7
Train Loss: 1.125 | Acc: 75.204 (3418/4545)
Train Loss: 0.141 | Acc: 95.380 (4335/4545)
8
Train Loss: 1.004 | Acc: 71.353 (3243/4545)
Train Loss: 0.134 | Acc: 95.248 (4329/4545)
9
Train Loss: 0.518 | Acc: 80.616 (3664/4545)
Train Loss: 0.073 | Acc: 97.470 (4430/4545)
10
Train Loss: 0.143 | Acc: 96.304 (4377/4545)
Train Loss: 0.027 | Acc: 99.230 (4510/4545)
layer1.0
layer4.1
layer3.1
layer4.0
1.bn1
layer3.0
layer2.1
linear
layer2.0
layer1.1
1.conv1
Test Loss: 4.512 | Acc: 14.730 (1473/10000)
mseloss[1]:0.8161378502845764, 0.9722932577133179, 0.964890718460083, 0.3198862373828888
mseloss[2]:0.7819857597351074, 0.7332258820533752, 0.47143080830574036, 0.2363715022802353
mseloss[3]:0.786318302154541, 0.7779712677001953, 0.7145258784294128, 0.43926945328712463
mseloss[4]:0.8050712943077087, 0.7807600498199463, 0.5901538729667664, 0.3244861364364624
mseloss[5]:0.8040624856948853, 0.7982853651046753, 0.6539674997329712, 0.3044535219669342
mseloss[6]:0.8250433206558228, 0.9969773292541504, 0.93533855676651, 0.36553192138671875
mseloss[7]:0.8170036673545837, 0.7398279309272766, 0.43450453877449036, 0.16746602952480316
mseloss[8]:0.7977840304374695, 0.7969281673431396, 0.460956871509552, 0.18785201013088226
mseloss[9]:0.812981367111206, 0.8280211091041565, 0.7434612512588501, 0.3082484304904938
Epoch:128
0
Train Loss: 0.345 | Acc: 87.635 (3983/4545)
Train Loss: 0.053 | Acc: 98.284 (4467/4545)
1
Train Loss: 0.637 | Acc: 79.340 (3606/4545)
Train Loss: 0.069 | Acc: 97.756 (4443/4545)
2
Train Loss: 0.256 | Acc: 90.781 (4126/4545)
Train Loss: 0.040 | Acc: 98.526 (4478/4545)
3
Train Loss: 0.867 | Acc: 67.503 (3068/4545)
Train Loss: 0.256 | Acc: 89.769 (4080/4545)
4
Train Loss: 0.932 | Acc: 71.221 (3237/4545)
Train Loss: 0.153 | Acc: 94.587 (4299/4545)
5
Train Loss: 0.525 | Acc: 82.574 (3753/4545)
Train Loss: 0.113 | Acc: 96.370 (4380/4545)
6
Train Loss: 0.394 | Acc: 84.708 (3850/4545)
Train Loss: 0.026 | Acc: 99.164 (4507/4545)
7
Train Loss: 0.664 | Acc: 79.956 (3634/4545)
Train Loss: 0.001 | Acc: 100.000 (4545/4545)
8
Train Loss: 0.520 | Acc: 82.816 (3764/4545)
Train Loss: 0.000 | Acc: 100.000 (4545/4545)
9
Train Loss: 0.467 | Acc: 85.325 (3878/4545)
Train Loss: 0.029 | Acc: 98.966 (4498/4545)
10
Train Loss: 0.865 | Acc: 75.314 (3423/4545)
Train Loss: 0.110 | Acc: 96.436 (4383/4545)
layer1.1
1.bn1
layer1.0
1.conv1
layer4.0
layer3.1
layer2.1
layer2.0
layer4.1
linear
layer3.0
Test Loss: 3.093 | Acc: 20.920 (2092/10000)
mseloss[1]:0.8104852437973022, 0.9507849812507629, 0.7758876085281372, 0.3540547788143158
mseloss[2]:0.8076502680778503, 0.8494935631752014, 0.559319019317627, 0.4200342893600464
mseloss[3]:0.7763404846191406, 0.8608769178390503, 0.5577223896980286, 0.35688650608062744
mseloss[4]:0.7780478596687317, 0.7658106088638306, 0.4859163165092468, 0.2636297941207886
mseloss[5]:0.8082853555679321, 0.7714056372642517, 0.5065245032310486, 0.26261645555496216
mseloss[6]:0.7787598371505737, 0.8575019240379333, 0.5621349811553955, 0.379178911447525
mseloss[7]:0.8061894178390503, 0.9441666603088379, 0.7118768692016602, 0.33362939953804016
mseloss[8]:0.8155570030212402, 1.058376431465149, 0.8352290391921997, 0.3857599198818207
mseloss[9]:0.7894923686981201, 0.8758130669593811, 0.550283670425415, 0.37367478013038635
Epoch:129
0
Train Loss: 0.780 | Acc: 77.448 (3520/4545)
Train Loss: 0.044 | Acc: 98.680 (4485/4545)
1
Train Loss: 0.756 | Acc: 79.318 (3605/4545)
Train Loss: 0.001 | Acc: 100.000 (4545/4545)
2
Train Loss: 0.319 | Acc: 88.537 (4024/4545)
Train Loss: 0.109 | Acc: 96.304 (4377/4545)
3
Train Loss: 0.428 | Acc: 86.095 (3913/4545)
Train Loss: 0.148 | Acc: 94.543 (4297/4545)
4
Train Loss: 0.605 | Acc: 77.272 (3512/4545)
Train Loss: 0.234 | Acc: 90.715 (4123/4545)
5
Train Loss: 0.310 | Acc: 89.241 (4056/4545)
Train Loss: 0.099 | Acc: 96.766 (4398/4545)
6
Train Loss: 0.503 | Acc: 84.532 (3842/4545)
Train Loss: 0.001 | Acc: 100.000 (4545/4545)
7
Train Loss: 0.510 | Acc: 82.596 (3754/4545)
Train Loss: 0.052 | Acc: 98.328 (4469/4545)
8
Train Loss: 1.021 | Acc: 72.563 (3298/4545)
Train Loss: 0.071 | Acc: 97.866 (4448/4545)
9
Train Loss: 0.537 | Acc: 81.408 (3700/4545)
Train Loss: 0.042 | Acc: 98.592 (4481/4545)
10
Train Loss: 0.451 | Acc: 84.576 (3844/4545)
Train Loss: 0.037 | Acc: 98.636 (4483/4545)
layer1.1
layer2.1
layer3.1
linear
layer2.0
layer4.0
1.conv1
layer3.0
layer4.1
1.bn1
layer1.0
Test Loss: 2.754 | Acc: 14.340 (1434/10000)
mseloss[1]:0.7601703405380249, 0.7789438366889954, 0.7627096176147461, 0.3681541979312897
mseloss[2]:0.8381484746932983, 0.9443925023078918, 1.010546326637268, 0.6144059300422668
mseloss[3]:0.786191999912262, 0.8466706871986389, 0.8940402269363403, 0.5310443639755249
mseloss[4]:0.7800061702728271, 0.77540123462677, 0.7200102210044861, 0.5011594295501709
mseloss[5]:0.8072270154953003, 0.9613465070724487, 0.919024646282196, 0.5786229968070984
mseloss[6]:0.7625642418861389, 0.8488333821296692, 0.823497474193573, 0.3591517508029938
mseloss[7]:0.7966301441192627, 0.8358301520347595, 0.8032046556472778, 0.5631058216094971
mseloss[8]:0.7718839645385742, 0.7554014921188354, 0.7296256422996521, 0.35982513427734375
mseloss[9]:0.7744410037994385, 0.7912409901618958, 0.8109726309776306, 0.5603135228157043
Epoch:130
0
Train Loss: 0.280 | Acc: 91.485 (4158/4545)
Train Loss: 0.042 | Acc: 98.702 (4486/4545)
1
Train Loss: 0.357 | Acc: 88.889 (4040/4545)
Train Loss: 0.000 | Acc: 100.000 (4545/4545)
2
Train Loss: 0.470 | Acc: 82.552 (3752/4545)
Train Loss: 0.152 | Acc: 94.433 (4292/4545)
3
Train Loss: 0.617 | Acc: 78.680 (3576/4545)
Train Loss: 0.038 | Acc: 98.658 (4484/4545)
4
Train Loss: 0.382 | Acc: 86.689 (3940/4545)
Train Loss: 0.044 | Acc: 98.262 (4466/4545)
5
Train Loss: 0.425 | Acc: 87.855 (3993/4545)
Train Loss: 0.036 | Acc: 98.790 (4490/4545)
6
Train Loss: 0.535 | Acc: 79.758 (3625/4545)
Train Loss: 0.216 | Acc: 91.309 (4150/4545)
7
Train Loss: 1.002 | Acc: 79.780 (3626/4545)
Train Loss: 0.117 | Acc: 95.864 (4357/4545)
8
Train Loss: 1.293 | Acc: 74.675 (3394/4545)
Train Loss: 0.137 | Acc: 94.917 (4314/4545)
9
Train Loss: 1.190 | Acc: 72.629 (3301/4545)
Train Loss: 0.078 | Acc: 97.316 (4423/4545)
10
Train Loss: 0.533 | Acc: 85.171 (3871/4545)
Train Loss: 0.001 | Acc: 100.000 (4545/4545)
linear
layer1.1
layer2.1
1.conv1
1.bn1
layer2.0
layer4.0
layer1.0
layer3.1
layer4.1
layer3.0
Test Loss: 3.434 | Acc: 27.360 (2736/10000)
mseloss[1]:0.7947385311126709, 0.8257401585578918, 0.752975344657898, 0.4016893208026886
mseloss[2]:0.7790762186050415, 0.776768684387207, 0.6058405041694641, 0.2862797677516937
mseloss[3]:0.7697030901908875, 0.7955406904220581, 0.7473698258399963, 0.5237106084823608
mseloss[4]:0.7865777611732483, 0.7881984114646912, 0.6976393461227417, 0.5102056264877319
mseloss[5]:0.7740430235862732, 0.813525378704071, 0.7806908488273621, 0.427979052066803
mseloss[6]:0.7662405967712402, 0.8166650533676147, 0.703416645526886, 0.5481762886047363
mseloss[7]:0.7927606701850891, 0.8256399631500244, 0.5904209017753601, 0.24128733575344086
mseloss[8]:0.8132479190826416, 0.8221498727798462, 0.6273652911186218, 0.2551470696926117
mseloss[9]:0.8037217259407043, 0.817294716835022, 0.7828475832939148, 0.36459314823150635
Epoch:131
0
Train Loss: 0.810 | Acc: 72.541 (3297/4545)
Train Loss: 0.159 | Acc: 93.729 (4260/4545)
1
Train Loss: 0.280 | Acc: 92.475 (4203/4545)
Train Loss: 0.030 | Acc: 99.076 (4503/4545)
2
Train Loss: 0.339 | Acc: 88.097 (4004/4545)
Train Loss: 0.000 | Acc: 100.000 (4545/4545)
3
Train Loss: 0.465 | Acc: 83.696 (3804/4545)
Train Loss: 0.026 | Acc: 99.120 (4505/4545)
4
Train Loss: 0.198 | Acc: 94.543 (4297/4545)
Train Loss: 0.001 | Acc: 100.000 (4545/4545)
5
Train Loss: 0.412 | Acc: 84.422 (3837/4545)
Train Loss: 0.049 | Acc: 98.042 (4456/4545)
6
Train Loss: 0.489 | Acc: 83.124 (3778/4545)
Train Loss: 0.069 | Acc: 97.580 (4435/4545)
7
Train Loss: 0.656 | Acc: 75.116 (3414/4545)
Train Loss: 0.231 | Acc: 90.517 (4114/4545)
8
Train Loss: 0.941 | Acc: 78.130 (3551/4545)
Train Loss: 0.141 | Acc: 94.785 (4308/4545)
9
Train Loss: 0.648 | Acc: 78.042 (3547/4545)
Train Loss: 0.113 | Acc: 95.754 (4352/4545)
10
Train Loss: 0.184 | Acc: 95.182 (4326/4545)
Train Loss: 0.043 | Acc: 98.724 (4487/4545)
layer4.1
layer2.1
linear
layer3.0
1.bn1
layer4.0
1.conv1
layer1.1
layer2.0
layer1.0
layer3.1
Test Loss: 4.857 | Acc: 13.990 (1399/10000)
mseloss[1]:0.801421046257019, 0.7779718041419983, 0.7006818056106567, 0.3616705536842346
mseloss[2]:0.8194559216499329, 0.8602159023284912, 0.8768253922462463, 0.411706805229187
mseloss[3]:0.7945234775543213, 0.8324920535087585, 0.9142107367515564, 0.5005795359611511
mseloss[4]:0.8035559058189392, 0.8380612134933472, 0.8223354816436768, 0.3515026569366455
mseloss[5]:0.7962986826896667, 0.8385612964630127, 0.9749836921691895, 0.5253683924674988
mseloss[6]:0.8012362122535706, 0.7845854759216309, 0.6499577164649963, 0.2867618501186371
mseloss[7]:0.810524046421051, 0.828911542892456, 0.7917320728302002, 0.46340295672416687
mseloss[8]:0.8187021017074585, 0.7517111897468567, 0.4635572135448456, 0.20041708648204803
mseloss[9]:0.7984477877616882, 0.7638967633247375, 0.4590073525905609, 0.20660735666751862
Epoch:132
0
Train Loss: 0.202 | Acc: 93.465 (4248/4545)
Train Loss: 0.047 | Acc: 98.218 (4464/4545)
1
Train Loss: 0.557 | Acc: 79.098 (3595/4545)
Train Loss: 0.159 | Acc: 94.037 (4274/4545)
2
Train Loss: 0.982 | Acc: 74.609 (3391/4545)
Train Loss: 0.001 | Acc: 100.000 (4545/4545)
3
Train Loss: 0.650 | Acc: 80.572 (3662/4545)
Train Loss: 0.056 | Acc: 97.888 (4449/4545)
4
Train Loss: 0.467 | Acc: 84.708 (3850/4545)
Train Loss: 0.108 | Acc: 96.348 (4379/4545)
5
Train Loss: 0.112 | Acc: 97.492 (4431/4545)
Train Loss: 0.000 | Acc: 100.000 (4545/4545)
6
Train Loss: 0.477 | Acc: 82.816 (3764/4545)
Train Loss: 0.028 | Acc: 99.076 (4503/4545)
7
Train Loss: 0.812 | Acc: 71.155 (3234/4545)
Train Loss: 0.223 | Acc: 90.803 (4127/4545)
8
Train Loss: 0.565 | Acc: 81.914 (3723/4545)
Train Loss: 0.118 | Acc: 95.930 (4360/4545)
9
Train Loss: 0.706 | Acc: 77.976 (3544/4545)
Train Loss: 0.033 | Acc: 99.098 (4504/4545)
10
Train Loss: 0.913 | Acc: 73.729 (3351/4545)
Train Loss: 0.067 | Acc: 97.580 (4435/4545)
layer4.1
linear
layer3.1
1.bn1
layer2.1
layer2.0
layer4.0
layer1.1
layer3.0
1.conv1
layer1.0
Test Loss: 3.122 | Acc: 12.810 (1281/10000)
mseloss[1]:0.7718616127967834, 0.7254442572593689, 0.5507178902626038, 0.25250983238220215
mseloss[2]:0.7949805855751038, 0.7950206995010376, 0.5494711995124817, 0.2648262083530426
mseloss[3]:0.7955288887023926, 0.8241571187973022, 0.6835553646087646, 0.45588219165802
mseloss[4]:0.7877378463745117, 0.7945759892463684, 0.529111921787262, 0.20202237367630005
mseloss[5]:0.7975050806999207, 0.7916501760482788, 0.6072242259979248, 0.3252977132797241
mseloss[6]:0.7772430181503296, 0.7693651914596558, 0.7282654643058777, 0.4836063086986542
mseloss[7]:0.7608416676521301, 0.7380340099334717, 0.518950879573822, 0.48052775859832764
mseloss[8]:0.8245970010757446, 0.8301728963851929, 0.6196737289428711, 0.2235286980867386
mseloss[9]:0.7736136317253113, 0.7494237422943115, 0.5708534121513367, 0.44209328293800354
Epoch:133
0
Train Loss: 0.627 | Acc: 75.732 (3442/4545)
Train Loss: 0.216 | Acc: 91.089 (4140/4545)
1
Train Loss: 0.315 | Acc: 88.515 (4023/4545)
Train Loss: 0.024 | Acc: 99.296 (4513/4545)
2
Train Loss: 0.973 | Acc: 76.656 (3484/4545)
Train Loss: 0.001 | Acc: 100.000 (4545/4545)
3
Train Loss: 0.979 | Acc: 78.944 (3588/4545)
Train Loss: 0.073 | Acc: 97.514 (4432/4545)
4
Train Loss: 0.368 | Acc: 87.745 (3988/4545)
Train Loss: 0.115 | Acc: 96.018 (4364/4545)
5
Train Loss: 0.276 | Acc: 91.397 (4154/4545)
Train Loss: 0.026 | Acc: 99.252 (4511/4545)
6
Train Loss: 0.449 | Acc: 83.960 (3816/4545)
Train Loss: 0.125 | Acc: 95.622 (4346/4545)
7
Train Loss: 0.394 | Acc: 87.217 (3964/4545)
Train Loss: 0.054 | Acc: 97.800 (4445/4545)
8
Train Loss: 0.545 | Acc: 79.846 (3629/4545)
Train Loss: 0.174 | Acc: 93.465 (4248/4545)
9
Train Loss: 0.379 | Acc: 86.997 (3954/4545)
Train Loss: 0.000 | Acc: 100.000 (4545/4545)
10
Train Loss: 0.322 | Acc: 89.593 (4072/4545)
Train Loss: 0.054 | Acc: 98.174 (4462/4545)
layer1.1
layer2.0
1.bn1
layer4.0
layer4.1
layer3.1
layer3.0
layer2.1
linear
1.conv1
layer1.0
Test Loss: 2.387 | Acc: 25.260 (2526/10000)
mseloss[1]:0.7829391360282898, 0.7398654818534851, 0.5743245482444763, 0.5482025146484375
mseloss[2]:0.7956990003585815, 0.951933741569519, 0.9314913153648376, 0.5547689199447632
mseloss[3]:0.8005837202072144, 0.9922475814819336, 0.996049165725708, 0.5538167357444763
mseloss[4]:0.7972103357315063, 0.9929460883140564, 0.9329812526702881, 0.5627140998840332
mseloss[5]:0.7816566824913025, 0.7890438437461853, 0.6885473132133484, 0.4539166986942291
mseloss[6]:0.7958794236183167, 0.8961916565895081, 0.8962409496307373, 0.4969061613082886
mseloss[7]:0.7986069917678833, 0.8010332584381104, 0.7078396677970886, 0.5128721594810486
mseloss[8]:0.7918938398361206, 0.8512817621231079, 0.7998562455177307, 0.45158568024635315
mseloss[9]:0.7899960875511169, 0.85019451379776, 0.8863095641136169, 0.5177922248840332
Epoch:134
0
Train Loss: 0.407 | Acc: 84.708 (3850/4545)
Train Loss: 0.162 | Acc: 94.213 (4282/4545)
1
Train Loss: 0.561 | Acc: 80.924 (3678/4545)
Train Loss: 0.054 | Acc: 97.998 (4454/4545)
2
Train Loss: 0.528 | Acc: 79.318 (3605/4545)
Train Loss: 0.220 | Acc: 91.353 (4152/4545)
3
Train Loss: 0.813 | Acc: 83.718 (3805/4545)
Train Loss: 0.064 | Acc: 97.822 (4446/4545)
4
Train Loss: 1.591 | Acc: 69.307 (3150/4545)
Train Loss: 0.135 | Acc: 95.006 (4318/4545)
5
Train Loss: 0.381 | Acc: 86.755 (3943/4545)
Train Loss: 0.000 | Acc: 100.000 (4545/4545)
6
Train Loss: 0.365 | Acc: 86.843 (3947/4545)
Train Loss: 0.019 | Acc: 99.274 (4512/4545)
7
Train Loss: 0.642 | Acc: 82.156 (3734/4545)
Train Loss: 0.001 | Acc: 100.000 (4545/4545)
8
Train Loss: 0.891 | Acc: 77.602 (3527/4545)
Train Loss: 0.031 | Acc: 98.856 (4493/4545)
9
Train Loss: 1.154 | Acc: 74.433 (3383/4545)
Train Loss: 0.067 | Acc: 97.756 (4443/4545)
10
Train Loss: 0.777 | Acc: 80.528 (3660/4545)
Train Loss: 0.126 | Acc: 95.578 (4344/4545)
layer3.1
layer3.0
layer4.0
1.bn1
layer1.0
layer1.1
1.conv1
linear
layer2.1
layer4.1
layer2.0
Test Loss: 3.879 | Acc: 18.850 (1885/10000)
mseloss[1]:0.7778098583221436, 0.8158014416694641, 0.8096378445625305, 0.47296661138534546
mseloss[2]:0.8008265495300293, 0.8033102750778198, 0.7261126041412354, 0.4624312222003937
mseloss[3]:0.8008283376693726, 0.924871563911438, 0.7360209822654724, 0.2991129457950592
mseloss[4]:0.7926222085952759, 0.9088066220283508, 0.6324747204780579, 0.24426254630088806
mseloss[5]:0.8159180879592896, 0.8687658905982971, 0.8894716501235962, 0.4249110221862793
mseloss[6]:0.7735552191734314, 0.8047409057617188, 0.7536588311195374, 0.40427738428115845
mseloss[7]:0.811194896697998, 0.898960292339325, 0.8826353549957275, 0.34408751130104065
mseloss[8]:0.7821125388145447, 0.8063323497772217, 0.7676420211791992, 0.33151984214782715
mseloss[9]:0.788550853729248, 0.865696132183075, 0.746751070022583, 0.28133854269981384
Epoch:135
0
Train Loss: 0.483 | Acc: 84.378 (3835/4545)
Train Loss: 0.104 | Acc: 96.238 (4374/4545)
1
Train Loss: 0.392 | Acc: 86.755 (3943/4545)
Train Loss: 0.028 | Acc: 98.944 (4497/4545)
2
Train Loss: 0.729 | Acc: 77.514 (3523/4545)
Train Loss: 0.023 | Acc: 99.120 (4505/4545)
3
Train Loss: 0.502 | Acc: 82.970 (3771/4545)
Train Loss: 0.053 | Acc: 98.042 (4456/4545)
4
Train Loss: 0.542 | Acc: 82.288 (3740/4545)
Train Loss: 0.124 | Acc: 95.622 (4346/4545)
5
Train Loss: 0.713 | Acc: 77.822 (3537/4545)
Train Loss: 0.067 | Acc: 97.624 (4437/4545)
6
Train Loss: 0.484 | Acc: 83.630 (3801/4545)
Train Loss: 0.000 | Acc: 100.000 (4545/4545)
7
Train Loss: 0.073 | Acc: 99.120 (4505/4545)
Train Loss: 0.001 | Acc: 100.000 (4545/4545)
8
Train Loss: 0.515 | Acc: 78.966 (3589/4545)
Train Loss: 0.180 | Acc: 93.069 (4230/4545)
9
Train Loss: 0.664 | Acc: 75.534 (3433/4545)
Train Loss: 0.221 | Acc: 91.111 (4141/4545)
10
Train Loss: 0.530 | Acc: 83.652 (3802/4545)
Train Loss: 0.070 | Acc: 97.514 (4432/4545)
layer2.1
layer1.1
layer2.0
layer3.1
1.bn1
linear
layer4.1
layer4.0
1.conv1
layer3.0
layer1.0
Test Loss: 3.502 | Acc: 24.860 (2486/10000)
mseloss[1]:0.8058672547340393, 0.9019212126731873, 0.8265559077262878, 0.3346517086029053
mseloss[2]:0.8262048363685608, 0.9688822031021118, 0.8798258900642395, 0.44480055570602417
mseloss[3]:0.8162111043930054, 0.9956148862838745, 0.9644824266433716, 0.513688862323761
mseloss[4]:0.8019060492515564, 0.7278169393539429, 0.48742246627807617, 0.15331389009952545
mseloss[5]:0.8086534142494202, 0.881345808506012, 0.8018974661827087, 0.2650825083255768
mseloss[6]:0.8307945132255554, 1.0416065454483032, 1.1138516664505005, 0.42702701687812805
mseloss[7]:0.848102867603302, 1.064716100692749, 1.068359375, 0.34593769907951355
mseloss[8]:0.7864899635314941, 0.746912956237793, 0.4607580304145813, 0.20817475020885468
mseloss[9]:0.8096705675125122, 0.9612221121788025, 0.7953720092773438, 0.52921062707901
Epoch:136
0
Train Loss: 0.370 | Acc: 87.151 (3961/4545)
Train Loss: 0.000 | Acc: 100.000 (4545/4545)
1
Train Loss: 0.365 | Acc: 86.667 (3939/4545)
Train Loss: 0.044 | Acc: 98.614 (4482/4545)
2
Train Loss: 0.330 | Acc: 89.021 (4046/4545)
Train Loss: 0.000 | Acc: 100.000 (4545/4545)
3
Train Loss: 0.524 | Acc: 82.838 (3765/4545)
Train Loss: 0.062 | Acc: 98.020 (4455/4545)
4
Train Loss: 0.523 | Acc: 83.366 (3789/4545)
Train Loss: 0.012 | Acc: 99.604 (4527/4545)
5
Train Loss: 0.921 | Acc: 76.766 (3489/4545)
Train Loss: 0.127 | Acc: 95.446 (4338/4545)
6
Train Loss: 0.797 | Acc: 78.372 (3562/4545)
Train Loss: 0.097 | Acc: 96.722 (4396/4545)
7
Train Loss: 0.465 | Acc: 84.642 (3847/4545)
Train Loss: 0.065 | Acc: 97.712 (4441/4545)
8
Train Loss: 0.587 | Acc: 82.860 (3766/4545)
Train Loss: 0.039 | Acc: 98.878 (4494/4545)
9
Train Loss: 0.500 | Acc: 80.330 (3651/4545)
Train Loss: 0.197 | Acc: 92.057 (4184/4545)
10
Train Loss: 0.369 | Acc: 86.799 (3945/4545)
Train Loss: 0.157 | Acc: 94.103 (4277/4545)
layer3.0
layer4.0
linear
1.conv1
layer1.0
layer1.1
layer3.1
1.bn1
layer2.1
layer4.1
layer2.0
Test Loss: 5.012 | Acc: 17.250 (1725/10000)
mseloss[1]:0.766090989112854, 0.7572022676467896, 0.6160014867782593, 0.3624124825000763
mseloss[2]:0.759135901927948, 0.7773371934890747, 0.6613996028900146, 0.28833019733428955
mseloss[3]:0.7829980850219727, 0.9303746223449707, 0.8650970458984375, 0.438607782125473
mseloss[4]:0.806346595287323, 0.8412806391716003, 0.7461314797401428, 0.4900447428226471
mseloss[5]:0.8429755568504333, 1.058024287223816, 1.0341804027557373, 0.462461918592453
mseloss[6]:0.8244130611419678, 1.0234929323196411, 0.9595416784286499, 0.45343276858329773
mseloss[7]:0.7755230665206909, 0.8403462171554565, 0.7103922963142395, 0.3255796730518341
mseloss[8]:0.7753942608833313, 0.8386902213096619, 0.956693172454834, 0.44843804836273193
mseloss[9]:0.7791170477867126, 0.8459778428077698, 0.7270441651344299, 0.5127988457679749
Epoch:137
0
Train Loss: 0.499 | Acc: 81.320 (3696/4545)
Train Loss: 0.198 | Acc: 91.881 (4176/4545)
1
Train Loss: 0.589 | Acc: 84.004 (3818/4545)
Train Loss: 0.036 | Acc: 98.900 (4495/4545)
2
Train Loss: 0.829 | Acc: 79.604 (3618/4545)
Train Loss: 0.095 | Acc: 96.810 (4400/4545)
3
Train Loss: 0.709 | Acc: 79.560 (3616/4545)
Train Loss: 0.064 | Acc: 97.844 (4447/4545)
4
Train Loss: 0.671 | Acc: 82.332 (3742/4545)
Train Loss: 0.061 | Acc: 97.888 (4449/4545)
5
Train Loss: 0.757 | Acc: 79.956 (3634/4545)
Train Loss: 0.120 | Acc: 96.128 (4369/4545)
6
Train Loss: 0.300 | Acc: 89.109 (4050/4545)
Train Loss: 0.000 | Acc: 100.000 (4545/4545)
7
Train Loss: 0.151 | Acc: 94.763 (4307/4545)
Train Loss: 0.000 | Acc: 100.000 (4545/4545)
8
Train Loss: 0.546 | Acc: 78.724 (3578/4545)
Train Loss: 0.140 | Acc: 94.895 (4313/4545)
9
Train Loss: 0.635 | Acc: 79.626 (3619/4545)
Train Loss: 0.054 | Acc: 98.152 (4461/4545)
10
Train Loss: 0.730 | Acc: 78.174 (3553/4545)
Train Loss: 0.019 | Acc: 99.516 (4523/4545)
linear
layer4.1
layer3.0
layer3.1
layer2.0
layer1.1
1.conv1
layer4.0
1.bn1
layer2.1
layer1.0
Test Loss: 2.873 | Acc: 17.860 (1786/10000)
mseloss[1]:0.8002049326896667, 0.7422089576721191, 0.6905811429023743, 0.5058401226997375
mseloss[2]:0.8237099647521973, 0.9356333613395691, 0.7667494416236877, 0.5800260305404663
mseloss[3]:0.8214225172996521, 0.880993664264679, 0.8912361860275269, 0.6591949462890625
mseloss[4]:0.7912073731422424, 0.849738597869873, 0.6989032030105591, 0.5665426850318909
mseloss[5]:0.8218411803245544, 0.9185299277305603, 0.8926022052764893, 0.6488560438156128
mseloss[6]:0.809256374835968, 0.9405368566513062, 0.8291386365890503, 0.5328129529953003
mseloss[7]:0.7927817106246948, 0.7329709529876709, 0.737801730632782, 0.6949414610862732
mseloss[8]:0.8142728209495544, 0.8207307457923889, 0.705230712890625, 0.42842110991477966
mseloss[9]:0.8025509119033813, 0.748637855052948, 0.6337923407554626, 0.46716368198394775
Epoch:138
0
Train Loss: 0.321 | Acc: 87.877 (3994/4545)
Train Loss: 0.016 | Acc: 99.450 (4520/4545)
1
Train Loss: 0.050 | Acc: 99.868 (4539/4545)
Train Loss: 0.001 | Acc: 100.000 (4545/4545)
2
Train Loss: 0.702 | Acc: 76.216 (3464/4545)
Train Loss: 0.138 | Acc: 94.763 (4307/4545)
3
Train Loss: 0.774 | Acc: 79.098 (3595/4545)
Train Loss: 0.125 | Acc: 95.644 (4347/4545)
4
Train Loss: 0.667 | Acc: 81.496 (3704/4545)
Train Loss: 0.035 | Acc: 98.922 (4496/4545)
5
Train Loss: 0.647 | Acc: 74.961 (3407/4545)
Train Loss: 0.219 | Acc: 90.935 (4133/4545)
6
Train Loss: 0.498 | Acc: 83.498 (3795/4545)
Train Loss: 0.047 | Acc: 98.460 (4475/4545)
7
Train Loss: 0.438 | Acc: 84.158 (3825/4545)
Train Loss: 0.063 | Acc: 97.822 (4446/4545)
8
Train Loss: 0.360 | Acc: 87.481 (3976/4545)
Train Loss: 0.000 | Acc: 100.000 (4545/4545)
9
Train Loss: 0.838 | Acc: 77.338 (3515/4545)
Train Loss: 0.098 | Acc: 96.436 (4383/4545)
10
Train Loss: 0.480 | Acc: 85.963 (3907/4545)
Train Loss: 0.048 | Acc: 98.174 (4462/4545)
layer4.1
layer3.0
layer2.0
1.bn1
layer1.1
layer1.0
linear
layer3.1
layer4.0
1.conv1
layer2.1
Test Loss: 5.271 | Acc: 10.280 (1028/10000)
mseloss[1]:0.7879544496536255, 0.7623403668403625, 0.706819474697113, 0.4670282304286957
mseloss[2]:0.7956656217575073, 0.7903372049331665, 0.7237275242805481, 0.49314621090888977
mseloss[3]:0.8442394137382507, 0.9281553030014038, 0.9792516827583313, 0.6090226173400879
mseloss[4]:0.7997884750366211, 0.7607938051223755, 0.7038439512252808, 0.5742943286895752
mseloss[5]:0.8123624324798584, 0.7432764768600464, 0.560666024684906, 0.5417596697807312
mseloss[6]:0.7910073399543762, 0.741783618927002, 0.7051258683204651, 0.5541013479232788
mseloss[7]:0.8165524005889893, 0.84209805727005, 0.8675150871276855, 0.5628084540367126
mseloss[8]:0.8205503225326538, 0.8466002345085144, 0.852668046951294, 0.5579943656921387
mseloss[9]:0.8426610827445984, 0.9527915120124817, 0.9143578410148621, 0.5817145705223083
Epoch:139
0
Train Loss: 0.585 | Acc: 84.818 (3855/4545)
Train Loss: 0.043 | Acc: 98.460 (4475/4545)
1
Train Loss: 0.709 | Acc: 78.086 (3549/4545)
Train Loss: 0.066 | Acc: 97.624 (4437/4545)
2
Train Loss: 0.610 | Acc: 82.464 (3748/4545)
Train Loss: 0.095 | Acc: 96.854 (4402/4545)
3
Train Loss: 0.334 | Acc: 88.339 (4015/4545)
Train Loss: 0.051 | Acc: 98.284 (4467/4545)
4
Train Loss: 0.509 | Acc: 82.926 (3769/4545)
Train Loss: 0.023 | Acc: 99.230 (4510/4545)
5
Train Loss: 0.295 | Acc: 90.671 (4121/4545)
Train Loss: 0.000 | Acc: 100.000 (4545/4545)
6
Train Loss: 0.349 | Acc: 90.077 (4094/4545)
Train Loss: 0.116 | Acc: 96.040 (4365/4545)
7
Train Loss: 0.225 | Acc: 93.729 (4260/4545)
Train Loss: 0.045 | Acc: 98.416 (4473/4545)
8
Train Loss: 0.206 | Acc: 91.441 (4156/4545)
Train Loss: 0.001 | Acc: 100.000 (4545/4545)
9
Train Loss: 0.697 | Acc: 74.301 (3377/4545)
Train Loss: 0.221 | Acc: 91.155 (4143/4545)
10
Train Loss: 0.608 | Acc: 78.746 (3579/4545)
Train Loss: 0.142 | Acc: 95.006 (4318/4545)
1.conv1
layer4.0
layer1.1
layer4.1
layer2.1
layer1.0
linear
1.bn1
layer3.0
layer2.0
layer3.1
Test Loss: 2.656 | Acc: 18.420 (1842/10000)
mseloss[1]:0.8089738488197327, 0.8666993379592896, 0.9358068108558655, 0.3735318183898926
mseloss[2]:0.8146976232528687, 0.8950897455215454, 0.9093236923217773, 0.3951438367366791
mseloss[3]:0.7772619128227234, 0.7594701647758484, 0.8198511004447937, 0.37936490774154663
mseloss[4]:0.7929885983467102, 0.7664905190467834, 0.734218955039978, 0.4824986159801483
mseloss[5]:0.7854313850402832, 0.7944858074188232, 0.891440749168396, 0.3813289403915405
mseloss[6]:0.8166943192481995, 0.8137061595916748, 0.983919084072113, 0.3809351623058319
mseloss[7]:0.7791191935539246, 0.7647309899330139, 0.7484583854675293, 0.3666485846042633
mseloss[8]:0.7895331978797913, 0.9140904545783997, 1.14847731590271, 0.4474605321884155
mseloss[9]:0.7778956294059753, 0.7505055069923401, 0.7398497462272644, 0.5554739236831665
Epoch:140
0
Train Loss: 0.289 | Acc: 90.913 (4132/4545)
Train Loss: 0.117 | Acc: 95.600 (4345/4545)
1
Train Loss: 0.510 | Acc: 82.376 (3744/4545)
Train Loss: 0.054 | Acc: 98.108 (4459/4545)
2
Train Loss: 0.298 | Acc: 90.869 (4130/4545)
Train Loss: 0.056 | Acc: 98.020 (4455/4545)
3
Train Loss: 0.465 | Acc: 82.046 (3729/4545)
Train Loss: 0.177 | Acc: 93.157 (4234/4545)
4
Train Loss: 0.897 | Acc: 76.722 (3487/4545)
Train Loss: 0.105 | Acc: 96.238 (4374/4545)
5
Train Loss: 0.445 | Acc: 85.941 (3906/4545)
Train Loss: 0.001 | Acc: 100.000 (4545/4545)
6
Train Loss: 0.436 | Acc: 85.721 (3896/4545)
Train Loss: 0.052 | Acc: 98.020 (4455/4545)
7
Train Loss: 0.404 | Acc: 85.985 (3908/4545)
Train Loss: 0.000 | Acc: 100.000 (4545/4545)
8
Train Loss: 0.677 | Acc: 81.078 (3685/4545)
Train Loss: 0.051 | Acc: 98.284 (4467/4545)
9
Train Loss: 0.687 | Acc: 78.064 (3548/4545)
Train Loss: 0.173 | Acc: 93.619 (4255/4545)
10
Train Loss: 0.222 | Acc: 93.245 (4238/4545)
Train Loss: 0.028 | Acc: 99.142 (4506/4545)
1.conv1
layer1.0
layer1.1
1.bn1
layer4.0
layer3.0
layer3.1
layer4.1
layer2.0
linear
layer2.1
Test Loss: 4.224 | Acc: 14.810 (1481/10000)
mseloss[1]:0.8613080382347107, 0.88690185546875, 1.015570044517517, 0.33684593439102173
mseloss[2]:0.8122962713241577, 0.7752062082290649, 0.7650025486946106, 0.28391847014427185
mseloss[3]:0.8125858306884766, 0.7731927633285522, 0.8476603031158447, 0.476173460483551
mseloss[4]:0.8052295446395874, 0.6870366930961609, 0.5204452276229858, 0.1672397404909134
mseloss[5]:0.8290349841117859, 0.7829232215881348, 0.9165655374526978, 0.27791571617126465
mseloss[6]:0.8016796112060547, 0.6839103102684021, 0.662729024887085, 0.2283831387758255
mseloss[7]:0.8608461618423462, 0.9410141706466675, 1.2667136192321777, 0.3424524664878845
mseloss[8]:0.8248500227928162, 0.7797738909721375, 0.9237552285194397, 0.3628687262535095
mseloss[9]:0.7936875820159912, 0.6877132654190063, 0.5862622857093811, 0.22507452964782715
Epoch:141
0
Train Loss: 0.584 | Acc: 82.420 (3746/4545)
Train Loss: 0.052 | Acc: 98.218 (4464/4545)
1
Train Loss: 0.348 | Acc: 88.779 (4035/4545)
Train Loss: 0.103 | Acc: 96.282 (4376/4545)
2
Train Loss: 0.652 | Acc: 83.916 (3814/4545)
Train Loss: 0.000 | Acc: 100.000 (4545/4545)
3
Train Loss: 0.756 | Acc: 79.648 (3620/4545)
Train Loss: 0.019 | Acc: 99.252 (4511/4545)
4
Train Loss: 0.836 | Acc: 79.010 (3591/4545)
Train Loss: 0.034 | Acc: 98.834 (4492/4545)
5
Train Loss: 0.611 | Acc: 81.254 (3693/4545)
Train Loss: 0.069 | Acc: 97.822 (4446/4545)
6
Train Loss: 0.320 | Acc: 87.591 (3981/4545)
Train Loss: 0.159 | Acc: 94.125 (4278/4545)
7
Train Loss: 1.026 | Acc: 76.590 (3481/4545)
Train Loss: 0.060 | Acc: 97.646 (4438/4545)
8
Train Loss: 0.737 | Acc: 75.424 (3428/4545)
Train Loss: 0.199 | Acc: 91.705 (4168/4545)
9
Train Loss: 0.487 | Acc: 85.677 (3894/4545)
Train Loss: 0.000 | Acc: 100.000 (4545/4545)
10
Train Loss: 0.433 | Acc: 84.466 (3839/4545)
Train Loss: 0.118 | Acc: 95.798 (4354/4545)
linear
layer1.1
layer2.1
layer3.0
layer4.1
layer3.1
layer1.0
layer2.0
layer4.0
1.conv1
1.bn1
Test Loss: 6.337 | Acc: 10.000 (1000/10000)
mseloss[1]:0.8424699306488037, 0.8912022113800049, 1.0184239149093628, 0.3948126435279846
mseloss[2]:0.8431228399276733, 0.7926009297370911, 0.7167266607284546, 0.2903057634830475
mseloss[3]:0.7953516840934753, 0.7536998987197876, 0.7715243101119995, 0.40941715240478516
mseloss[4]:0.8103246688842773, 0.7585293054580688, 0.89823317527771, 0.38237836956977844
mseloss[5]:0.8128198385238647, 0.7493758797645569, 0.8185088634490967, 0.3422088027000427
mseloss[6]:0.8125188946723938, 0.7629631161689758, 0.8861438632011414, 0.4460821747779846
mseloss[7]:0.8100423812866211, 0.8149809837341309, 0.9404928088188171, 0.3132374584674835
mseloss[8]:0.8240779638290405, 0.7392168641090393, 0.705176055431366, 0.3779825270175934
mseloss[9]:0.7934140563011169, 0.7616493701934814, 0.7635440826416016, 0.25966382026672363
Epoch:142
0
Train Loss: 0.185 | Acc: 91.507 (4159/4545)
Train Loss: 0.000 | Acc: 100.000 (4545/4545)
1
Train Loss: 0.585 | Acc: 83.212 (3782/4545)
Train Loss: 0.075 | Acc: 97.448 (4429/4545)
2
Train Loss: 1.021 | Acc: 70.011 (3182/4545)
Train Loss: 0.169 | Acc: 93.619 (4255/4545)
3
Train Loss: 0.907 | Acc: 71.837 (3265/4545)
Train Loss: 0.208 | Acc: 91.595 (4163/4545)
4
Train Loss: 0.406 | Acc: 86.535 (3933/4545)
Train Loss: 0.049 | Acc: 98.416 (4473/4545)
5
Train Loss: 0.617 | Acc: 80.550 (3661/4545)
Train Loss: 0.132 | Acc: 95.336 (4333/4545)
6
Train Loss: 0.676 | Acc: 78.570 (3571/4545)
Train Loss: 0.125 | Acc: 95.226 (4328/4545)
7
Train Loss: 0.258 | Acc: 91.507 (4159/4545)
Train Loss: 0.000 | Acc: 100.000 (4545/4545)
8
Train Loss: 0.526 | Acc: 85.303 (3877/4545)
Train Loss: 0.035 | Acc: 98.856 (4493/4545)
9
Train Loss: 0.286 | Acc: 90.715 (4123/4545)
Train Loss: 0.028 | Acc: 98.790 (4490/4545)
10
Train Loss: 0.273 | Acc: 89.285 (4058/4545)
Train Loss: 0.050 | Acc: 98.064 (4457/4545)
layer1.0
layer1.1
linear
1.bn1
layer2.1
layer3.1
layer2.0
layer3.0
1.conv1
layer4.1
layer4.0
Test Loss: 4.367 | Acc: 14.990 (1499/10000)
mseloss[1]:0.8021798133850098, 0.8902090191841125, 1.1075454950332642, 0.3461054861545563
mseloss[2]:0.826456606388092, 1.0010255575180054, 1.2103067636489868, 0.31612399220466614
mseloss[3]:0.7952151298522949, 0.8087451457977295, 0.8235061764717102, 0.37871691584587097
mseloss[4]:0.769653856754303, 0.7672751545906067, 0.6301592588424683, 0.22116929292678833
mseloss[5]:0.8454580307006836, 1.0402418375015259, 1.278963565826416, 0.352417528629303
mseloss[6]:0.8402823209762573, 1.0718202590942383, 1.1626968383789062, 0.3328569233417511
mseloss[7]:0.7710632085800171, 0.7663456797599792, 0.6655409932136536, 0.20928609371185303
mseloss[8]:0.790875256061554, 0.8358147144317627, 0.9858931303024292, 0.3403690755367279
mseloss[9]:0.8132860660552979, 0.8492684364318848, 0.8099539279937744, 0.3505193293094635
Epoch:143
0
Train Loss: 0.407 | Acc: 84.070 (3821/4545)
Train Loss: 0.196 | Acc: 92.387 (4199/4545)
1
Train Loss: 0.917 | Acc: 76.700 (3486/4545)
Train Loss: 0.140 | Acc: 94.939 (4315/4545)
2
Train Loss: 0.523 | Acc: 82.838 (3765/4545)
Train Loss: 0.044 | Acc: 98.570 (4480/4545)
3
Train Loss: 0.352 | Acc: 85.083 (3867/4545)
Train Loss: 0.164 | Acc: 93.751 (4261/4545)
4
Train Loss: 0.554 | Acc: 82.838 (3765/4545)
Train Loss: 0.056 | Acc: 97.690 (4440/4545)
5
Train Loss: 0.465 | Acc: 86.865 (3948/4545)
Train Loss: 0.030 | Acc: 98.900 (4495/4545)
6
Train Loss: 0.683 | Acc: 79.054 (3593/4545)
Train Loss: 0.025 | Acc: 99.076 (4503/4545)
7
Train Loss: 0.345 | Acc: 87.723 (3987/4545)
Train Loss: 0.000 | Acc: 100.000 (4545/4545)
8
Train Loss: 0.834 | Acc: 77.866 (3539/4545)
Train Loss: 0.119 | Acc: 95.358 (4334/4545)
9
Train Loss: 0.585 | Acc: 83.542 (3797/4545)
Train Loss: 0.000 | Acc: 100.000 (4545/4545)
10
Train Loss: 0.618 | Acc: 82.706 (3759/4545)
Train Loss: 0.063 | Acc: 97.888 (4449/4545)
1.bn1
layer2.0
layer1.0
linear
layer4.0
layer3.1
layer3.0
1.conv1
layer4.1
layer1.1
layer2.1
Test Loss: 3.493 | Acc: 10.360 (1036/10000)
mseloss[1]:0.8152710199356079, 0.9010214805603027, 1.2245970964431763, 0.485817015171051
mseloss[2]:0.7870708703994751, 0.7768082618713379, 0.8355438113212585, 0.3819011151790619
mseloss[3]:0.8018659353256226, 0.8070077896118164, 0.8076571822166443, 0.3320784866809845
mseloss[4]:0.8040502071380615, 0.7984378337860107, 0.7704420685768127, 0.39778271317481995
mseloss[5]:0.7924447655677795, 0.7190963625907898, 0.6330451369285583, 0.4035170078277588
mseloss[6]:0.803555428981781, 0.7240605354309082, 0.5604115128517151, 0.33309707045555115
mseloss[7]:0.8003641963005066, 0.7941470742225647, 0.8672800660133362, 0.38385871052742004
mseloss[8]:0.8283281922340393, 0.9680111408233643, 1.0033197402954102, 0.41228774189949036
mseloss[9]:0.7760066390037537, 0.7468618750572205, 0.7064242959022522, 0.34952181577682495
Epoch:144
0
Train Loss: 0.353 | Acc: 87.679 (3985/4545)
Train Loss: 0.072 | Acc: 97.646 (4438/4545)
1
Train Loss: 0.400 | Acc: 86.777 (3944/4545)
Train Loss: 0.118 | Acc: 96.062 (4366/4545)
2
Train Loss: 0.440 | Acc: 86.403 (3927/4545)
Train Loss: 0.025 | Acc: 99.142 (4506/4545)
3
Train Loss: 0.541 | Acc: 82.090 (3731/4545)
Train Loss: 0.045 | Acc: 98.438 (4474/4545)
4
Train Loss: 0.514 | Acc: 84.664 (3848/4545)
Train Loss: 0.000 | Acc: 100.000 (4545/4545)
5
Train Loss: 0.362 | Acc: 88.185 (4008/4545)
Train Loss: 0.000 | Acc: 100.000 (4545/4545)
6
Train Loss: 0.264 | Acc: 91.529 (4160/4545)
Train Loss: 0.057 | Acc: 98.020 (4455/4545)
7
Train Loss: 0.681 | Acc: 80.066 (3639/4545)
Train Loss: 0.025 | Acc: 99.054 (4502/4545)
8
Train Loss: 0.633 | Acc: 79.868 (3630/4545)
Train Loss: 0.131 | Acc: 94.961 (4316/4545)
9
Train Loss: 0.451 | Acc: 81.848 (3720/4545)
Train Loss: 0.182 | Acc: 93.113 (4232/4545)
10
Train Loss: 0.602 | Acc: 77.976 (3544/4545)
Train Loss: 0.236 | Acc: 90.539 (4115/4545)
layer2.0
layer3.0
layer2.1
layer3.1
1.conv1
1.bn1
layer1.0
linear
layer1.1
layer4.0
layer4.1
Test Loss: 8.943 | Acc: 10.000 (1000/10000)
mseloss[1]:0.7917523980140686, 0.8065313100814819, 0.6765927672386169, 0.17787207663059235
mseloss[2]:0.7787923812866211, 0.982771635055542, 1.0720590353012085, 0.4082324206829071
mseloss[3]:0.776606559753418, 0.9932945966720581, 1.0974953174591064, 0.3122560977935791
mseloss[4]:0.8138909935951233, 1.1730139255523682, 1.2315329313278198, 0.29551032185554504
mseloss[5]:0.7728080153465271, 0.972079336643219, 1.1122475862503052, 0.2989949882030487
mseloss[6]:0.794357180595398, 0.9716038703918457, 0.9389316439628601, 0.38122886419296265
mseloss[7]:0.7499403357505798, 0.9742020964622498, 1.039002537727356, 0.3933509290218353
mseloss[8]:0.7616742849349976, 0.6591016054153442, 0.4420839846134186, 0.16562864184379578
mseloss[9]:0.7515175938606262, 0.79227614402771, 0.7142168879508972, 0.2482239007949829
Epoch:145
0
Train Loss: 0.496 | Acc: 83.344 (3788/4545)
Train Loss: 0.053 | Acc: 98.306 (4468/4545)
1
Train Loss: 0.627 | Acc: 79.868 (3630/4545)
Train Loss: 0.113 | Acc: 95.820 (4355/4545)
2
Train Loss: 0.617 | Acc: 81.760 (3716/4545)
Train Loss: 0.065 | Acc: 98.020 (4455/4545)
3
Train Loss: 0.523 | Acc: 78.306 (3559/4545)
Train Loss: 0.181 | Acc: 93.069 (4230/4545)
4
Train Loss: 0.894 | Acc: 78.768 (3580/4545)
Train Loss: 0.000 | Acc: 100.000 (4545/4545)
5
Train Loss: 0.375 | Acc: 88.097 (4004/4545)
Train Loss: 0.000 | Acc: 100.000 (4545/4545)
6
Train Loss: 0.765 | Acc: 77.008 (3500/4545)
Train Loss: 0.135 | Acc: 95.556 (4343/4545)
7
Train Loss: 0.603 | Acc: 81.342 (3697/4545)
Train Loss: 0.056 | Acc: 97.778 (4444/4545)
8
Train Loss: 0.851 | Acc: 78.570 (3571/4545)
Train Loss: 0.039 | Acc: 98.592 (4481/4545)
9
Train Loss: 0.262 | Acc: 89.703 (4077/4545)
Train Loss: 0.038 | Acc: 98.702 (4486/4545)
10
Train Loss: 0.523 | Acc: 79.054 (3593/4545)
Train Loss: 0.227 | Acc: 90.891 (4131/4545)
layer4.1
linear
1.conv1
layer4.0
layer3.0
1.bn1
layer3.1
layer1.1
layer2.0
layer1.0
layer2.1
Test Loss: 5.134 | Acc: 10.000 (1000/10000)
mseloss[1]:0.8062333464622498, 1.024131178855896, 1.067491888999939, 0.26055315136909485
mseloss[2]:0.7866403460502625, 1.0403345823287964, 1.198225498199463, 0.2927877604961395
mseloss[3]:0.7884882688522339, 0.9692522287368774, 0.9521566033363342, 0.2497607320547104
mseloss[4]:0.7632248997688293, 0.8612223267555237, 1.1275495290756226, 0.17256340384483337
mseloss[5]:0.7687051296234131, 0.8131664395332336, 0.6571474671363831, 0.179576575756073
mseloss[6]:0.8005483150482178, 0.9228075742721558, 1.1103923320770264, 0.2707219421863556
mseloss[7]:0.7701808214187622, 0.8490013480186462, 0.9923365712165833, 0.2516258656978607
mseloss[8]:0.7723572850227356, 0.8401920199394226, 1.1270798444747925, 0.3010920286178589
mseloss[9]:0.7811802625656128, 0.8678063750267029, 0.9593963623046875, 0.4364496171474457
Epoch:146
0
Train Loss: 0.887 | Acc: 78.438 (3565/4545)
Train Loss: 0.036 | Acc: 98.746 (4488/4545)
1
Train Loss: 0.664 | Acc: 81.738 (3715/4545)
Train Loss: 0.000 | Acc: 100.000 (4545/4545)
2
Train Loss: 0.534 | Acc: 77.800 (3536/4545)
Train Loss: 0.203 | Acc: 91.683 (4167/4545)
3
Train Loss: 0.152 | Acc: 95.358 (4334/4545)
Train Loss: 0.029 | Acc: 98.812 (4491/4545)
4
Train Loss: 0.367 | Acc: 86.667 (3939/4545)
Train Loss: 0.050 | Acc: 97.976 (4453/4545)
5
Train Loss: 1.052 | Acc: 73.377 (3335/4545)
Train Loss: 0.127 | Acc: 95.754 (4352/4545)
6
Train Loss: 0.939 | Acc: 76.678 (3485/4545)
Train Loss: 0.063 | Acc: 97.778 (4444/4545)
7
Train Loss: 0.729 | Acc: 78.944 (3588/4545)
Train Loss: 0.060 | Acc: 98.196 (4463/4545)
8
Train Loss: 0.437 | Acc: 87.239 (3965/4545)
Train Loss: 0.000 | Acc: 100.000 (4545/4545)
9
Train Loss: 0.431 | Acc: 86.051 (3911/4545)
Train Loss: 0.123 | Acc: 95.468 (4339/4545)
10
Train Loss: 0.438 | Acc: 83.212 (3782/4545)
Train Loss: 0.185 | Acc: 92.871 (4221/4545)
layer1.1
layer3.1
1.conv1
layer3.0
layer2.0
layer2.1
linear
layer4.1
layer1.0
layer4.0
1.bn1
Test Loss: 3.307 | Acc: 20.780 (2078/10000)
mseloss[1]:0.7530717253684998, 0.6317209005355835, 0.6750066876411438, 0.2873983681201935
mseloss[2]:0.791890025138855, 0.7572951316833496, 0.8657760620117188, 0.4860612750053406
mseloss[3]:0.7709080576896667, 0.7217669486999512, 0.805124819278717, 0.47738736867904663
mseloss[4]:0.7779479622840881, 0.7326500415802002, 0.7116422057151794, 0.363129198551178
mseloss[5]:0.8519303798675537, 0.865973174571991, 1.2339723110198975, 0.33732670545578003
mseloss[6]:0.8033705353736877, 0.7544898390769958, 1.0550525188446045, 0.3464345932006836
mseloss[7]:0.781559407711029, 0.7549195885658264, 1.0169316530227661, 0.38963305950164795
mseloss[8]:0.7930947542190552, 0.7904818654060364, 1.0088520050048828, 0.3611255884170532
mseloss[9]:0.8147064447402954, 0.8689311742782593, 1.1665995121002197, 0.3794602155685425
Epoch:147
0
Train Loss: 0.653 | Acc: 77.624 (3528/4545)
Train Loss: 0.193 | Acc: 92.563 (4207/4545)
1
Train Loss: 0.140 | Acc: 95.424 (4337/4545)
Train Loss: 0.043 | Acc: 98.614 (4482/4545)
2
Train Loss: 0.311 | Acc: 91.045 (4138/4545)
Train Loss: 0.040 | Acc: 98.856 (4493/4545)
3
Train Loss: 0.940 | Acc: 78.350 (3561/4545)
Train Loss: 0.070 | Acc: 97.910 (4450/4545)
4
Train Loss: 0.948 | Acc: 79.670 (3621/4545)
Train Loss: 0.000 | Acc: 100.000 (4545/4545)
5
Train Loss: 0.580 | Acc: 79.054 (3593/4545)
Train Loss: 0.187 | Acc: 91.991 (4181/4545)
6
Train Loss: 0.630 | Acc: 82.134 (3733/4545)
Train Loss: 0.047 | Acc: 98.240 (4465/4545)
7
Train Loss: 0.891 | Acc: 79.626 (3619/4545)
Train Loss: 0.114 | Acc: 95.930 (4360/4545)
8
Train Loss: 0.676 | Acc: 82.618 (3755/4545)
Train Loss: 0.056 | Acc: 98.218 (4464/4545)
9
Train Loss: 0.278 | Acc: 89.021 (4046/4545)
Train Loss: 0.000 | Acc: 100.000 (4545/4545)
10
Train Loss: 0.454 | Acc: 84.070 (3821/4545)
Train Loss: 0.113 | Acc: 95.996 (4363/4545)
layer2.1
layer1.0
layer2.0
layer4.0
layer3.0
1.conv1
layer4.1
linear
layer3.1
1.bn1
layer1.1
Test Loss: 3.297 | Acc: 12.720 (1272/10000)
mseloss[1]:0.7896723747253418, 0.7612839937210083, 0.805068850517273, 0.35938405990600586
mseloss[2]:0.7893949747085571, 0.7601499557495117, 0.7183911800384521, 0.39663389325141907
mseloss[3]:0.7868471145629883, 0.8072641491889954, 0.7237434983253479, 0.2744990885257721
mseloss[4]:0.8399746417999268, 0.9226020574569702, 1.0092401504516602, 0.3725231885910034
mseloss[5]:0.8038963675498962, 0.7422717809677124, 0.6436191201210022, 0.43382754921913147
mseloss[6]:0.7921352982521057, 0.8017328381538391, 0.831303060054779, 0.38047295808792114
mseloss[7]:0.8358425498008728, 0.8437269330024719, 0.6643258929252625, 0.2183464616537094
mseloss[8]:0.8226205706596375, 0.7693530917167664, 0.7783238291740417, 0.3174525797367096
mseloss[9]:0.7860609889030457, 0.7523136734962463, 0.690864622592926, 0.30106329917907715
Epoch:148
0
Train Loss: 0.660 | Acc: 83.938 (3815/4545)
Train Loss: 0.000 | Acc: 100.000 (4545/4545)
1
Train Loss: 0.217 | Acc: 92.981 (4226/4545)
Train Loss: 0.013 | Acc: 99.516 (4523/4545)
2
Train Loss: 0.579 | Acc: 86.161 (3916/4545)
Train Loss: 0.050 | Acc: 98.592 (4481/4545)
3
Train Loss: 0.797 | Acc: 81.144 (3688/4545)
Train Loss: 0.131 | Acc: 95.336 (4333/4545)
4
Train Loss: 0.769 | Acc: 75.776 (3444/4545)
Train Loss: 0.189 | Acc: 92.409 (4200/4545)
5
Train Loss: 0.516 | Acc: 80.858 (3675/4545)
Train Loss: 0.178 | Acc: 93.113 (4232/4545)
6
Train Loss: 0.306 | Acc: 91.925 (4178/4545)
Train Loss: 0.052 | Acc: 98.196 (4463/4545)
7
Train Loss: 0.431 | Acc: 85.721 (3896/4545)
Train Loss: 0.044 | Acc: 98.394 (4472/4545)
8
Train Loss: 0.536 | Acc: 82.420 (3746/4545)
Train Loss: 0.121 | Acc: 95.446 (4338/4545)
9
Train Loss: 0.634 | Acc: 85.831 (3901/4545)
Train Loss: 0.000 | Acc: 100.000 (4545/4545)
10
Train Loss: 0.313 | Acc: 89.109 (4050/4545)
Train Loss: 0.049 | Acc: 98.152 (4461/4545)
layer1.1
layer2.1
layer4.0
layer3.0
layer3.1
1.conv1
linear
layer2.0
1.bn1
layer1.0
layer4.1
Test Loss: 2.766 | Acc: 28.500 (2850/10000)
mseloss[1]:0.7419908046722412, 0.6915370225906372, 0.5566111207008362, 0.4005838632583618
mseloss[2]:0.7629503011703491, 0.7286871075630188, 0.8201550841331482, 0.4511570632457733
mseloss[3]:0.800909161567688, 0.7924150824546814, 0.9768071174621582, 0.39883092045783997
mseloss[4]:0.7769737839698792, 0.7367180585861206, 0.8034314513206482, 0.4719153046607971
mseloss[5]:0.7572205662727356, 0.738795816898346, 0.7211704254150391, 0.5123570561408997
mseloss[6]:0.7619043588638306, 0.7116785645484924, 0.656990647315979, 0.3671920895576477
mseloss[7]:0.7326528429985046, 0.7402498722076416, 0.5740028023719788, 0.24989770352840424
mseloss[8]:0.7875325083732605, 0.7607338428497314, 0.8965125679969788, 0.39189624786376953
mseloss[9]:0.7553625106811523, 0.8182376027107239, 0.8938964605331421, 0.3259667754173279
Epoch:149
0
Train Loss: 0.700 | Acc: 78.680 (3576/4545)
Train Loss: 0.156 | Acc: 94.191 (4281/4545)
1
Train Loss: 0.412 | Acc: 87.833 (3992/4545)
Train Loss: 0.045 | Acc: 98.174 (4462/4545)
2
Train Loss: 0.499 | Acc: 87.217 (3964/4545)
Train Loss: 0.000 | Acc: 100.000 (4545/4545)
3
Train Loss: 0.157 | Acc: 95.050 (4320/4545)
Train Loss: 0.047 | Acc: 98.262 (4466/4545)
4
Train Loss: 0.529 | Acc: 84.356 (3834/4545)
Train Loss: 0.047 | Acc: 98.174 (4462/4545)
5
Train Loss: 0.750 | Acc: 82.970 (3771/4545)
Train Loss: 0.000 | Acc: 100.000 (4545/4545)
6
Train Loss: 0.228 | Acc: 92.035 (4183/4545)
Train Loss: 0.034 | Acc: 98.680 (4485/4545)
7
Train Loss: 0.490 | Acc: 86.579 (3935/4545)
Train Loss: 0.027 | Acc: 98.900 (4495/4545)
8
Train Loss: 0.967 | Acc: 74.279 (3376/4545)
Train Loss: 0.149 | Acc: 93.553 (4252/4545)
9
Train Loss: 0.750 | Acc: 76.590 (3481/4545)
Train Loss: 0.183 | Acc: 92.739 (4215/4545)
10
Train Loss: 0.723 | Acc: 81.320 (3696/4545)
Train Loss: 0.130 | Acc: 95.094 (4322/4545)
1.conv1
linear
layer3.1
layer4.1
layer1.0
layer1.1
layer4.0
layer3.0
layer2.1
1.bn1
layer2.0
Test Loss: 4.533 | Acc: 10.260 (1026/10000)
mseloss[1]:0.7682186365127563, 0.7990908026695251, 0.7251558899879456, 0.4308016300201416
mseloss[2]:0.775899350643158, 0.8356422781944275, 0.8091145157814026, 0.3897448480129242
mseloss[3]:0.7426177859306335, 0.7292068600654602, 0.6593694686889648, 0.42836010456085205
mseloss[4]:0.7778702974319458, 0.8163691759109497, 0.7334448099136353, 0.40119701623916626
mseloss[5]:0.7505296468734741, 0.8042038083076477, 0.6886034607887268, 0.4179227352142334
mseloss[6]:0.7656099796295166, 0.7687022089958191, 0.5974588990211487, 0.36503779888153076
mseloss[7]:0.775059700012207, 0.7644709944725037, 0.573911726474762, 0.40111327171325684
mseloss[8]:0.786249577999115, 0.7499750256538391, 0.5865462422370911, 0.34184277057647705
mseloss[9]:0.788524329662323, 0.7541954517364502, 0.5057821273803711, 0.34051740169525146
Epoch:150
0
Train Loss: 0.666 | Acc: 84.048 (3820/4545)
Train Loss: 0.000 | Acc: 100.000 (4545/4545)
1
Train Loss: 0.728 | Acc: 81.166 (3689/4545)
Train Loss: 0.119 | Acc: 95.886 (4358/4545)
2
Train Loss: 0.812 | Acc: 75.622 (3437/4545)
Train Loss: 0.185 | Acc: 92.717 (4214/4545)
3
Train Loss: 0.127 | Acc: 95.512 (4341/4545)
Train Loss: 0.048 | Acc: 98.218 (4464/4545)
4
Train Loss: 0.449 | Acc: 85.281 (3876/4545)
Train Loss: 0.062 | Acc: 97.844 (4447/4545)
5
Train Loss: 0.646 | Acc: 84.554 (3843/4545)
Train Loss: 0.027 | Acc: 99.098 (4504/4545)
6
Train Loss: 0.825 | Acc: 74.257 (3375/4545)
Train Loss: 0.191 | Acc: 92.321 (4196/4545)
7
Train Loss: 0.756 | Acc: 81.870 (3721/4545)
Train Loss: 0.040 | Acc: 98.548 (4479/4545)
8
Train Loss: 0.398 | Acc: 86.711 (3941/4545)
Train Loss: 0.039 | Acc: 98.636 (4483/4545)
9
Train Loss: 0.686 | Acc: 77.778 (3535/4545)
Train Loss: 0.143 | Acc: 94.609 (4300/4545)
10
Train Loss: 0.583 | Acc: 83.542 (3797/4545)
Train Loss: 0.000 | Acc: 100.000 (4545/4545)
layer4.1
layer1.1
layer4.0
layer2.1
layer2.0
layer1.0
layer3.1
1.bn1
layer3.0
1.conv1
linear
Test Loss: 6.500 | Acc: 10.000 (1000/10000)
mseloss[1]:0.8053985834121704, 0.8574882745742798, 0.9344845414161682, 0.24956436455249786
mseloss[2]:0.7689274549484253, 0.8193241953849792, 0.6834520101547241, 0.3452441692352295
mseloss[3]:0.7483097910881042, 0.7917246222496033, 0.577494204044342, 0.2382359355688095
mseloss[4]:0.7680744528770447, 0.9009469151496887, 0.9453896284103394, 0.26654288172721863
mseloss[5]:0.7836071252822876, 0.8197094202041626, 0.7172454595565796, 0.4064743220806122
mseloss[6]:0.7860875129699707, 0.8307233452796936, 0.7773939967155457, 0.3403246998786926
mseloss[7]:0.7520692348480225, 0.8196523785591125, 0.8462124466896057, 0.31641772389411926
mseloss[8]:0.7298213243484497, 0.8069193959236145, 0.6309042572975159, 0.22197093069553375
mseloss[9]:0.784830629825592, 0.8902851343154907, 1.0652029514312744, 0.3038649559020996
Epoch:151
0
Train Loss: 0.798 | Acc: 79.956 (3634/4545)
Train Loss: 0.024 | Acc: 99.076 (4503/4545)
1
Train Loss: 1.079 | Acc: 77.074 (3503/4545)
Train Loss: 0.041 | Acc: 98.592 (4481/4545)
2
Train Loss: 0.685 | Acc: 78.768 (3580/4545)
Train Loss: 0.139 | Acc: 94.653 (4302/4545)
3
Train Loss: 0.875 | Acc: 78.416 (3564/4545)
Train Loss: 0.060 | Acc: 97.888 (4449/4545)
4
Train Loss: 0.037 | Acc: 99.890 (4540/4545)
Train Loss: 0.000 | Acc: 100.000 (4545/4545)
5
Train Loss: 0.830 | Acc: 72.827 (3310/4545)
Train Loss: 0.194 | Acc: 91.991 (4181/4545)
6
Train Loss: 0.545 | Acc: 82.090 (3731/4545)
Train Loss: 0.199 | Acc: 92.673 (4212/4545)
7
Train Loss: 0.983 | Acc: 78.548 (3570/4545)
Train Loss: 0.040 | Acc: 98.592 (4481/4545)
8
Train Loss: 0.579 | Acc: 80.880 (3676/4545)
Train Loss: 0.113 | Acc: 95.842 (4356/4545)
9
Train Loss: 0.768 | Acc: 79.648 (3620/4545)
Train Loss: 0.057 | Acc: 98.152 (4461/4545)
10
Train Loss: 0.582 | Acc: 84.642 (3847/4545)
Train Loss: 0.000 | Acc: 100.000 (4545/4545)
linear
layer1.1
layer4.0
layer3.0
layer2.1
1.conv1
layer2.0
1.bn1
layer3.1
layer4.1
layer1.0
Test Loss: 3.318 | Acc: 13.910 (1391/10000)
mseloss[1]:0.7649407982826233, 0.8301066160202026, 0.7792887091636658, 0.39026153087615967
mseloss[2]:0.7961745262145996, 0.8472567796707153, 1.024619460105896, 0.42971071600914
mseloss[3]:0.7899443507194519, 0.9223437309265137, 1.231744647026062, 0.404264897108078
mseloss[4]:0.7464056015014648, 0.718608558177948, 0.5727548599243164, 0.3818051517009735
mseloss[5]:0.7829376459121704, 0.7438387274742126, 0.5750482678413391, 0.30010733008384705
mseloss[6]:0.7703072428703308, 0.7812163233757019, 0.82511305809021, 0.39499324560165405
mseloss[7]:0.7864857316017151, 0.8182669878005981, 1.0023772716522217, 0.42201969027519226
mseloss[8]:0.8186861276626587, 0.9244447350502014, 1.2926279306411743, 0.4752058684825897
mseloss[9]:0.7682201862335205, 0.9267382621765137, 1.162519931793213, 0.4489271640777588
Epoch:152
0
Train Loss: 0.465 | Acc: 84.862 (3857/4545)
Train Loss: 0.026 | Acc: 98.966 (4498/4545)
1
Train Loss: 0.996 | Acc: 75.996 (3454/4545)
Train Loss: 0.042 | Acc: 98.394 (4472/4545)
2
Train Loss: 0.760 | Acc: 81.804 (3718/4545)
Train Loss: 0.000 | Acc: 100.000 (4545/4545)
3
Train Loss: 0.233 | Acc: 91.837 (4174/4545)
Train Loss: 0.108 | Acc: 96.084 (4367/4545)
4
Train Loss: 0.273 | Acc: 90.891 (4131/4545)
Train Loss: 0.104 | Acc: 96.216 (4373/4545)
5
Train Loss: 1.103 | Acc: 76.326 (3469/4545)
Train Loss: 0.042 | Acc: 98.702 (4486/4545)
6
Train Loss: 1.269 | Acc: 64.444 (2929/4545)
Train Loss: 0.235 | Acc: 90.319 (4105/4545)
7
Train Loss: 0.531 | Acc: 83.498 (3795/4545)
Train Loss: 0.056 | Acc: 98.086 (4458/4545)
8
Train Loss: 0.768 | Acc: 79.098 (3595/4545)
Train Loss: 0.183 | Acc: 92.827 (4219/4545)
9
Train Loss: 0.525 | Acc: 83.894 (3813/4545)
Train Loss: 0.074 | Acc: 97.492 (4431/4545)
10
Train Loss: 0.473 | Acc: 84.840 (3856/4545)
Train Loss: 0.000 | Acc: 100.000 (4545/4545)
layer4.0
layer2.0
1.bn1
layer3.0
layer1.1
1.conv1
linear
layer1.0
layer3.1
layer2.1
layer4.1
Test Loss: 9.211 | Acc: 10.010 (1001/10000)
mseloss[1]:0.7707321047782898, 0.7952967882156372, 0.9058424830436707, 0.3931737542152405
mseloss[2]:0.7957452535629272, 0.9205873608589172, 1.1115275621414185, 0.39397335052490234
mseloss[3]:0.8157962560653687, 0.8379514217376709, 1.2442958354949951, 0.4338981509208679
mseloss[4]:0.8058593273162842, 0.8673577308654785, 1.209867238998413, 0.43915465474128723
mseloss[5]:0.7895418405532837, 0.775052011013031, 1.1058392524719238, 0.4190501272678375
mseloss[6]:0.8025533556938171, 0.8437779545783997, 0.9744059443473816, 0.4094308912754059
mseloss[7]:0.7826764583587646, 0.8094252943992615, 0.9056584239006042, 0.4018586575984955
mseloss[8]:0.7755855917930603, 0.8101215362548828, 1.1161160469055176, 0.43456634879112244
mseloss[9]:0.7890550494194031, 0.8765193223953247, 1.298628330230713, 0.42173144221305847
Epoch:153
0
Train Loss: 0.421 | Acc: 82.596 (3754/4545)
Train Loss: 0.188 | Acc: 92.431 (4201/4545)
1
Train Loss: 1.043 | Acc: 75.600 (3436/4545)
Train Loss: 0.205 | Acc: 92.211 (4191/4545)
2
Train Loss: 0.748 | Acc: 80.066 (3639/4545)
Train Loss: 0.058 | Acc: 98.042 (4456/4545)
3
Train Loss: 0.252 | Acc: 91.573 (4162/4545)
Train Loss: 0.020 | Acc: 99.384 (4517/4545)
4
Train Loss: 1.030 | Acc: 78.988 (3590/4545)
Train Loss: 0.000 | Acc: 100.000 (4545/4545)
5
Train Loss: 0.553 | Acc: 82.464 (3748/4545)
Train Loss: 0.067 | Acc: 97.976 (4453/4545)
6
Train Loss: 0.951 | Acc: 75.864 (3448/4545)
Train Loss: 0.135 | Acc: 95.226 (4328/4545)
7
Train Loss: 0.997 | Acc: 76.920 (3496/4545)
Train Loss: 0.032 | Acc: 98.944 (4497/4545)
8
Train Loss: 1.265 | Acc: 69.659 (3166/4545)
Train Loss: 0.146 | Acc: 94.741 (4306/4545)
9
Train Loss: 0.760 | Acc: 80.440 (3656/4545)
Train Loss: 0.041 | Acc: 98.526 (4478/4545)
10
Train Loss: 0.338 | Acc: 87.767 (3989/4545)
Train Loss: 0.001 | Acc: 100.000 (4545/4545)
layer4.1
layer3.1
1.bn1
1.conv1
layer1.0
layer1.1
layer3.0
layer2.0
layer4.0
linear
layer2.1
Test Loss: 4.085 | Acc: 12.790 (1279/10000)
mseloss[1]:0.7959955334663391, 0.8277068138122559, 1.2711822986602783, 0.3239215016365051
mseloss[2]:0.7598921656608582, 0.8844811320304871, 1.2368667125701904, 0.30255115032196045
mseloss[3]:0.7686856389045715, 0.7475859522819519, 0.7181490659713745, 0.267562597990036
mseloss[4]:0.7851728200912476, 0.9493730068206787, 1.1313624382019043, 0.28631213307380676
mseloss[5]:0.7696365714073181, 0.8774268627166748, 1.3158570528030396, 0.27129146456718445
mseloss[6]:0.7936376929283142, 0.8649918437004089, 1.554975986480713, 0.3238784074783325
mseloss[7]:0.7632542252540588, 0.7743026614189148, 0.7984339594841003, 0.3010850250720978
mseloss[8]:0.788006603717804, 0.904484748840332, 1.3813010454177856, 0.2678542733192444
mseloss[9]:0.7782618999481201, 0.7757797241210938, 1.0274617671966553, 0.2826959192752838
Epoch:154
0
Train Loss: 0.533 | Acc: 83.520 (3796/4545)
Train Loss: 0.034 | Acc: 98.922 (4496/4545)
1
Train Loss: 0.326 | Acc: 91.221 (4146/4545)
Train Loss: 0.043 | Acc: 98.570 (4480/4545)
2
Train Loss: 0.319 | Acc: 90.165 (4098/4545)
Train Loss: 0.054 | Acc: 98.196 (4463/4545)
3
Train Loss: 0.573 | Acc: 81.474 (3703/4545)
Train Loss: 0.128 | Acc: 95.754 (4352/4545)
4
Train Loss: 0.578 | Acc: 83.784 (3808/4545)
Train Loss: 0.000 | Acc: 100.000 (4545/4545)
5
Train Loss: 0.597 | Acc: 76.260 (3466/4545)
Train Loss: 0.212 | Acc: 91.199 (4145/4545)
6
Train Loss: 0.790 | Acc: 81.826 (3719/4545)
Train Loss: 0.000 | Acc: 100.000 (4545/4545)
7
Train Loss: 0.531 | Acc: 83.278 (3785/4545)
Train Loss: 0.052 | Acc: 98.086 (4458/4545)
8
Train Loss: 0.519 | Acc: 83.960 (3816/4545)
Train Loss: 0.118 | Acc: 95.864 (4357/4545)
9
Train Loss: 0.721 | Acc: 80.242 (3647/4545)
Train Loss: 0.041 | Acc: 98.306 (4468/4545)
10
Train Loss: 0.456 | Acc: 83.674 (3803/4545)
Train Loss: 0.179 | Acc: 93.289 (4240/4545)
1.conv1
layer4.0
linear
layer2.0
layer2.1
layer1.0
layer1.1
layer3.0
1.bn1
layer4.1
layer3.1
Test Loss: 3.705 | Acc: 14.630 (1463/10000)
mseloss[1]:0.7613595724105835, 0.7370973825454712, 0.6998319029808044, 0.24857641756534576
mseloss[2]:0.7433279752731323, 0.7724055051803589, 1.068325400352478, 0.27753785252571106
mseloss[3]:0.7815845012664795, 0.8359524011611938, 1.1841071844100952, 0.31653520464897156
mseloss[4]:0.7263092994689941, 0.7731882929801941, 0.7973498106002808, 0.24684742093086243
mseloss[5]:0.7711431384086609, 0.7596001029014587, 0.6850507855415344, 0.30378445982933044
mseloss[6]:0.766681969165802, 0.8474146723747253, 0.9835636019706726, 0.3130258321762085
mseloss[7]:0.7527599930763245, 0.8106244802474976, 1.136879563331604, 0.34448719024658203
mseloss[8]:0.7912780046463013, 0.8124482035636902, 1.192321538925171, 0.3176064193248749
mseloss[9]:0.7282326221466064, 0.7593250870704651, 0.834868311882019, 0.2998228669166565
Epoch:155
0
Train Loss: 0.446 | Acc: 85.303 (3877/4545)
Train Loss: 0.000 | Acc: 100.000 (4545/4545)
1
Train Loss: 0.379 | Acc: 88.031 (4001/4545)
Train Loss: 0.033 | Acc: 98.834 (4492/4545)
2
Train Loss: 1.518 | Acc: 66.381 (3017/4545)
Train Loss: 0.131 | Acc: 95.204 (4327/4545)
3
Train Loss: 0.451 | Acc: 86.249 (3920/4545)
Train Loss: 0.000 | Acc: 100.000 (4545/4545)
4
Train Loss: 0.553 | Acc: 78.834 (3583/4545)
Train Loss: 0.228 | Acc: 90.011 (4091/4545)
5
Train Loss: 1.426 | Acc: 65.765 (2989/4545)
Train Loss: 0.235 | Acc: 91.001 (4136/4545)
6
Train Loss: 0.300 | Acc: 90.165 (4098/4545)
Train Loss: 0.041 | Acc: 98.416 (4473/4545)
7
Train Loss: 0.718 | Acc: 81.210 (3691/4545)
Train Loss: 0.057 | Acc: 97.954 (4452/4545)
8
Train Loss: 0.668 | Acc: 83.784 (3808/4545)
Train Loss: 0.070 | Acc: 97.404 (4427/4545)
9
Train Loss: 1.391 | Acc: 72.189 (3281/4545)
Train Loss: 0.170 | Acc: 93.773 (4262/4545)
10
Train Loss: 0.514 | Acc: 83.674 (3803/4545)
Train Loss: 0.051 | Acc: 97.910 (4450/4545)
layer2.0
layer4.1
layer4.0
layer1.1
linear
1.conv1
layer3.1
layer3.0
layer1.0
layer2.1
1.bn1
Test Loss: 3.538 | Acc: 13.690 (1369/10000)
mseloss[1]:0.7541956305503845, 0.8164359927177429, 0.8774401545524597, 0.4295405447483063
mseloss[2]:0.835094153881073, 1.021789312362671, 1.596908688545227, 0.5358406901359558
mseloss[3]:0.7292365431785583, 0.7606863379478455, 0.8010246753692627, 0.38679414987564087
mseloss[4]:0.7714611291885376, 0.8652531504631042, 0.915280282497406, 0.45313891768455505
mseloss[5]:0.8027916550636292, 0.9656157493591309, 1.3430086374282837, 0.4864363968372345
mseloss[6]:0.7583997249603271, 0.9226771593093872, 1.3004242181777954, 0.4613025188446045
mseloss[7]:0.7557064890861511, 0.8058802485466003, 0.8782126903533936, 0.38920870423316956
mseloss[8]:0.8153945803642273, 0.987534761428833, 1.3522212505340576, 0.465779572725296
mseloss[9]:0.8767004013061523, 0.9996781349182129, 1.5633671283721924, 0.5242540240287781
Epoch:156
0
Train Loss: 0.439 | Acc: 84.774 (3853/4545)
Train Loss: 0.035 | Acc: 98.680 (4485/4545)
1
Train Loss: 0.424 | Acc: 86.227 (3919/4545)
Train Loss: 0.129 | Acc: 95.380 (4335/4545)
2
Train Loss: 0.478 | Acc: 84.906 (3859/4545)
Train Loss: 0.180 | Acc: 93.399 (4245/4545)
3
Train Loss: 0.275 | Acc: 91.485 (4158/4545)
Train Loss: 0.051 | Acc: 98.064 (4457/4545)
4
Train Loss: 0.390 | Acc: 85.325 (3878/4545)
Train Loss: 0.035 | Acc: 98.636 (4483/4545)
5
Train Loss: 0.539 | Acc: 85.149 (3870/4545)
Train Loss: 0.000 | Acc: 100.000 (4545/4545)
6
Train Loss: 0.362 | Acc: 87.965 (3998/4545)
Train Loss: 0.000 | Acc: 100.000 (4545/4545)
7
Train Loss: 0.670 | Acc: 79.670 (3621/4545)
Train Loss: 0.132 | Acc: 95.424 (4337/4545)
8
Train Loss: 0.459 | Acc: 84.180 (3826/4545)
Train Loss: 0.056 | Acc: 98.042 (4456/4545)
9
Train Loss: 0.401 | Acc: 86.997 (3954/4545)
Train Loss: 0.044 | Acc: 98.394 (4472/4545)
10
Train Loss: 0.425 | Acc: 83.234 (3783/4545)
Train Loss: 0.200 | Acc: 91.551 (4161/4545)
layer3.0
layer1.0
linear
layer1.1
layer2.0
layer3.1
layer4.0
layer2.1
1.bn1
layer4.1
1.conv1
Test Loss: 4.298 | Acc: 10.220 (1022/10000)
mseloss[1]:0.8260667324066162, 0.918688952922821, 1.5844124555587769, 0.24560092389583588
mseloss[2]:0.7755305171012878, 0.8569336533546448, 1.4307494163513184, 0.2747649848461151
mseloss[3]:0.7705153822898865, 0.8746746778488159, 1.3659158945083618, 0.2463594228029251
mseloss[4]:0.7627438902854919, 0.7422114014625549, 0.7451128363609314, 0.3443519175052643
mseloss[5]:0.7473880648612976, 0.7620745897293091, 0.9360237121582031, 0.2665086090564728
mseloss[6]:0.7240433096885681, 0.6872564554214478, 0.6771058440208435, 0.19476355612277985
mseloss[7]:0.8214712738990784, 0.9480786919593811, 1.6008988618850708, 0.26152893900871277
mseloss[8]:0.756917417049408, 0.7301321029663086, 0.7894946932792664, 0.26069632172584534
mseloss[9]:0.7608920931816101, 0.7583028674125671, 0.9734702706336975, 0.2759527564048767
Epoch:157
0
Train Loss: 1.247 | Acc: 71.485 (3249/4545)
Train Loss: 0.134 | Acc: 95.006 (4318/4545)
1
Train Loss: 0.312 | Acc: 89.285 (4058/4545)
Train Loss: 0.030 | Acc: 99.054 (4502/4545)
2
Train Loss: 0.591 | Acc: 84.334 (3833/4545)
Train Loss: 0.000 | Acc: 100.000 (4545/4545)
3
Train Loss: 0.473 | Acc: 82.596 (3754/4545)
Train Loss: 0.166 | Acc: 93.729 (4260/4545)
4
Train Loss: 0.441 | Acc: 83.938 (3815/4545)
Train Loss: 0.063 | Acc: 97.756 (4443/4545)
5
Train Loss: 0.457 | Acc: 84.400 (3836/4545)
Train Loss: 0.030 | Acc: 98.922 (4496/4545)
6
Train Loss: 0.759 | Acc: 79.274 (3603/4545)
Train Loss: 0.071 | Acc: 97.558 (4434/4545)
7
Train Loss: 0.481 | Acc: 84.818 (3855/4545)
Train Loss: 0.054 | Acc: 97.888 (4449/4545)
8
Train Loss: 0.490 | Acc: 82.332 (3742/4545)
Train Loss: 0.199 | Acc: 91.815 (4173/4545)
9
Train Loss: 0.338 | Acc: 89.747 (4079/4545)
Train Loss: 0.000 | Acc: 100.000 (4545/4545)
10
Train Loss: 1.530 | Acc: 71.265 (3239/4545)
Train Loss: 0.149 | Acc: 94.543 (4297/4545)
layer2.0
layer3.1
layer1.0
layer3.0
linear
layer4.0
layer1.1
layer4.1
1.conv1
1.bn1
layer2.1
Test Loss: 6.724 | Acc: 10.770 (1077/10000)
mseloss[1]:0.7952397465705872, 0.9191550016403198, 1.440779447555542, 0.2931458652019501
mseloss[2]:0.8317713737487793, 1.0600310564041138, 1.884464979171753, 0.21754319965839386
mseloss[3]:0.7758325338363647, 0.7176503539085388, 0.5303623080253601, 0.14371827244758606
mseloss[4]:0.7864891886711121, 0.9318614602088928, 1.4706815481185913, 0.39273810386657715
mseloss[5]:0.8188143372535706, 0.9427659511566162, 1.5782510042190552, 0.4520195424556732
mseloss[6]:0.7954612374305725, 0.7660899758338928, 0.8814929127693176, 0.14019830524921417
mseloss[7]:0.8069239854812622, 0.964553952217102, 1.5488736629486084, 0.3284122347831726
mseloss[8]:0.8027832508087158, 0.9012733697891235, 1.4640796184539795, 0.5299732089042664
mseloss[9]:0.7880032062530518, 0.9443604946136475, 1.6416831016540527, 0.2571936845779419
Epoch:158
0
Train Loss: 0.618 | Acc: 82.178 (3735/4545)
Train Loss: 0.059 | Acc: 97.888 (4449/4545)
1
Train Loss: 0.230 | Acc: 93.443 (4247/4545)
Train Loss: 0.055 | Acc: 98.086 (4458/4545)
2
Train Loss: 0.666 | Acc: 75.182 (3417/4545)
Train Loss: 0.205 | Acc: 91.177 (4144/4545)
3
Train Loss: 0.277 | Acc: 90.869 (4130/4545)
Train Loss: 0.050 | Acc: 98.350 (4470/4545)
4
Train Loss: 0.424 | Acc: 85.281 (3876/4545)
Train Loss: 0.000 | Acc: 100.000 (4545/4545)
5
Train Loss: 0.732 | Acc: 81.122 (3687/4545)
Train Loss: 0.032 | Acc: 98.856 (4493/4545)
6
Train Loss: 1.084 | Acc: 76.282 (3467/4545)
Train Loss: 0.138 | Acc: 95.204 (4327/4545)
7
Train Loss: 0.778 | Acc: 79.164 (3598/4545)
Train Loss: 0.068 | Acc: 97.514 (4432/4545)
8
Train Loss: 0.490 | Acc: 81.232 (3692/4545)
Train Loss: 0.156 | Acc: 93.487 (4249/4545)
9
Train Loss: 0.577 | Acc: 84.488 (3840/4545)
Train Loss: 0.001 | Acc: 100.000 (4545/4545)
10
Train Loss: 0.658 | Acc: 81.078 (3685/4545)
Train Loss: 0.129 | Acc: 95.292 (4331/4545)
layer4.0
layer3.1
1.conv1
1.bn1
layer2.0
layer1.0
linear
layer4.1
layer3.0
layer1.1
layer2.1
Test Loss: 2.826 | Acc: 23.960 (2396/10000)
mseloss[1]:0.7569870352745056, 0.8911922574043274, 0.9683825969696045, 0.327478289604187
mseloss[2]:0.7384827733039856, 0.8710423111915588, 0.9774720072746277, 0.304348886013031
mseloss[3]:0.7385269403457642, 0.9092928171157837, 1.0913013219833374, 0.33946704864501953
mseloss[4]:0.7379581332206726, 0.8826673626899719, 1.1541930437088013, 0.22107839584350586
mseloss[5]:0.735709547996521, 0.9419481754302979, 1.1019132137298584, 0.3258835971355438
mseloss[6]:0.7668986320495605, 0.7240789532661438, 0.7669960856437683, 0.1485675871372223
mseloss[7]:0.7529832124710083, 0.8850355744361877, 0.9231014847755432, 0.22633150219917297
mseloss[8]:0.7539964318275452, 0.7918698787689209, 0.7445677518844604, 0.23364336788654327
mseloss[9]:0.7851712703704834, 1.1002994775772095, 1.483933925628662, 0.2303331196308136
Epoch:159
0
Train Loss: 0.531 | Acc: 83.190 (3781/4545)
Train Loss: 0.119 | Acc: 95.468 (4339/4545)
1
Train Loss: 0.566 | Acc: 82.332 (3742/4545)
Train Loss: 0.055 | Acc: 97.778 (4444/4545)
2
Train Loss: 0.201 | Acc: 94.389 (4290/4545)
Train Loss: 0.056 | Acc: 98.064 (4457/4545)
3
Train Loss: 0.438 | Acc: 84.862 (3857/4545)
Train Loss: 0.057 | Acc: 98.108 (4459/4545)
4
Train Loss: 0.814 | Acc: 80.000 (3636/4545)
Train Loss: 0.045 | Acc: 98.394 (4472/4545)
5
Train Loss: 0.302 | Acc: 88.977 (4044/4545)
Train Loss: 0.107 | Acc: 96.304 (4377/4545)
6
Train Loss: 0.966 | Acc: 72.497 (3295/4545)
Train Loss: 0.211 | Acc: 91.067 (4139/4545)
7
Train Loss: 0.708 | Acc: 78.108 (3550/4545)
Train Loss: 0.160 | Acc: 93.795 (4263/4545)
8
Train Loss: 0.404 | Acc: 87.679 (3985/4545)
Train Loss: 0.037 | Acc: 98.878 (4494/4545)
9
Train Loss: 0.460 | Acc: 86.381 (3926/4545)
Train Loss: 0.000 | Acc: 100.000 (4545/4545)
10
Train Loss: 0.614 | Acc: 84.510 (3841/4545)
Train Loss: 0.000 | Acc: 100.000 (4545/4545)
layer3.1
layer4.1
layer2.1
layer4.0
layer1.1
linear
layer2.0
layer1.0
1.conv1
1.bn1
layer3.0
Test Loss: 3.660 | Acc: 11.890 (1189/10000)
mseloss[1]:0.7653544545173645, 0.8749614953994751, 0.8166264295578003, 0.2549670338630676
mseloss[2]:0.742289125919342, 0.6579843163490295, 0.5548238158226013, 0.21618616580963135
mseloss[3]:0.7803083062171936, 0.8137925267219543, 0.7476478219032288, 0.32882580161094666
mseloss[4]:0.7725238800048828, 0.8831784725189209, 0.9340617060661316, 0.5559606552124023
mseloss[5]:0.7637346982955933, 0.7145730257034302, 0.5382986068725586, 0.18559041619300842
mseloss[6]:0.7651619911193848, 0.8237355351448059, 0.6904417872428894, 0.4079549014568329
mseloss[7]:0.7676945924758911, 0.7436158657073975, 0.5834581255912781, 0.3327656388282776
mseloss[8]:0.7790555357933044, 0.8871892690658569, 0.8798853754997253, 0.41471806168556213
mseloss[9]:0.772825300693512, 0.8114157915115356, 0.7653726935386658, 0.4152829349040985
Epoch:160
0
Train Loss: 0.275 | Acc: 90.737 (4124/4545)
Train Loss: 0.000 | Acc: 100.000 (4545/4545)
1
Train Loss: 0.455 | Acc: 84.356 (3834/4545)
Train Loss: 0.114 | Acc: 95.534 (4342/4545)
2
Train Loss: 0.388 | Acc: 87.019 (3955/4545)
Train Loss: 0.050 | Acc: 98.240 (4465/4545)
3
Train Loss: 0.352 | Acc: 87.745 (3988/4545)
Train Loss: 0.102 | Acc: 96.722 (4396/4545)
4
Train Loss: 0.513 | Acc: 86.315 (3923/4545)
Train Loss: 0.000 | Acc: 100.000 (4545/4545)
5
Train Loss: 0.537 | Acc: 85.149 (3870/4545)
Train Loss: 0.051 | Acc: 98.548 (4479/4545)
6
Train Loss: 0.624 | Acc: 80.616 (3664/4545)
Train Loss: 0.172 | Acc: 93.003 (4227/4545)
7
Train Loss: 0.412 | Acc: 87.151 (3961/4545)
Train Loss: 0.028 | Acc: 98.856 (4493/4545)
8
Train Loss: 0.459 | Acc: 81.584 (3708/4545)
Train Loss: 0.173 | Acc: 93.003 (4227/4545)
9
Train Loss: 0.307 | Acc: 88.603 (4027/4545)
Train Loss: 0.057 | Acc: 97.822 (4446/4545)
10
Train Loss: 0.332 | Acc: 89.021 (4046/4545)
Train Loss: 0.052 | Acc: 98.152 (4461/4545)
linear
1.bn1
layer4.1
layer2.0
layer2.1
layer4.0
layer1.0
layer3.0
layer3.1
1.conv1
layer1.1
Test Loss: 5.028 | Acc: 10.010 (1001/10000)
mseloss[1]:0.7792847752571106, 0.801358699798584, 0.6025726199150085, 0.3805791735649109
mseloss[2]:0.7184616923332214, 0.7601898312568665, 0.6784363389015198, 0.4145936369895935
mseloss[3]:0.7652381658554077, 0.7520462274551392, 0.6804335117340088, 0.4118368923664093
mseloss[4]:0.7315036654472351, 0.8363412022590637, 0.7496732473373413, 0.42340123653411865
mseloss[5]:0.7190159559249878, 0.7610230445861816, 0.6057866215705872, 0.40229669213294983
mseloss[6]:0.7479281425476074, 0.7769573926925659, 0.6363921165466309, 0.3651089668273926
mseloss[7]:0.7140913009643555, 0.7513298392295837, 0.6213909387588501, 0.382341593503952
mseloss[8]:0.7322467565536499, 0.7549006342887878, 0.6225112676620483, 0.4234957695007324
mseloss[9]:0.7352142333984375, 0.752173662185669, 0.5769447684288025, 0.3665269613265991
Epoch:161
0
Train Loss: 0.918 | Acc: 74.279 (3376/4545)
Train Loss: 0.167 | Acc: 93.355 (4243/4545)
1
Train Loss: 1.074 | Acc: 74.125 (3369/4545)
Train Loss: 0.145 | Acc: 94.499 (4295/4545)
2
Train Loss: 0.721 | Acc: 83.300 (3786/4545)
Train Loss: 0.038 | Acc: 98.724 (4487/4545)
3
Train Loss: 0.617 | Acc: 85.325 (3878/4545)
Train Loss: 0.026 | Acc: 99.076 (4503/4545)
4
Train Loss: 1.261 | Acc: 71.463 (3248/4545)
Train Loss: 0.126 | Acc: 95.380 (4335/4545)
5
Train Loss: 0.731 | Acc: 83.432 (3792/4545)
Train Loss: 0.000 | Acc: 100.000 (4545/4545)
6
Train Loss: 1.115 | Acc: 74.917 (3405/4545)
Train Loss: 0.106 | Acc: 96.260 (4375/4545)
7
Train Loss: 0.335 | Acc: 89.417 (4064/4545)
Train Loss: 0.048 | Acc: 98.350 (4470/4545)
8
Train Loss: 0.942 | Acc: 78.702 (3577/4545)
Train Loss: 0.070 | Acc: 97.426 (4428/4545)
9
Train Loss: 0.118 | Acc: 94.895 (4313/4545)
Train Loss: 0.000 | Acc: 100.000 (4545/4545)
10
Train Loss: 0.875 | Acc: 80.198 (3645/4545)
Train Loss: 0.049 | Acc: 98.372 (4471/4545)
1.conv1
layer3.0
layer2.0
layer1.1
layer1.0
layer4.0
layer4.1
layer3.1
layer2.1
linear
1.bn1
Test Loss: 3.341 | Acc: 10.090 (1009/10000)
mseloss[1]:0.7619727253913879, 0.8381214737892151, 0.5478121638298035, 0.3649834990501404
mseloss[2]:0.7437475323677063, 0.7213386297225952, 0.44312894344329834, 0.35285842418670654
mseloss[3]:0.7655951976776123, 0.7955823540687561, 0.5848552584648132, 0.4020617604255676
mseloss[4]:0.7691670060157776, 0.8073883056640625, 0.5707337260246277, 0.4043772220611572
mseloss[5]:0.7607275247573853, 0.9171013236045837, 0.5735893249511719, 0.3963233530521393
mseloss[6]:0.7599956393241882, 0.8510959148406982, 0.772823691368103, 0.4941178560256958
mseloss[7]:0.7438938021659851, 0.7672548890113831, 0.525711178779602, 0.3700721263885498
mseloss[8]:0.76128751039505, 0.8821482062339783, 0.8059154748916626, 0.4524233937263489
mseloss[9]:0.7324376106262207, 0.7368326187133789, 0.5175819993019104, 0.4180980920791626
Epoch:162
0
Train Loss: 0.622 | Acc: 82.882 (3767/4545)
Train Loss: 0.050 | Acc: 98.306 (4468/4545)
1
Train Loss: 0.724 | Acc: 78.262 (3557/4545)
Train Loss: 0.108 | Acc: 96.040 (4365/4545)
2
Train Loss: 1.046 | Acc: 77.162 (3507/4545)
Train Loss: 0.072 | Acc: 97.514 (4432/4545)
3
Train Loss: 0.039 | Acc: 99.032 (4501/4545)
Train Loss: 0.000 | Acc: 100.000 (4545/4545)
4
Train Loss: 0.745 | Acc: 78.086 (3549/4545)
Train Loss: 0.108 | Acc: 95.952 (4361/4545)
5
Train Loss: 0.741 | Acc: 81.188 (3690/4545)
Train Loss: 0.024 | Acc: 99.142 (4506/4545)
6
Train Loss: 0.592 | Acc: 79.252 (3602/4545)
Train Loss: 0.134 | Acc: 94.741 (4306/4545)
7
Train Loss: 0.595 | Acc: 76.502 (3477/4545)
Train Loss: 0.180 | Acc: 92.717 (4214/4545)
8
Train Loss: 0.323 | Acc: 87.943 (3997/4545)
Train Loss: 0.001 | Acc: 100.000 (4545/4545)
9
Train Loss: 0.749 | Acc: 80.044 (3638/4545)
Train Loss: 0.024 | Acc: 99.120 (4505/4545)
10
Train Loss: 0.658 | Acc: 81.342 (3697/4545)
Train Loss: 0.074 | Acc: 97.316 (4423/4545)
1.bn1
1.conv1
layer2.0
layer3.1
layer1.1
linear
layer4.0
layer4.1
layer3.0
layer2.1
layer1.0
Test Loss: 3.583 | Acc: 13.110 (1311/10000)
mseloss[1]:0.7312374711036682, 0.6294003129005432, 0.34133559465408325, 0.14893637597560883
mseloss[2]:0.749683678150177, 1.0277442932128906, 0.8882800340652466, 0.2567932903766632
mseloss[3]:0.7416903972625732, 0.9254572987556458, 0.6615505814552307, 0.31879952549934387
mseloss[4]:0.7628387212753296, 0.9318404793739319, 0.615204930305481, 0.1885654181241989
mseloss[5]:0.7339059710502625, 0.9531415104866028, 0.684558093547821, 0.18626058101654053
mseloss[6]:0.7455610632896423, 0.8130035400390625, 0.48667213320732117, 0.1897282898426056
mseloss[7]:0.7343204021453857, 0.9269762635231018, 0.6545612812042236, 0.2388559728860855
mseloss[8]:0.749110758304596, 1.1717513799667358, 0.9643070101737976, 0.21688979864120483
mseloss[9]:0.7228203415870667, 0.9706484079360962, 0.7362569570541382, 0.25694775581359863
Epoch:163
0
Train Loss: 0.533 | Acc: 86.117 (3914/4545)
Train Loss: 0.000 | Acc: 100.000 (4545/4545)
1
Train Loss: 0.267 | Acc: 90.143 (4097/4545)
Train Loss: 0.094 | Acc: 96.546 (4388/4545)
2
Train Loss: 0.530 | Acc: 84.554 (3843/4545)
Train Loss: 0.033 | Acc: 98.922 (4496/4545)
3
Train Loss: 0.725 | Acc: 78.746 (3579/4545)
Train Loss: 0.106 | Acc: 95.996 (4363/4545)
4
Train Loss: 0.564 | Acc: 85.105 (3868/4545)
Train Loss: 0.081 | Acc: 97.228 (4419/4545)
5
Train Loss: 0.523 | Acc: 86.799 (3945/4545)
Train Loss: 0.000 | Acc: 100.000 (4545/4545)
6
Train Loss: 0.825 | Acc: 73.905 (3359/4545)
Train Loss: 0.204 | Acc: 91.331 (4151/4545)
7
Train Loss: 0.467 | Acc: 84.510 (3841/4545)
Train Loss: 0.054 | Acc: 97.910 (4450/4545)
8
Train Loss: 0.734 | Acc: 76.810 (3491/4545)
Train Loss: 0.127 | Acc: 95.116 (4323/4545)
9
Train Loss: 0.499 | Acc: 85.435 (3883/4545)
Train Loss: 0.033 | Acc: 98.746 (4488/4545)
10
Train Loss: 0.405 | Acc: 85.941 (3906/4545)
Train Loss: 0.045 | Acc: 98.328 (4469/4545)
layer1.0
linear
1.conv1
layer4.0
layer3.1
1.bn1
layer2.1
layer3.0
layer4.1
layer1.1
layer2.0
Test Loss: 4.330 | Acc: 16.100 (1610/10000)
mseloss[1]:0.7567474246025085, 1.124106526374817, 0.8559321165084839, 0.22789080440998077
mseloss[2]:0.7187188863754272, 1.0270507335662842, 0.8103434443473816, 0.20766383409500122
mseloss[3]:0.7603058815002441, 1.1280407905578613, 1.022530436515808, 0.22851517796516418
mseloss[4]:0.7234238982200623, 1.0947176218032837, 0.8139854669570923, 0.20870333909988403
mseloss[5]:0.7243629097938538, 0.9991713166236877, 0.9207278490066528, 0.3346188962459564
mseloss[6]:0.7436375617980957, 0.853050172328949, 0.5200413465499878, 0.2037642002105713
mseloss[7]:0.7010994553565979, 1.0479164123535156, 0.6744863390922546, 0.17324890196323395
mseloss[8]:0.7582329511642456, 1.1782556772232056, 0.8415365219116211, 0.2175738364458084
mseloss[9]:0.7470112442970276, 0.9931825995445251, 0.6908819079399109, 0.29893627762794495
Epoch:164
0
Train Loss: 1.092 | Acc: 76.810 (3491/4545)
Train Loss: 0.057 | Acc: 97.646 (4438/4545)
1
Train Loss: 0.324 | Acc: 91.331 (4151/4545)
Train Loss: 0.050 | Acc: 98.306 (4468/4545)
2
Train Loss: 0.413 | Acc: 84.048 (3820/4545)
Train Loss: 0.115 | Acc: 95.644 (4347/4545)
3
Train Loss: 0.304 | Acc: 89.879 (4085/4545)
Train Loss: 0.000 | Acc: 100.000 (4545/4545)
4
Train Loss: 0.188 | Acc: 93.641 (4256/4545)
Train Loss: 0.086 | Acc: 97.162 (4416/4545)
5
Train Loss: 0.752 | Acc: 77.646 (3529/4545)
Train Loss: 0.138 | Acc: 94.587 (4299/4545)
6
Train Loss: 1.035 | Acc: 77.228 (3510/4545)
Train Loss: 0.030 | Acc: 98.900 (4495/4545)
7
Train Loss: 0.819 | Acc: 75.732 (3442/4545)
Train Loss: 0.197 | Acc: 91.595 (4163/4545)
8
Train Loss: 0.591 | Acc: 83.080 (3776/4545)
Train Loss: 0.038 | Acc: 98.680 (4485/4545)
9
Train Loss: 0.921 | Acc: 80.572 (3662/4545)
Train Loss: 0.000 | Acc: 100.000 (4545/4545)
10
Train Loss: 1.028 | Acc: 75.204 (3418/4545)
Train Loss: 0.053 | Acc: 98.064 (4457/4545)
linear
1.bn1
layer3.1
layer4.0
layer3.0
1.conv1
layer4.1
layer1.0
layer1.1
layer2.1
layer2.0
Test Loss: 4.768 | Acc: 12.960 (1296/10000)
mseloss[1]:0.7042027115821838, 0.8408613801002502, 0.5778250098228455, 0.20285634696483612
mseloss[2]:0.7206431031227112, 0.8240571022033691, 0.6198607683181763, 0.22993668913841248
mseloss[3]:0.6673765778541565, 0.7063391208648682, 0.6758185625076294, 0.3448140025138855
mseloss[4]:0.7375361919403076, 0.8422499895095825, 0.7626705765724182, 0.24441111087799072
mseloss[5]:0.7255091071128845, 0.8496080040931702, 0.7956938743591309, 0.262924462556839
mseloss[6]:0.6906659603118896, 0.7365402579307556, 0.6811851263046265, 0.36389076709747314
mseloss[7]:0.7413131594657898, 0.7969740629196167, 0.5889551043510437, 0.2356855571269989
mseloss[8]:0.7038080096244812, 0.7544139623641968, 0.6887073516845703, 0.2697945237159729
mseloss[9]:0.6846505999565125, 0.879181981086731, 0.7320719361305237, 0.2138623744249344
Epoch:165
0
Train Loss: 0.560 | Acc: 81.914 (3723/4545)
Train Loss: 0.111 | Acc: 95.996 (4363/4545)
1
Train Loss: 0.611 | Acc: 82.882 (3767/4545)
Train Loss: 0.029 | Acc: 99.076 (4503/4545)
2
Train Loss: 0.420 | Acc: 87.547 (3979/4545)
Train Loss: 0.091 | Acc: 97.030 (4410/4545)
3
Train Loss: 0.178 | Acc: 93.641 (4256/4545)
Train Loss: 0.000 | Acc: 100.000 (4545/4545)
4
Train Loss: 0.593 | Acc: 82.618 (3755/4545)
Train Loss: 0.049 | Acc: 98.042 (4456/4545)
5
Train Loss: 0.511 | Acc: 83.806 (3809/4545)
Train Loss: 0.049 | Acc: 98.108 (4459/4545)
6
Train Loss: 0.684 | Acc: 77.646 (3529/4545)
Train Loss: 0.135 | Acc: 94.961 (4316/4545)
7
Train Loss: 0.584 | Acc: 77.756 (3534/4545)
Train Loss: 0.162 | Acc: 93.267 (4239/4545)
8
Train Loss: 0.497 | Acc: 84.862 (3857/4545)
Train Loss: 0.000 | Acc: 100.000 (4545/4545)
9
Train Loss: 0.691 | Acc: 80.682 (3667/4545)
Train Loss: 0.065 | Acc: 97.822 (4446/4545)
10
Train Loss: 0.596 | Acc: 84.642 (3847/4545)
Train Loss: 0.039 | Acc: 98.856 (4493/4545)
layer2.0
linear
layer2.1
1.conv1
layer4.1
layer3.0
layer4.0
layer3.1
1.bn1
layer1.1
layer1.0
Test Loss: 7.887 | Acc: 10.560 (1056/10000)
mseloss[1]:0.748691976070404, 0.94931560754776, 0.9987947940826416, 0.319692999124527
mseloss[2]:0.7337828278541565, 0.7217239141464233, 0.4890919625759125, 0.12222380936145782
mseloss[3]:0.7508023977279663, 1.0204929113388062, 1.212868094444275, 0.3070387840270996
mseloss[4]:0.7509835362434387, 0.9305132031440735, 0.8381479382514954, 0.2307836264371872
mseloss[5]:0.7277405858039856, 0.8991599678993225, 0.7417859435081482, 0.21443496644496918
mseloss[6]:0.7366343140602112, 0.816512942314148, 0.5535391569137573, 0.14813558757305145
mseloss[7]:0.7525904774665833, 0.8790216445922852, 0.7569165229797363, 0.20726025104522705
mseloss[8]:0.7600534558296204, 1.0770995616912842, 0.997555673122406, 0.1838991940021515
mseloss[9]:0.7204456925392151, 0.6506986618041992, 0.4093332290649414, 0.13426893949508667
Epoch:166
0
Train Loss: 0.218 | Acc: 93.333 (4242/4545)
Train Loss: 0.020 | Acc: 99.230 (4510/4545)
1
Train Loss: 1.063 | Acc: 77.382 (3517/4545)
Train Loss: 0.075 | Acc: 97.404 (4427/4545)
2
Train Loss: 0.839 | Acc: 78.152 (3552/4545)
Train Loss: 0.110 | Acc: 96.282 (4376/4545)
3
Train Loss: 1.157 | Acc: 77.250 (3511/4545)
Train Loss: 0.001 | Acc: 100.000 (4545/4545)
4
Train Loss: 0.415 | Acc: 83.850 (3811/4545)
Train Loss: 0.115 | Acc: 96.282 (4376/4545)
5
Train Loss: 0.468 | Acc: 85.831 (3901/4545)
Train Loss: 0.091 | Acc: 96.964 (4407/4545)
6
Train Loss: 0.901 | Acc: 79.846 (3629/4545)
Train Loss: 0.000 | Acc: 100.000 (4545/4545)
7
Train Loss: 0.469 | Acc: 81.320 (3696/4545)
Train Loss: 0.183 | Acc: 93.003 (4227/4545)
8
Train Loss: 0.781 | Acc: 79.164 (3598/4545)
Train Loss: 0.045 | Acc: 98.614 (4482/4545)
9
Train Loss: 0.880 | Acc: 77.690 (3531/4545)
Train Loss: 0.055 | Acc: 97.844 (4447/4545)
10
Train Loss: 0.780 | Acc: 80.330 (3651/4545)
Train Loss: 0.036 | Acc: 98.944 (4497/4545)
1.conv1
layer2.1
layer1.1
layer3.1
layer3.0
layer2.0
1.bn1
layer4.1
layer1.0
layer4.0
linear
Test Loss: 3.943 | Acc: 12.710 (1271/10000)
mseloss[1]:0.709008514881134, 0.9312026500701904, 0.9072377681732178, 0.2703576385974884
mseloss[2]:0.740092933177948, 0.9455108642578125, 1.0526632070541382, 0.27870944142341614
mseloss[3]:0.7567481398582458, 0.9840241074562073, 0.8355854749679565, 0.234610915184021
mseloss[4]:0.7179473638534546, 0.9025266170501709, 0.9499748945236206, 0.2658628523349762
mseloss[5]:0.7409598231315613, 0.8779739141464233, 0.8232094645500183, 0.275539755821228
mseloss[6]:0.685276448726654, 0.7669205069541931, 0.6735220551490784, 0.2786305248737335
mseloss[7]:0.7218206524848938, 0.7342342734336853, 0.5320298671722412, 0.24486713111400604
mseloss[8]:0.7153717875480652, 0.8542361855506897, 0.918220579624176, 0.3162999749183655
mseloss[9]:0.6976114511489868, 0.7771987915039062, 0.7065934538841248, 0.26767632365226746
Epoch:167
0
Train Loss: 0.310 | Acc: 91.881 (4176/4545)
Train Loss: 0.001 | Acc: 100.000 (4545/4545)
1
Train Loss: 0.522 | Acc: 83.432 (3792/4545)
Train Loss: 0.048 | Acc: 98.306 (4468/4545)
2
Train Loss: 0.513 | Acc: 85.149 (3870/4545)
Train Loss: 0.071 | Acc: 97.822 (4446/4545)
3
Train Loss: 0.312 | Acc: 90.649 (4120/4545)
Train Loss: 0.023 | Acc: 99.296 (4513/4545)
4
Train Loss: 0.559 | Acc: 80.880 (3676/4545)
Train Loss: 0.192 | Acc: 92.255 (4193/4545)
5
Train Loss: 0.323 | Acc: 88.207 (4009/4545)
Train Loss: 0.052 | Acc: 97.888 (4449/4545)
6
Train Loss: 0.814 | Acc: 77.338 (3515/4545)
Train Loss: 0.102 | Acc: 96.392 (4381/4545)
7
Train Loss: 0.647 | Acc: 81.430 (3701/4545)
Train Loss: 0.000 | Acc: 100.000 (4545/4545)
8
Train Loss: 0.862 | Acc: 77.536 (3524/4545)
Train Loss: 0.135 | Acc: 95.314 (4332/4545)
9
Train Loss: 0.309 | Acc: 89.373 (4062/4545)
Train Loss: 0.031 | Acc: 98.922 (4496/4545)
10
Train Loss: 0.712 | Acc: 76.810 (3491/4545)
Train Loss: 0.131 | Acc: 95.534 (4342/4545)
1.bn1
1.conv1
layer1.1
layer1.0
layer3.0
layer4.0
layer2.1
layer4.1
layer2.0
layer3.1
linear
Test Loss: 3.821 | Acc: 15.920 (1592/10000)
mseloss[1]:0.6707102656364441, 0.7544596195220947, 0.6110401749610901, 0.1726323515176773
mseloss[2]:0.6948654055595398, 1.0484693050384521, 1.1428688764572144, 0.14358317852020264
mseloss[3]:0.6959038376808167, 0.9027671813964844, 0.9251617789268494, 0.1755293756723404
mseloss[4]:0.6979674696922302, 0.7554022669792175, 0.5355743765830994, 0.12459979206323624
mseloss[5]:0.6571139097213745, 0.8618293404579163, 0.9399755001068115, 0.15744954347610474
mseloss[6]:0.7261278629302979, 1.0228545665740967, 1.097688913345337, 0.1432151198387146
mseloss[7]:0.6438338756561279, 0.6999618411064148, 0.4851503372192383, 0.15575243532657623
mseloss[8]:0.7314212322235107, 1.0424479246139526, 1.2496546506881714, 0.14938892424106598
mseloss[9]:0.6746415495872498, 0.8440473079681396, 0.6931239366531372, 0.17192061245441437
Epoch:168
0
Train Loss: 0.854 | Acc: 77.668 (3530/4545)
Train Loss: 0.114 | Acc: 95.776 (4353/4545)
1
Train Loss: 0.310 | Acc: 89.395 (4063/4545)
Train Loss: 0.043 | Acc: 98.394 (4472/4545)
2
Train Loss: 0.503 | Acc: 81.430 (3701/4545)
Train Loss: 0.163 | Acc: 93.817 (4264/4545)
3
Train Loss: 0.294 | Acc: 90.979 (4135/4545)
Train Loss: 0.023 | Acc: 99.274 (4512/4545)
4
Train Loss: 0.396 | Acc: 86.007 (3909/4545)
Train Loss: 0.134 | Acc: 95.050 (4320/4545)
5
Train Loss: 0.411 | Acc: 88.317 (4014/4545)
Train Loss: 0.000 | Acc: 100.000 (4545/4545)
6
Train Loss: 0.332 | Acc: 88.141 (4006/4545)
Train Loss: 0.037 | Acc: 98.680 (4485/4545)
7
Train Loss: 0.475 | Acc: 85.567 (3889/4545)
Train Loss: 0.034 | Acc: 98.812 (4491/4545)
8
Train Loss: 0.604 | Acc: 84.752 (3852/4545)
Train Loss: 0.095 | Acc: 96.480 (4385/4545)
9
Train Loss: 0.687 | Acc: 82.948 (3770/4545)
Train Loss: 0.058 | Acc: 97.998 (4454/4545)
10
Train Loss: 0.341 | Acc: 89.131 (4051/4545)
Train Loss: 0.000 | Acc: 100.000 (4545/4545)
layer2.1
layer4.1
1.bn1
1.conv1
layer1.0
layer4.0
layer3.0
layer1.1
layer3.1
layer2.0
linear
Test Loss: 5.309 | Acc: 10.050 (1005/10000)
mseloss[1]:0.7382192611694336, 0.8090955018997192, 0.9407544732093811, 0.2405644804239273
mseloss[2]:0.7201991081237793, 0.8814719915390015, 1.173082947731018, 0.26686757802963257
mseloss[3]:0.7185116410255432, 0.783674418926239, 0.9831988215446472, 0.2840578258037567
mseloss[4]:0.713330090045929, 0.66965651512146, 0.5784143209457397, 0.1808788925409317
mseloss[5]:0.7581624984741211, 1.0789318084716797, 1.1612612009048462, 0.23031528294086456
mseloss[6]:0.7354301810264587, 0.7834404110908508, 0.8938171863555908, 0.2503485083580017
mseloss[7]:0.7206265926361084, 0.7542109489440918, 0.6797186136245728, 0.2639886736869812
mseloss[8]:0.7114130854606628, 0.6555401086807251, 0.544454038143158, 0.13629865646362305
mseloss[9]:0.7001737356185913, 0.6727420091629028, 0.5802484750747681, 0.13822779059410095
Epoch:169
0
Train Loss: 0.021 | Acc: 100.000 (4545/4545)
Train Loss: 0.000 | Acc: 100.000 (4545/4545)
1
Train Loss: 0.590 | Acc: 84.224 (3828/4545)
Train Loss: 0.001 | Acc: 100.000 (4545/4545)
2
Train Loss: 0.633 | Acc: 76.062 (3457/4545)
Train Loss: 0.141 | Acc: 94.609 (4300/4545)
3
Train Loss: 0.386 | Acc: 86.249 (3920/4545)
Train Loss: 0.023 | Acc: 99.230 (4510/4545)
4
Train Loss: 0.765 | Acc: 80.506 (3659/4545)
Train Loss: 0.043 | Acc: 98.526 (4478/4545)
5
Train Loss: 0.968 | Acc: 75.776 (3444/4545)
Train Loss: 0.106 | Acc: 96.656 (4393/4545)
6
Train Loss: 0.463 | Acc: 84.752 (3852/4545)
Train Loss: 0.020 | Acc: 99.274 (4512/4545)
7
Train Loss: 0.620 | Acc: 76.436 (3474/4545)
Train Loss: 0.176 | Acc: 93.289 (4240/4545)
8
Train Loss: 0.541 | Acc: 82.838 (3765/4545)
Train Loss: 0.051 | Acc: 98.064 (4457/4545)
9
Train Loss: 0.477 | Acc: 84.070 (3821/4545)
Train Loss: 0.060 | Acc: 97.800 (4445/4545)
10
Train Loss: 0.852 | Acc: 75.380 (3426/4545)
Train Loss: 0.110 | Acc: 95.886 (4358/4545)
layer2.0
layer1.0
linear
1.conv1
layer2.1
layer4.1
layer3.1
1.bn1
layer3.0
layer1.1
layer4.0
Test Loss: 3.825 | Acc: 13.550 (1355/10000)
mseloss[1]:0.7100129127502441, 1.050628662109375, 1.0065127611160278, 0.2864169180393219
mseloss[2]:0.6808569431304932, 0.6678107380867004, 0.5588123202323914, 0.27817487716674805
mseloss[3]:0.6610973477363586, 0.6638912558555603, 0.6559270024299622, 0.3094719648361206
mseloss[4]:0.6828867197036743, 0.77632075548172, 0.6677238345146179, 0.284809947013855
mseloss[5]:0.7068326473236084, 0.7479840517044067, 0.7359597086906433, 0.2941983640193939
mseloss[6]:0.6543792486190796, 0.6658077836036682, 0.7363787889480591, 0.30496686697006226
mseloss[7]:0.6682966351509094, 0.6919914484024048, 0.6756662130355835, 0.29368504881858826
mseloss[8]:0.673898458480835, 0.7010363340377808, 0.7233322262763977, 0.29965150356292725
mseloss[9]:0.6392320990562439, 0.725314199924469, 0.7604967951774597, 0.29019221663475037
Epoch:170
0
Train Loss: 0.384 | Acc: 84.356 (3834/4545)
Train Loss: 0.144 | Acc: 94.499 (4295/4545)
1
Train Loss: 0.826 | Acc: 79.978 (3635/4545)
Train Loss: 0.041 | Acc: 98.592 (4481/4545)
2
Train Loss: 0.330 | Acc: 87.745 (3988/4545)
Train Loss: 0.091 | Acc: 96.832 (4401/4545)
3
Train Loss: 1.278 | Acc: 74.807 (3400/4545)
Train Loss: 0.000 | Acc: 100.000 (4545/4545)
4
Train Loss: 0.366 | Acc: 87.415 (3973/4545)
Train Loss: 0.103 | Acc: 96.370 (4380/4545)
5
Train Loss: 0.873 | Acc: 78.636 (3574/4545)
Train Loss: 0.066 | Acc: 97.338 (4424/4545)
6
Train Loss: 0.918 | Acc: 77.888 (3540/4545)
Train Loss: 0.037 | Acc: 98.812 (4491/4545)
7
Train Loss: 0.384 | Acc: 86.535 (3933/4545)
Train Loss: 0.039 | Acc: 98.504 (4477/4545)
8
Train Loss: 0.391 | Acc: 85.369 (3880/4545)
Train Loss: 0.055 | Acc: 98.262 (4466/4545)
9
Train Loss: 0.210 | Acc: 92.717 (4214/4545)
Train Loss: 0.000 | Acc: 100.000 (4545/4545)
10
Train Loss: 0.774 | Acc: 74.455 (3384/4545)
Train Loss: 0.207 | Acc: 91.023 (4137/4545)
layer1.1
layer4.0
layer3.0
layer1.0
layer2.1
linear
layer2.0
layer4.1
layer3.1
1.bn1
1.conv1
Test Loss: 4.987 | Acc: 18.860 (1886/10000)
mseloss[1]:0.7075080871582031, 0.7756491899490356, 0.7255815863609314, 0.2687356472015381
mseloss[2]:0.7105262279510498, 0.6841903924942017, 0.5062222480773926, 0.13371184468269348
mseloss[3]:0.7800954580307007, 1.190566062927246, 1.1092334985733032, 0.1929648518562317
mseloss[4]:0.706303060054779, 0.6406471729278564, 0.466702401638031, 0.138463094830513
mseloss[5]:0.7145252823829651, 0.8607257008552551, 0.9875049591064453, 0.24659886956214905
mseloss[6]:0.7067267894744873, 0.7894147038459778, 0.8765963912010193, 0.28031542897224426
mseloss[7]:0.7160733938217163, 0.7985197901725769, 0.8518653512001038, 0.2654951810836792
mseloss[8]:0.6862484216690063, 0.6936289072036743, 0.6254754662513733, 0.17628273367881775
mseloss[9]:0.7282101511955261, 0.8187593221664429, 0.9517121315002441, 0.4534277021884918
Epoch:171
0
Train Loss: 0.179 | Acc: 94.433 (4292/4545)
Train Loss: 0.029 | Acc: 99.010 (4500/4545)
1
Train Loss: 1.372 | Acc: 65.457 (2975/4545)
Train Loss: 0.173 | Acc: 93.531 (4251/4545)
2
Train Loss: 0.230 | Acc: 92.563 (4207/4545)
Train Loss: 0.000 | Acc: 100.000 (4545/4545)
3
Train Loss: 0.555 | Acc: 83.850 (3811/4545)
Train Loss: 0.076 | Acc: 97.096 (4413/4545)
4
Train Loss: 1.786 | Acc: 63.014 (2864/4545)
Train Loss: 0.156 | Acc: 94.103 (4277/4545)
5
Train Loss: 0.768 | Acc: 78.922 (3587/4545)
Train Loss: 0.068 | Acc: 97.690 (4440/4545)
6
Train Loss: 0.494 | Acc: 84.906 (3859/4545)
Train Loss: 0.023 | Acc: 99.296 (4513/4545)
7
Train Loss: 0.722 | Acc: 81.694 (3713/4545)
Train Loss: 0.001 | Acc: 100.000 (4545/4545)
8
Train Loss: 0.378 | Acc: 87.239 (3965/4545)
Train Loss: 0.040 | Acc: 98.482 (4476/4545)
9
Train Loss: 0.817 | Acc: 75.798 (3445/4545)
Train Loss: 0.125 | Acc: 95.336 (4333/4545)
10
Train Loss: 0.753 | Acc: 75.512 (3432/4545)
Train Loss: 0.172 | Acc: 93.399 (4245/4545)
layer3.0
layer2.1
layer2.0
1.conv1
layer3.1
layer4.1
layer1.0
linear
layer1.1
1.bn1
layer4.0
Test Loss: 2.875 | Acc: 18.600 (1860/10000)
mseloss[1]:0.7258889675140381, 0.8989713788032532, 0.8480249047279358, 0.2364363819360733
mseloss[2]:0.6944180130958557, 0.7091344594955444, 0.7506394982337952, 0.3436761200428009
mseloss[3]:0.7106812000274658, 0.8615937232971191, 1.1362638473510742, 0.2611982226371765
mseloss[4]:0.7359146475791931, 0.9134646058082581, 0.8883299231529236, 0.21296213567256927
mseloss[5]:0.6998158097267151, 0.8594872951507568, 0.9196268916130066, 0.22999681532382965
mseloss[6]:0.6929324865341187, 0.7642338871955872, 0.8651840090751648, 0.3187091648578644
mseloss[7]:0.7155051231384277, 0.9716905951499939, 0.7469477653503418, 0.16931448876857758
mseloss[8]:0.7102017998695374, 0.7973929047584534, 0.8955666422843933, 0.31278491020202637
mseloss[9]:0.7182326316833496, 0.7928489446640015, 0.9288062453269958, 0.22769281268119812
Epoch:172
0
Train Loss: 0.453 | Acc: 85.567 (3889/4545)
Train Loss: 0.031 | Acc: 98.856 (4493/4545)
1
Train Loss: 0.532 | Acc: 81.364 (3698/4545)
Train Loss: 0.154 | Acc: 94.081 (4276/4545)
2
Train Loss: 0.597 | Acc: 81.386 (3699/4545)
Train Loss: 0.035 | Acc: 98.680 (4485/4545)
3
Train Loss: 0.370 | Acc: 85.149 (3870/4545)
Train Loss: 0.162 | Acc: 93.597 (4254/4545)
4
Train Loss: 0.476 | Acc: 86.931 (3951/4545)
Train Loss: 0.000 | Acc: 100.000 (4545/4545)
5
Train Loss: 0.910 | Acc: 77.690 (3531/4545)
Train Loss: 0.076 | Acc: 97.250 (4420/4545)
6
Train Loss: 1.292 | Acc: 69.263 (3148/4545)
Train Loss: 0.112 | Acc: 95.820 (4355/4545)
7
Train Loss: 0.239 | Acc: 91.947 (4179/4545)
Train Loss: 0.000 | Acc: 100.000 (4545/4545)
8
Train Loss: 1.156 | Acc: 74.323 (3378/4545)
Train Loss: 0.122 | Acc: 95.842 (4356/4545)
9
Train Loss: 0.894 | Acc: 78.812 (3582/4545)
Train Loss: 0.071 | Acc: 97.118 (4414/4545)
10
Train Loss: 0.673 | Acc: 82.134 (3733/4545)
Train Loss: 0.024 | Acc: 99.098 (4504/4545)
layer1.0
layer2.0
layer3.0
layer4.0
linear
layer4.1
layer1.1
layer2.1
layer3.1
1.bn1
1.conv1
Test Loss: 9.599 | Acc: 10.000 (1000/10000)
mseloss[1]:0.6976590156555176, 0.7085189819335938, 0.7261936664581299, 0.23224836587905884
mseloss[2]:0.6791016459465027, 0.7555583715438843, 0.8390757441520691, 0.2432967871427536
mseloss[3]:0.6761766672134399, 0.6694576740264893, 0.6117328405380249, 0.24113018810749054
mseloss[4]:0.6823017001152039, 0.6772599220275879, 0.7078574299812317, 0.2931617796421051
mseloss[5]:0.697869062423706, 0.8002999424934387, 0.8170982003211975, 0.21324630081653595
mseloss[6]:0.7194351553916931, 0.8203077912330627, 0.73060542345047, 0.20553450286388397
mseloss[7]:0.6673641800880432, 0.7916115522384644, 0.8493669033050537, 0.2296822965145111
mseloss[8]:0.7114924788475037, 0.7804778814315796, 0.9332882165908813, 0.19786003232002258
mseloss[9]:0.6745346188545227, 0.6982720494270325, 0.5932399034500122, 0.2174452841281891
Epoch:173
0
Train Loss: 0.584 | Acc: 82.948 (3770/4545)
Train Loss: 0.048 | Acc: 98.416 (4473/4545)
1
Train Loss: 0.339 | Acc: 87.811 (3991/4545)
Train Loss: 0.017 | Acc: 99.384 (4517/4545)
2
Train Loss: 0.049 | Acc: 99.604 (4527/4545)
Train Loss: 0.000 | Acc: 100.000 (4545/4545)
3
Train Loss: 0.628 | Acc: 76.832 (3492/4545)
Train Loss: 0.177 | Acc: 93.355 (4243/4545)
4
Train Loss: 0.456 | Acc: 86.359 (3925/4545)
Train Loss: 0.000 | Acc: 100.000 (4545/4545)
5
Train Loss: 0.638 | Acc: 80.154 (3643/4545)
Train Loss: 0.054 | Acc: 98.240 (4465/4545)
6
Train Loss: 0.445 | Acc: 84.884 (3858/4545)
Train Loss: 0.116 | Acc: 95.710 (4350/4545)
7
Train Loss: 0.379 | Acc: 86.909 (3950/4545)
Train Loss: 0.031 | Acc: 98.900 (4495/4545)
8
Train Loss: 0.839 | Acc: 78.834 (3583/4545)
Train Loss: 0.044 | Acc: 98.504 (4477/4545)
9
Train Loss: 0.740 | Acc: 76.502 (3477/4545)
Train Loss: 0.117 | Acc: 95.446 (4338/4545)
10
Train Loss: 0.585 | Acc: 81.386 (3699/4545)
Train Loss: 0.120 | Acc: 95.534 (4342/4545)
layer1.1
layer2.1
layer2.0
1.bn1
layer3.1
linear
layer3.0
layer4.0
1.conv1
layer1.0
layer4.1
Test Loss: 5.224 | Acc: 10.610 (1061/10000)
mseloss[1]:0.6579562425613403, 0.7157067060470581, 0.7936295866966248, 0.29979753494262695
mseloss[2]:0.6510525345802307, 0.6577982902526855, 0.7171220779418945, 0.3399285078048706
mseloss[3]:0.6900296807289124, 0.7456366419792175, 0.7417426109313965, 0.18728967010974884
mseloss[4]:0.6959955096244812, 0.9036366939544678, 1.1642919778823853, 0.1825972944498062
mseloss[5]:0.692223310470581, 0.8217304348945618, 1.002435326576233, 0.1719941645860672
mseloss[6]:0.6923538446426392, 0.7327517867088318, 0.706141471862793, 0.20920628309249878
mseloss[7]:0.6720815896987915, 0.7272653579711914, 0.6682755947113037, 0.21928201615810394
mseloss[8]:0.6706269383430481, 0.7598331570625305, 0.9856982827186584, 0.24629078805446625
mseloss[9]:0.7042160034179688, 0.7787615656852722, 0.7743619680404663, 0.1750275194644928
Epoch:174
0
Train Loss: 0.303 | Acc: 91.837 (4174/4545)
Train Loss: 0.000 | Acc: 100.000 (4545/4545)
1
Train Loss: 1.329 | Acc: 72.871 (3312/4545)
Train Loss: 0.144 | Acc: 94.873 (4312/4545)
2
Train Loss: 1.702 | Acc: 66.887 (3040/4545)
Train Loss: 0.119 | Acc: 95.754 (4352/4545)
3
Train Loss: 0.135 | Acc: 95.710 (4350/4545)
Train Loss: 0.021 | Acc: 99.340 (4515/4545)
4
Train Loss: 0.433 | Acc: 84.928 (3860/4545)
Train Loss: 0.069 | Acc: 97.580 (4435/4545)
5
Train Loss: 1.755 | Acc: 63.366 (2880/4545)
Train Loss: 0.205 | Acc: 91.617 (4164/4545)
6
Train Loss: 1.380 | Acc: 73.333 (3333/4545)
Train Loss: 0.023 | Acc: 99.208 (4509/4545)
7
Train Loss: 1.082 | Acc: 73.377 (3335/4545)
Train Loss: 0.105 | Acc: 96.084 (4367/4545)
8
Train Loss: 1.254 | Acc: 74.301 (3377/4545)
Train Loss: 0.046 | Acc: 98.372 (4471/4545)
9
Train Loss: 0.503 | Acc: 83.718 (3805/4545)
Train Loss: 0.049 | Acc: 98.328 (4469/4545)
10
Train Loss: 0.320 | Acc: 90.187 (4099/4545)
Train Loss: 0.000 | Acc: 100.000 (4545/4545)
layer4.1
1.bn1
layer3.1
layer2.0
layer3.0
layer2.1
layer1.1
layer4.0
linear
1.conv1
layer1.0
Test Loss: 11.410 | Acc: 18.660 (1866/10000)
mseloss[1]:0.7692049741744995, 0.9847604632377625, 1.4094150066375732, 0.36637210845947266
mseloss[2]:0.7607858180999756, 0.8610871434211731, 0.886322021484375, 0.34422266483306885
mseloss[3]:0.7316874265670776, 0.7271885871887207, 0.7277957797050476, 0.30280277132987976
mseloss[4]:0.7845252156257629, 0.9350109696388245, 1.044905424118042, 0.34077730774879456
mseloss[5]:0.7457351684570312, 0.8397160768508911, 0.9223669171333313, 0.3819591999053955
mseloss[6]:0.7055073380470276, 0.7441403269767761, 0.8588971495628357, 0.3996465504169464
mseloss[7]:0.7287688255310059, 0.7486981749534607, 0.752853274345398, 0.38313230872154236
mseloss[8]:0.7070942521095276, 0.7334352731704712, 0.7392805814743042, 0.35126543045043945
mseloss[9]:0.6952772736549377, 0.7219610214233398, 0.7872467041015625, 0.3066902458667755
Epoch:175
0
Train Loss: 0.119 | Acc: 96.062 (4366/4545)
Train Loss: 0.023 | Acc: 99.340 (4515/4545)
1
Train Loss: 0.662 | Acc: 82.530 (3751/4545)
Train Loss: 0.047 | Acc: 98.108 (4459/4545)
2
Train Loss: 0.499 | Acc: 85.853 (3902/4545)
Train Loss: 0.029 | Acc: 98.878 (4494/4545)
3
Train Loss: 0.446 | Acc: 86.095 (3913/4545)
Train Loss: 0.000 | Acc: 100.000 (4545/4545)
4
Train Loss: 0.649 | Acc: 83.982 (3817/4545)
Train Loss: 0.000 | Acc: 100.000 (4545/4545)
5
Train Loss: 0.485 | Acc: 82.156 (3734/4545)
Train Loss: 0.102 | Acc: 96.568 (4389/4545)
6
Train Loss: 0.886 | Acc: 77.140 (3506/4545)
Train Loss: 0.137 | Acc: 95.182 (4326/4545)
7
Train Loss: 0.644 | Acc: 79.472 (3612/4545)
Train Loss: 0.189 | Acc: 92.321 (4196/4545)
8
Train Loss: 0.662 | Acc: 84.774 (3853/4545)
Train Loss: 0.100 | Acc: 96.106 (4368/4545)
9
Train Loss: 0.655 | Acc: 83.146 (3779/4545)
Train Loss: 0.015 | Acc: 99.560 (4525/4545)
10
Train Loss: 0.414 | Acc: 86.447 (3929/4545)
Train Loss: 0.056 | Acc: 98.152 (4461/4545)
layer4.1
1.conv1
layer1.0
layer4.0
layer1.1
linear
layer3.1
layer2.0
layer2.1
layer3.0
1.bn1
Test Loss: 5.106 | Acc: 14.980 (1498/10000)
mseloss[1]:0.6608410477638245, 0.7121450304985046, 0.9940401315689087, 0.23717525601387024
mseloss[2]:0.6715511679649353, 0.7551727890968323, 1.0332549810409546, 0.2580127716064453
mseloss[3]:0.6804861426353455, 0.7189815044403076, 0.9049839973449707, 0.3379300534725189
mseloss[4]:0.6673582792282104, 0.7605474591255188, 0.853705108165741, 0.19413331151008606
mseloss[5]:0.6850234866142273, 0.7466856241226196, 0.8958655595779419, 0.22944973409175873
mseloss[6]:0.6767432689666748, 0.7711405158042908, 1.1413533687591553, 0.21822808682918549
mseloss[7]:0.6769135594367981, 0.7042317986488342, 0.8322669267654419, 0.2153508961200714
mseloss[8]:0.6823447346687317, 0.7579350471496582, 0.8995847702026367, 0.20205964148044586
mseloss[9]:0.6532317996025085, 0.708088219165802, 0.9580956697463989, 0.26359623670578003
Epoch:176
0
Train Loss: 0.363 | Acc: 88.779 (4035/4545)
Train Loss: 0.058 | Acc: 97.910 (4450/4545)
1
Train Loss: 0.251 | Acc: 91.485 (4158/4545)
Train Loss: 0.034 | Acc: 98.812 (4491/4545)
2
Train Loss: 0.754 | Acc: 78.790 (3581/4545)
Train Loss: 0.131 | Acc: 95.666 (4348/4545)
3
Train Loss: 0.519 | Acc: 86.645 (3938/4545)
Train Loss: 0.020 | Acc: 99.208 (4509/4545)
4
Train Loss: 0.630 | Acc: 80.880 (3676/4545)
Train Loss: 0.096 | Acc: 96.370 (4380/4545)
5
Train Loss: 0.421 | Acc: 87.679 (3985/4545)
Train Loss: 0.020 | Acc: 99.274 (4512/4545)
6
Train Loss: 0.544 | Acc: 81.100 (3686/4545)
Train Loss: 0.154 | Acc: 93.883 (4267/4545)
7
Train Loss: 0.492 | Acc: 85.171 (3871/4545)
Train Loss: 0.041 | Acc: 98.658 (4484/4545)
8
Train Loss: 0.464 | Acc: 86.579 (3935/4545)
Train Loss: 0.000 | Acc: 100.000 (4545/4545)
9
Train Loss: 0.330 | Acc: 89.043 (4047/4545)
Train Loss: 0.118 | Acc: 95.930 (4360/4545)
10
Train Loss: 0.232 | Acc: 91.309 (4150/4545)
Train Loss: 0.000 | Acc: 100.000 (4545/4545)
layer2.0
layer2.1
layer1.0
layer3.1
linear
layer4.1
layer4.0
layer1.1
1.bn1
1.conv1
layer3.0
Test Loss: 2.944 | Acc: 14.810 (1481/10000)
mseloss[1]:0.6742293238639832, 0.8098559975624084, 1.1365259885787964, 0.23917855322360992
mseloss[2]:0.6577281355857849, 0.6483213901519775, 0.6798700094223022, 0.10852665454149246
mseloss[3]:0.6440949440002441, 0.7471448183059692, 1.1315791606903076, 0.20368921756744385
mseloss[4]:0.6482089161872864, 0.5994973182678223, 0.40588390827178955, 0.10597292333841324
mseloss[5]:0.6579270362854004, 0.7655926942825317, 0.9286836385726929, 0.21424558758735657
mseloss[6]:0.659220814704895, 0.7484714388847351, 0.9643869996070862, 0.1900051087141037
mseloss[7]:0.6620855331420898, 0.7762393951416016, 0.9170467853546143, 0.21357135474681854
mseloss[8]:0.6880277395248413, 0.8705667853355408, 1.408705711364746, 0.15848666429519653
mseloss[9]:0.6523335576057434, 0.7367886304855347, 0.7830462455749512, 0.17492686212062836
Epoch:177
0
Train Loss: 0.427 | Acc: 87.217 (3964/4545)
Train Loss: 0.096 | Acc: 96.788 (4399/4545)
1
Train Loss: 0.285 | Acc: 90.913 (4132/4545)
Train Loss: 0.086 | Acc: 97.096 (4413/4545)
2
Train Loss: 0.566 | Acc: 83.916 (3814/4545)
Train Loss: 0.024 | Acc: 99.296 (4513/4545)
3
Train Loss: 0.517 | Acc: 85.347 (3879/4545)
Train Loss: 0.045 | Acc: 98.416 (4473/4545)
4
Train Loss: 0.552 | Acc: 83.828 (3810/4545)
Train Loss: 0.049 | Acc: 98.328 (4469/4545)
5
Train Loss: 0.431 | Acc: 86.271 (3921/4545)
Train Loss: 0.016 | Acc: 99.428 (4519/4545)
6
Train Loss: 0.257 | Acc: 91.155 (4143/4545)
Train Loss: 0.000 | Acc: 100.000 (4545/4545)
7
Train Loss: 0.586 | Acc: 83.740 (3806/4545)
Train Loss: 0.046 | Acc: 98.350 (4470/4545)
8
Train Loss: 0.763 | Acc: 74.807 (3400/4545)
Train Loss: 0.169 | Acc: 93.289 (4240/4545)
9
Train Loss: 0.466 | Acc: 87.723 (3987/4545)
Train Loss: 0.000 | Acc: 100.000 (4545/4545)
10
Train Loss: 0.331 | Acc: 87.459 (3975/4545)
Train Loss: 0.117 | Acc: 95.512 (4341/4545)
layer2.0
layer2.1
layer1.0
layer3.1
layer1.1
layer3.0
1.bn1
layer4.1
layer4.0
linear
1.conv1
Test Loss: 3.361 | Acc: 10.000 (1000/10000)
mseloss[1]:0.6671388149261475, 0.6630569696426392, 0.5892858505249023, 0.1293572187423706
mseloss[2]:0.6758884191513062, 0.7578506469726562, 1.0925687551498413, 0.21123400330543518
mseloss[3]:0.6813493967056274, 0.7618301510810852, 1.1887096166610718, 0.27282968163490295
mseloss[4]:0.6950762271881104, 0.7873808741569519, 1.064808964729309, 0.2997386157512665
mseloss[5]:0.676825225353241, 0.7544559240341187, 1.2368708848953247, 0.23605482280254364
mseloss[6]:0.685019850730896, 0.7742312550544739, 1.182183861732483, 0.43183207511901855
mseloss[7]:0.6827682852745056, 0.7505717277526855, 0.689041018486023, 0.15669749677181244
mseloss[8]:0.6854215860366821, 0.8553162217140198, 1.2906025648117065, 0.202068030834198
mseloss[9]:0.7035886645317078, 0.9469470977783203, 1.3421630859375, 0.21925584971904755
Epoch:178
0
Train Loss: 0.035 | Acc: 99.934 (4542/4545)
Train Loss: 0.000 | Acc: 100.000 (4545/4545)
1
Train Loss: 0.634 | Acc: 82.354 (3743/4545)
Train Loss: 0.049 | Acc: 98.240 (4465/4545)
2
Train Loss: 0.559 | Acc: 83.784 (3808/4545)
Train Loss: 0.018 | Acc: 99.428 (4519/4545)
3
Train Loss: 0.460 | Acc: 83.740 (3806/4545)
Train Loss: 0.082 | Acc: 97.492 (4431/4545)
4
Train Loss: 0.615 | Acc: 84.202 (3827/4545)
Train Loss: 0.000 | Acc: 100.000 (4545/4545)
5
Train Loss: 0.723 | Acc: 81.650 (3711/4545)
Train Loss: 0.055 | Acc: 98.240 (4465/4545)
6
Train Loss: 0.566 | Acc: 79.890 (3631/4545)
Train Loss: 0.110 | Acc: 95.732 (4351/4545)
7
Train Loss: 0.809 | Acc: 79.450 (3611/4545)
Train Loss: 0.043 | Acc: 98.636 (4483/4545)
8
Train Loss: 0.558 | Acc: 79.406 (3609/4545)
Train Loss: 0.153 | Acc: 94.169 (4280/4545)
9
Train Loss: 0.432 | Acc: 83.322 (3787/4545)
Train Loss: 0.099 | Acc: 96.128 (4369/4545)
10
Train Loss: 0.432 | Acc: 87.063 (3957/4545)
Train Loss: 0.029 | Acc: 99.010 (4500/4545)
1.conv1
layer3.1
layer1.0
layer4.0
layer1.1
1.bn1
layer3.0
layer2.1
linear
layer4.1
layer2.0
Test Loss: 3.495 | Acc: 17.280 (1728/10000)
mseloss[1]:0.6687139868736267, 0.8441483974456787, 1.0756990909576416, 0.21806351840496063
mseloss[2]:0.6641307473182678, 0.6985553503036499, 0.737339437007904, 0.2257028967142105
mseloss[3]:0.6796716451644897, 0.7717831134796143, 1.1373165845870972, 0.2296171337366104
mseloss[4]:0.6275051832199097, 0.6803634762763977, 0.8342363834381104, 0.31732189655303955
mseloss[5]:0.6457485556602478, 0.7158908843994141, 0.820105791091919, 0.2939305901527405
mseloss[6]:0.6724321842193604, 0.7529104351997375, 0.9887425303459167, 0.24615135788917542
mseloss[7]:0.6502526998519897, 0.7082563042640686, 0.9236128926277161, 0.3395121693611145
mseloss[8]:0.6628172397613525, 0.687588632106781, 0.7059235572814941, 0.19966283440589905
mseloss[9]:0.6836815476417542, 0.7450919151306152, 0.8866022825241089, 0.24655966460704803
Epoch:179
0
Train Loss: 0.411 | Acc: 87.393 (3972/4545)
Train Loss: 0.028 | Acc: 99.120 (4505/4545)
1
Train Loss: 0.168 | Acc: 94.279 (4285/4545)
Train Loss: 0.071 | Acc: 97.646 (4438/4545)
2
Train Loss: 0.770 | Acc: 75.094 (3413/4545)
Train Loss: 0.195 | Acc: 92.079 (4185/4545)
3
Train Loss: 0.796 | Acc: 81.342 (3697/4545)
Train Loss: 0.042 | Acc: 98.702 (4486/4545)
4
Train Loss: 0.401 | Acc: 88.449 (4020/4545)
Train Loss: 0.000 | Acc: 100.000 (4545/4545)
5
Train Loss: 0.254 | Acc: 91.573 (4162/4545)
Train Loss: 0.021 | Acc: 99.362 (4516/4545)
6
Train Loss: 0.675 | Acc: 82.728 (3760/4545)
Train Loss: 0.048 | Acc: 98.196 (4463/4545)
7
Train Loss: 0.284 | Acc: 91.441 (4156/4545)
Train Loss: 0.000 | Acc: 100.000 (4545/4545)
8
Train Loss: 0.525 | Acc: 84.862 (3857/4545)
Train Loss: 0.121 | Acc: 95.226 (4328/4545)
9
Train Loss: 0.645 | Acc: 80.858 (3675/4545)
Train Loss: 0.106 | Acc: 96.062 (4366/4545)
10
Train Loss: 0.571 | Acc: 84.400 (3836/4545)
Train Loss: 0.056 | Acc: 97.976 (4453/4545)
linear
layer4.1
layer1.1
layer3.1
layer1.0
layer4.0
1.bn1
1.conv1
layer2.0
layer3.0
layer2.1
Test Loss: 6.446 | Acc: 10.790 (1079/10000)
mseloss[1]:0.6776378750801086, 0.7265958189964294, 0.9688805937767029, 0.25060221552848816
mseloss[2]:0.6627300381660461, 0.6738771796226501, 0.7166059613227844, 0.31651103496551514
mseloss[3]:0.6642285585403442, 0.744759202003479, 0.8999583125114441, 0.37204083800315857
mseloss[4]:0.647003173828125, 0.7344740629196167, 0.7686120867729187, 0.3867073655128479
mseloss[5]:0.6428084373474121, 0.6787627935409546, 0.6650235652923584, 0.34332340955734253
mseloss[6]:0.6510416865348816, 0.7789058089256287, 0.8125784993171692, 0.3445003926753998
mseloss[7]:0.6692250967025757, 0.7963026762008667, 0.9506062865257263, 0.3326036036014557
mseloss[8]:0.6426296830177307, 0.6800717711448669, 0.6513713598251343, 0.28968214988708496
mseloss[9]:0.6588962078094482, 0.6708469390869141, 0.6737322211265564, 0.26001977920532227
Epoch:180
0
Train Loss: 0.553 | Acc: 83.652 (3802/4545)
Train Loss: 0.096 | Acc: 96.502 (4386/4545)
1
Train Loss: 0.088 | Acc: 97.492 (4431/4545)
Train Loss: 0.021 | Acc: 99.274 (4512/4545)
2
Train Loss: 0.508 | Acc: 86.051 (3911/4545)
Train Loss: 0.038 | Acc: 98.746 (4488/4545)
3
Train Loss: 0.337 | Acc: 90.253 (4102/4545)
Train Loss: 0.000 | Acc: 100.000 (4545/4545)
4
Train Loss: 0.577 | Acc: 86.645 (3938/4545)
Train Loss: 0.032 | Acc: 98.768 (4489/4545)
5
Train Loss: 0.776 | Acc: 76.524 (3478/4545)
Train Loss: 0.188 | Acc: 92.365 (4198/4545)
6
Train Loss: 0.297 | Acc: 89.879 (4085/4545)
Train Loss: 0.000 | Acc: 100.000 (4545/4545)
7
Train Loss: 0.534 | Acc: 83.938 (3815/4545)
Train Loss: 0.057 | Acc: 97.734 (4442/4545)
8
Train Loss: 0.702 | Acc: 79.714 (3623/4545)
Train Loss: 0.098 | Acc: 96.106 (4368/4545)
9
Train Loss: 0.519 | Acc: 86.953 (3952/4545)
Train Loss: 0.072 | Acc: 97.580 (4435/4545)
10
Train Loss: 0.519 | Acc: 83.014 (3773/4545)
Train Loss: 0.082 | Acc: 96.722 (4396/4545)
layer4.1
layer1.1
linear
1.bn1
layer2.0
layer4.0
layer3.0
layer1.0
1.conv1
layer3.1
layer2.1
Test Loss: 3.112 | Acc: 16.520 (1652/10000)
mseloss[1]:0.67548006772995, 0.7225731015205383, 0.9724856019020081, 0.24608483910560608
mseloss[2]:0.6714360117912292, 0.7302781343460083, 1.1114248037338257, 0.37269309163093567
mseloss[3]:0.6936754584312439, 0.8067118525505066, 1.0921167135238647, 0.33194699883461
mseloss[4]:0.6575407385826111, 0.6686882376670837, 0.8348873257637024, 0.28755927085876465
mseloss[5]:0.6559988260269165, 0.6398460268974304, 0.7954578995704651, 0.2760252058506012
mseloss[6]:0.7021251916885376, 0.7705749273300171, 1.2452385425567627, 0.42549100518226624
mseloss[7]:0.6724960207939148, 0.7414246797561646, 0.8260675668716431, 0.2358090579509735
mseloss[8]:0.6629034280776978, 0.6431499123573303, 0.6499282717704773, 0.17295363545417786
mseloss[9]:0.6651260256767273, 0.6950465440750122, 0.8898781538009644, 0.17957615852355957
Epoch:181
0
Train Loss: 0.135 | Acc: 95.006 (4318/4545)
Train Loss: 0.033 | Acc: 98.812 (4491/4545)
1
Train Loss: 0.800 | Acc: 80.924 (3678/4545)
Train Loss: 0.092 | Acc: 96.942 (4406/4545)
2
Train Loss: 0.711 | Acc: 81.870 (3721/4545)
Train Loss: 0.051 | Acc: 98.064 (4457/4545)
3
Train Loss: 0.562 | Acc: 78.768 (3580/4545)
Train Loss: 0.175 | Acc: 92.673 (4212/4545)
4
Train Loss: 0.117 | Acc: 95.952 (4361/4545)
Train Loss: 0.013 | Acc: 99.582 (4526/4545)
5
Train Loss: 0.385 | Acc: 87.965 (3998/4545)
Train Loss: 0.000 | Acc: 100.000 (4545/4545)
6
Train Loss: 0.450 | Acc: 86.579 (3935/4545)
Train Loss: 0.025 | Acc: 99.120 (4505/4545)
7
Train Loss: 0.657 | Acc: 80.308 (3650/4545)
Train Loss: 0.104 | Acc: 95.754 (4352/4545)
8
Train Loss: 0.604 | Acc: 85.765 (3898/4545)
Train Loss: 0.000 | Acc: 100.000 (4545/4545)
9
Train Loss: 0.461 | Acc: 86.139 (3915/4545)
Train Loss: 0.060 | Acc: 97.932 (4451/4545)
10
Train Loss: 0.440 | Acc: 85.105 (3868/4545)
Train Loss: 0.087 | Acc: 96.876 (4403/4545)
layer4.1
layer2.0
layer4.0
layer3.1
layer1.0
1.conv1
layer2.1
1.bn1
layer3.0
layer1.1
linear
Test Loss: 8.484 | Acc: 10.680 (1068/10000)
mseloss[1]:0.666958212852478, 0.7713877558708191, 1.137937307357788, 0.4239192605018616
mseloss[2]:0.6247057318687439, 0.7119807600975037, 0.9435117840766907, 0.39648619294166565
mseloss[3]:0.6521384716033936, 0.7129442691802979, 0.940036952495575, 0.37549248337745667
mseloss[4]:0.6255531907081604, 0.6758718490600586, 0.6741164326667786, 0.36622732877731323
mseloss[5]:0.6251687407493591, 0.6641272306442261, 0.7280864119529724, 0.3741406798362732
mseloss[6]:0.6420950293540955, 0.7279382348060608, 0.8929829597473145, 0.4280643165111542
mseloss[7]:0.6727527976036072, 0.7417647242546082, 0.8268077373504639, 0.3700830936431885
mseloss[8]:0.6536011695861816, 0.7144299149513245, 0.6447163820266724, 0.34229153394699097
mseloss[9]:0.6517284512519836, 0.7688367962837219, 1.0276200771331787, 0.4087280333042145
Epoch:182
0
Train Loss: 0.323 | Acc: 88.537 (4024/4545)
Train Loss: 0.081 | Acc: 97.162 (4416/4545)
1
Train Loss: 0.617 | Acc: 86.623 (3937/4545)
Train Loss: 0.024 | Acc: 99.208 (4509/4545)
2
Train Loss: 0.970 | Acc: 72.233 (3283/4545)
Train Loss: 0.234 | Acc: 90.253 (4102/4545)
3
Train Loss: 1.027 | Acc: 77.646 (3529/4545)
Train Loss: 0.025 | Acc: 99.054 (4502/4545)
4
Train Loss: 0.300 | Acc: 90.275 (4103/4545)
Train Loss: 0.000 | Acc: 100.000 (4545/4545)
5
Train Loss: 0.721 | Acc: 84.730 (3851/4545)
Train Loss: 0.117 | Acc: 96.018 (4364/4545)
6
Train Loss: 0.499 | Acc: 86.425 (3928/4545)
Train Loss: 0.046 | Acc: 98.592 (4481/4545)
7
Train Loss: 0.974 | Acc: 78.834 (3583/4545)
Train Loss: 0.081 | Acc: 96.942 (4406/4545)
8
Train Loss: 0.685 | Acc: 83.564 (3798/4545)
Train Loss: 0.051 | Acc: 98.108 (4459/4545)
9
Train Loss: 0.376 | Acc: 86.689 (3940/4545)
Train Loss: 0.046 | Acc: 98.262 (4466/4545)
10
Train Loss: 0.199 | Acc: 92.761 (4216/4545)
Train Loss: 0.000 | Acc: 100.000 (4545/4545)
layer3.0
layer2.1
1.bn1
layer3.1
layer1.0
layer4.1
layer1.1
1.conv1
layer2.0
linear
layer4.0
Test Loss: 3.088 | Acc: 17.260 (1726/10000)
mseloss[1]:0.6249565482139587, 0.6642767786979675, 0.8241148591041565, 0.3563295304775238
mseloss[2]:0.6174549460411072, 0.6501404643058777, 0.6424427628517151, 0.2248886674642563
mseloss[3]:0.6100170016288757, 0.6660667061805725, 0.7408658266067505, 0.30694258213043213
mseloss[4]:0.6125972867012024, 0.6583271622657776, 0.8228342533111572, 0.3882329761981964
mseloss[5]:0.6248052716255188, 0.6665928363800049, 0.639000654220581, 0.2748636305332184
mseloss[6]:0.58603435754776, 0.6560879349708557, 0.6951621174812317, 0.3005988895893097
mseloss[7]:0.6146183013916016, 0.6751099824905396, 0.7057306170463562, 0.26376593112945557
mseloss[8]:0.608099102973938, 0.6979320645332336, 0.9035642743110657, 0.31345847249031067
mseloss[9]:0.6252375841140747, 0.6920372843742371, 0.8240578174591064, 0.4345838129520416
Epoch:183
0
Train Loss: 0.657 | Acc: 83.454 (3793/4545)
Train Loss: 0.020 | Acc: 99.318 (4514/4545)
1
Train Loss: 0.606 | Acc: 84.070 (3821/4545)
Train Loss: 0.049 | Acc: 97.998 (4454/4545)
2
Train Loss: 0.467 | Acc: 86.777 (3944/4545)
Train Loss: 0.000 | Acc: 100.000 (4545/4545)
3
Train Loss: 0.888 | Acc: 74.939 (3406/4545)
Train Loss: 0.207 | Acc: 91.463 (4157/4545)
4
Train Loss: 0.610 | Acc: 84.884 (3858/4545)
Train Loss: 0.059 | Acc: 97.690 (4440/4545)
5
Train Loss: 0.526 | Acc: 82.486 (3749/4545)
Train Loss: 0.123 | Acc: 95.138 (4324/4545)
6
Train Loss: 0.197 | Acc: 92.167 (4189/4545)
Train Loss: 0.000 | Acc: 100.000 (4545/4545)
7
Train Loss: 0.373 | Acc: 85.611 (3891/4545)
Train Loss: 0.084 | Acc: 96.810 (4400/4545)
8
Train Loss: 0.718 | Acc: 82.904 (3768/4545)
Train Loss: 0.031 | Acc: 98.900 (4495/4545)
9
Train Loss: 0.287 | Acc: 89.747 (4079/4545)
Train Loss: 0.037 | Acc: 98.724 (4487/4545)
10
Train Loss: 0.729 | Acc: 78.878 (3585/4545)
Train Loss: 0.092 | Acc: 96.744 (4397/4545)
1.conv1
layer3.1
layer4.0
layer2.0
layer1.0
layer1.1
1.bn1
linear
layer4.1
layer3.0
layer2.1
Test Loss: 4.988 | Acc: 18.510 (1851/10000)
mseloss[1]:0.5765466690063477, 0.6712584495544434, 0.635263979434967, 0.22159764170646667
mseloss[2]:0.5769377946853638, 0.6200008988380432, 0.6013342142105103, 0.28350183367729187
mseloss[3]:0.6080816388130188, 0.6405011415481567, 0.7069202065467834, 0.23507072031497955
mseloss[4]:0.6027064323425293, 0.6740309596061707, 0.6851263046264648, 0.24873633682727814
mseloss[5]:0.6192519068717957, 0.6740809679031372, 0.7161735892295837, 0.22371281683444977
mseloss[6]:0.5854242444038391, 0.6918424367904663, 0.7820615768432617, 0.24020685255527496
mseloss[7]:0.6160326600074768, 0.6533535122871399, 0.8084209561347961, 0.2666337490081787
mseloss[8]:0.6031357049942017, 0.6702662110328674, 0.9173284769058228, 0.2770334482192993
mseloss[9]:0.6196670532226562, 0.7346746921539307, 1.0113561153411865, 0.2937569320201874
Epoch:184
0
Train Loss: 1.091 | Acc: 79.538 (3615/4545)
Train Loss: 0.000 | Acc: 100.000 (4545/4545)
1
Train Loss: 0.175 | Acc: 93.971 (4271/4545)
Train Loss: 0.072 | Acc: 97.470 (4430/4545)
2
Train Loss: 0.492 | Acc: 83.058 (3775/4545)
Train Loss: 0.161 | Acc: 93.707 (4259/4545)
3
Train Loss: 0.909 | Acc: 79.692 (3622/4545)
Train Loss: 0.053 | Acc: 98.218 (4464/4545)
4
Train Loss: 0.773 | Acc: 80.418 (3655/4545)
Train Loss: 0.082 | Acc: 97.338 (4424/4545)
5
Train Loss: 0.715 | Acc: 82.530 (3751/4545)
Train Loss: 0.022 | Acc: 99.340 (4515/4545)
6
Train Loss: 0.510 | Acc: 83.674 (3803/4545)
Train Loss: 0.043 | Acc: 98.526 (4478/4545)
7
Train Loss: 0.662 | Acc: 84.158 (3825/4545)
Train Loss: 0.029 | Acc: 99.032 (4501/4545)
8
Train Loss: 0.467 | Acc: 86.865 (3948/4545)
Train Loss: 0.109 | Acc: 96.018 (4364/4545)
9
Train Loss: 0.649 | Acc: 83.300 (3786/4545)
Train Loss: 0.051 | Acc: 98.284 (4467/4545)
10
Train Loss: 0.185 | Acc: 92.013 (4182/4545)
Train Loss: 0.000 | Acc: 100.000 (4545/4545)
linear
layer2.0
layer3.0
layer2.1
layer3.1
layer4.1
1.bn1
layer1.0
layer4.0
1.conv1
layer1.1
Test Loss: 5.056 | Acc: 10.000 (1000/10000)
mseloss[1]:0.6394960880279541, 0.779094398021698, 0.8916845917701721, 0.2698838412761688
mseloss[2]:0.616349458694458, 0.7094720602035522, 0.6742941737174988, 0.19021330773830414
mseloss[3]:0.5808053612709045, 0.663593590259552, 0.4878372251987457, 0.12202484905719757
mseloss[4]:0.6373999118804932, 0.8372038006782532, 1.0732048749923706, 0.19642193615436554
mseloss[5]:0.6043787002563477, 0.7430534362792969, 0.8643150925636292, 0.21643298864364624
mseloss[6]:0.594516932964325, 0.6509416103363037, 0.4680502712726593, 0.237309530377388
mseloss[7]:0.6337828636169434, 0.8488256335258484, 1.098801612854004, 0.3091708719730377
mseloss[8]:0.6325880885124207, 0.7759236693382263, 0.8791395425796509, 0.19323386251926422
mseloss[9]:0.6317482590675354, 0.790213942527771, 0.8958017826080322, 0.20518410205841064
Epoch:185
0
Train Loss: 0.864 | Acc: 77.228 (3510/4545)
Train Loss: 0.045 | Acc: 98.570 (4480/4545)
1
Train Loss: 1.226 | Acc: 67.943 (3088/4545)
Train Loss: 0.178 | Acc: 92.849 (4220/4545)
2
Train Loss: 0.679 | Acc: 79.956 (3634/4545)
Train Loss: 0.082 | Acc: 96.854 (4402/4545)
3
Train Loss: 0.836 | Acc: 80.352 (3652/4545)
Train Loss: 0.030 | Acc: 99.076 (4503/4545)
4
Train Loss: 0.497 | Acc: 82.266 (3739/4545)
Train Loss: 0.090 | Acc: 96.810 (4400/4545)
5
Train Loss: 0.565 | Acc: 83.212 (3782/4545)
Train Loss: 0.048 | Acc: 98.504 (4477/4545)
6
Train Loss: 0.117 | Acc: 94.763 (4307/4545)
Train Loss: 0.000 | Acc: 100.000 (4545/4545)
7
Train Loss: 0.799 | Acc: 79.912 (3632/4545)
Train Loss: 0.028 | Acc: 98.966 (4498/4545)
8
Train Loss: 0.621 | Acc: 78.878 (3585/4545)
Train Loss: 0.074 | Acc: 97.448 (4429/4545)
9
Train Loss: 0.812 | Acc: 82.156 (3734/4545)
Train Loss: 0.000 | Acc: 100.000 (4545/4545)
10
Train Loss: 1.000 | Acc: 75.776 (3444/4545)
Train Loss: 0.047 | Acc: 98.196 (4463/4545)
layer3.0
layer2.0
layer2.1
layer1.1
layer4.1
layer1.0
layer4.0
1.conv1
1.bn1
layer3.1
linear
Test Loss: 7.214 | Acc: 10.070 (1007/10000)
mseloss[1]:0.6020730137825012, 0.6551438570022583, 0.5636337995529175, 0.32190218567848206
mseloss[2]:0.6130475401878357, 0.7201937437057495, 0.8960564136505127, 0.3839767277240753
mseloss[3]:0.6002835631370544, 0.7322718501091003, 1.0384840965270996, 0.4958358108997345
mseloss[4]:0.6076316237449646, 0.6543346643447876, 0.6054990291595459, 0.3113940358161926
mseloss[5]:0.6113871932029724, 0.7065697312355042, 0.7524059414863586, 0.3218036890029907
mseloss[6]:0.638431966304779, 0.7471144199371338, 0.9403836727142334, 0.38465234637260437
mseloss[7]:0.6120094656944275, 0.704152524471283, 0.8431270122528076, 0.34205859899520874
mseloss[8]:0.604038655757904, 0.6455521583557129, 0.724942147731781, 0.33033931255340576
mseloss[9]:0.5761325359344482, 0.585369884967804, 0.5010776519775391, 0.2647080719470978
Epoch:186
0
Train Loss: 0.834 | Acc: 79.604 (3618/4545)
Train Loss: 0.048 | Acc: 98.482 (4476/4545)
1
Train Loss: 0.877 | Acc: 75.556 (3434/4545)
Train Loss: 0.096 | Acc: 96.744 (4397/4545)
2
Train Loss: 0.943 | Acc: 76.370 (3471/4545)
Train Loss: 0.098 | Acc: 96.458 (4384/4545)
3
Train Loss: 0.804 | Acc: 76.480 (3476/4545)
Train Loss: 0.119 | Acc: 95.248 (4329/4545)
4
Train Loss: 0.895 | Acc: 74.499 (3386/4545)
Train Loss: 0.139 | Acc: 94.763 (4307/4545)
5
Train Loss: 0.850 | Acc: 79.956 (3634/4545)
Train Loss: 0.033 | Acc: 98.790 (4490/4545)
6
Train Loss: 0.662 | Acc: 84.290 (3831/4545)
Train Loss: 0.029 | Acc: 99.010 (4500/4545)
7
Train Loss: 0.476 | Acc: 84.532 (3842/4545)
Train Loss: 0.031 | Acc: 98.922 (4496/4545)
8
Train Loss: 0.159 | Acc: 94.939 (4315/4545)
Train Loss: 0.046 | Acc: 98.416 (4473/4545)
9
Train Loss: 0.248 | Acc: 89.945 (4088/4545)
Train Loss: 0.000 | Acc: 100.000 (4545/4545)
10
Train Loss: 0.565 | Acc: 85.479 (3885/4545)
Train Loss: 0.000 | Acc: 100.000 (4545/4545)
layer3.1
linear
layer1.0
layer3.0
1.bn1
layer2.1
1.conv1
layer1.1
layer4.0
layer2.0
layer4.1
Test Loss: 2.697 | Acc: 15.680 (1568/10000)
mseloss[1]:0.6195755004882812, 0.7212079763412476, 1.3523683547973633, 0.17961087822914124
mseloss[2]:0.6118351817131042, 0.7039604783058167, 1.171525001525879, 0.20866122841835022
mseloss[3]:0.6037535667419434, 0.6639155745506287, 0.8588310480117798, 0.16879135370254517
mseloss[4]:0.6018582582473755, 0.6439996361732483, 0.8677114844322205, 0.19210855662822723
mseloss[5]:0.5961694717407227, 0.681182324886322, 1.1481074094772339, 0.24494004249572754
mseloss[6]:0.6084825992584229, 0.6547685265541077, 0.57192063331604, 0.1721508651971817
mseloss[7]:0.603947639465332, 0.66085284948349, 0.8388256430625916, 0.3101530075073242
mseloss[8]:0.5993762612342834, 0.6075398325920105, 0.5429401993751526, 0.12935906648635864
mseloss[9]:0.6116189360618591, 0.6494179368019104, 0.8104589581489563, 0.2939929664134979
Epoch:187
0
Train Loss: 0.520 | Acc: 85.171 (3871/4545)
Train Loss: 0.045 | Acc: 98.416 (4473/4545)
1
Train Loss: 0.798 | Acc: 76.722 (3487/4545)
Train Loss: 0.144 | Acc: 94.257 (4284/4545)
2
Train Loss: 0.276 | Acc: 90.099 (4095/4545)
Train Loss: 0.000 | Acc: 100.000 (4545/4545)
3
Train Loss: 0.504 | Acc: 84.114 (3823/4545)
Train Loss: 0.095 | Acc: 96.480 (4385/4545)
4
Train Loss: 0.091 | Acc: 97.998 (4454/4545)
Train Loss: 0.000 | Acc: 100.000 (4545/4545)
5
Train Loss: 0.730 | Acc: 82.882 (3767/4545)
Train Loss: 0.022 | Acc: 99.252 (4511/4545)
6
Train Loss: 0.457 | Acc: 83.608 (3800/4545)
Train Loss: 0.106 | Acc: 96.084 (4367/4545)
7
Train Loss: 0.415 | Acc: 86.601 (3936/4545)
Train Loss: 0.087 | Acc: 96.942 (4406/4545)
8
Train Loss: 0.625 | Acc: 84.510 (3841/4545)
Train Loss: 0.024 | Acc: 99.230 (4510/4545)
9
Train Loss: 0.325 | Acc: 87.679 (3985/4545)
Train Loss: 0.041 | Acc: 98.746 (4488/4545)
10
Train Loss: 0.751 | Acc: 82.222 (3737/4545)
Train Loss: 0.059 | Acc: 98.020 (4455/4545)
layer3.0
layer3.1
layer2.1
linear
layer4.1
1.bn1
layer2.0
layer4.0
layer1.0
1.conv1
layer1.1
Test Loss: 2.824 | Acc: 19.440 (1944/10000)
mseloss[1]:0.5982011556625366, 0.6656394004821777, 1.0315276384353638, 0.27296775579452515
mseloss[2]:0.6192097067832947, 0.6817636489868164, 0.925255537033081, 0.3268756866455078
mseloss[3]:0.5997516512870789, 0.6484337449073792, 0.9227506518363953, 0.3978980779647827
mseloss[4]:0.6005373597145081, 0.6916982531547546, 1.0912669897079468, 0.2485012412071228
mseloss[5]:0.5832768082618713, 0.6606225967407227, 0.9051775336265564, 0.39521506428718567
mseloss[6]:0.5899659395217896, 0.6667664647102356, 1.034490704536438, 0.18617011606693268
mseloss[7]:0.6106051206588745, 0.6740778088569641, 1.092922568321228, 0.20720264315605164
mseloss[8]:0.6025078296661377, 0.7002143263816833, 1.027506709098816, 0.30228447914123535
mseloss[9]:0.6183006763458252, 0.6992872357368469, 1.0326863527297974, 0.33850377798080444
Epoch:188
0
Train Loss: 0.352 | Acc: 87.789 (3990/4545)
Train Loss: 0.033 | Acc: 99.054 (4502/4545)
1
Train Loss: 0.686 | Acc: 85.083 (3867/4545)
Train Loss: 0.032 | Acc: 98.988 (4499/4545)
2
Train Loss: 0.366 | Acc: 89.483 (4067/4545)
Train Loss: 0.096 | Acc: 96.370 (4380/4545)
3
Train Loss: 0.581 | Acc: 85.479 (3885/4545)
Train Loss: 0.036 | Acc: 98.988 (4499/4545)
4
Train Loss: 0.245 | Acc: 90.979 (4135/4545)
Train Loss: 0.068 | Acc: 97.536 (4433/4545)
5
Train Loss: 0.672 | Acc: 80.352 (3652/4545)
Train Loss: 0.152 | Acc: 93.817 (4264/4545)
6
Train Loss: 0.535 | Acc: 86.315 (3923/4545)
Train Loss: 0.049 | Acc: 98.262 (4466/4545)
7
Train Loss: 0.381 | Acc: 88.515 (4023/4545)
Train Loss: 0.000 | Acc: 100.000 (4545/4545)
8
Train Loss: 0.264 | Acc: 91.045 (4138/4545)
Train Loss: 0.000 | Acc: 100.000 (4545/4545)
9
Train Loss: 0.535 | Acc: 84.202 (3827/4545)
Train Loss: 0.094 | Acc: 96.590 (4390/4545)
10
Train Loss: 0.624 | Acc: 82.596 (3754/4545)
Train Loss: 0.055 | Acc: 98.020 (4455/4545)
layer4.1
layer1.1
1.bn1
layer2.1
linear
layer4.0
layer3.0
layer3.1
1.conv1
layer1.0
layer2.0
Test Loss: 4.072 | Acc: 18.670 (1867/10000)
mseloss[1]:0.5979773998260498, 0.6832016110420227, 0.9689379334449768, 0.4394901990890503
mseloss[2]:0.6054232120513916, 0.6564631462097168, 0.6177213191986084, 0.2308817356824875
mseloss[3]:0.6024868488311768, 0.6786919236183167, 0.7914258241653442, 0.324238121509552
mseloss[4]:0.599656343460083, 0.6480413675308228, 0.6881316900253296, 0.3068223297595978
mseloss[5]:0.6066393256187439, 0.6321668028831482, 0.5450699925422668, 0.2410678267478943
mseloss[6]:0.6098451614379883, 0.732642650604248, 1.2434520721435547, 0.35068419575691223
mseloss[7]:0.5766923427581787, 0.6541439294815063, 0.5930566787719727, 0.1937110275030136
mseloss[8]:0.58091801404953, 0.6206640601158142, 0.4997183680534363, 0.28863629698753357
mseloss[9]:0.6148081421852112, 0.6960880160331726, 1.2203882932662964, 0.33789482712745667
Epoch:189
0
Train Loss: 0.462 | Acc: 85.941 (3906/4545)
Train Loss: 0.139 | Acc: 94.631 (4301/4545)
1
Train Loss: 0.857 | Acc: 80.484 (3658/4545)
Train Loss: 0.052 | Acc: 98.196 (4463/4545)
2
Train Loss: 0.317 | Acc: 88.317 (4014/4545)
Train Loss: 0.035 | Acc: 98.878 (4494/4545)
3
Train Loss: 0.614 | Acc: 82.596 (3754/4545)
Train Loss: 0.098 | Acc: 96.568 (4389/4545)
4
Train Loss: 0.436 | Acc: 88.405 (4018/4545)
Train Loss: 0.020 | Acc: 99.296 (4513/4545)
5
Train Loss: 0.365 | Acc: 85.127 (3869/4545)
Train Loss: 0.081 | Acc: 97.206 (4418/4545)
6
Train Loss: 0.400 | Acc: 88.383 (4017/4545)
Train Loss: 0.000 | Acc: 100.000 (4545/4545)
7
Train Loss: 0.906 | Acc: 81.430 (3701/4545)
Train Loss: 0.024 | Acc: 99.274 (4512/4545)
8
Train Loss: 0.748 | Acc: 83.476 (3794/4545)
Train Loss: 0.064 | Acc: 98.086 (4458/4545)
9
Train Loss: 0.678 | Acc: 81.760 (3716/4545)
Train Loss: 0.095 | Acc: 96.920 (4405/4545)
10
Train Loss: 0.443 | Acc: 87.415 (3973/4545)
Train Loss: 0.000 | Acc: 100.000 (4545/4545)
1.conv1
layer4.1
layer2.0
layer2.1
linear
layer1.0
1.bn1
layer3.1
layer4.0
layer1.1
layer3.0
Test Loss: 2.691 | Acc: 15.050 (1505/10000)
mseloss[1]:0.5871589183807373, 0.6473127007484436, 0.73794025182724, 0.31980398297309875
mseloss[2]:0.5949335098266602, 0.6585315465927124, 0.6614441871643066, 0.26372864842414856
mseloss[3]:0.612481951713562, 0.6405143141746521, 0.6737943291664124, 0.2401382029056549
mseloss[4]:0.6014238595962524, 0.6235218644142151, 0.734256386756897, 0.45110684633255005
mseloss[5]:0.6050096750259399, 0.5983021855354309, 0.7326422929763794, 0.37407398223876953
mseloss[6]:0.5892221331596375, 0.6674819588661194, 0.787832498550415, 0.34511706233024597
mseloss[7]:0.6111782789230347, 0.6867882609367371, 0.9361330270767212, 0.3523375391960144
mseloss[8]:0.5823965668678284, 0.7022563815116882, 0.8284454345703125, 0.29110783338546753
mseloss[9]:0.5958777070045471, 0.6520092487335205, 1.0723881721496582, 0.3180866837501526
Epoch:190
0
Train Loss: 0.528 | Acc: 85.985 (3908/4545)
Train Loss: 0.000 | Acc: 100.000 (4545/4545)
1
Train Loss: 0.759 | Acc: 77.140 (3506/4545)
Train Loss: 0.076 | Acc: 97.338 (4424/4545)
2
Train Loss: 0.974 | Acc: 70.649 (3211/4545)
Train Loss: 0.105 | Acc: 95.776 (4353/4545)
3
Train Loss: 0.867 | Acc: 72.013 (3273/4545)
Train Loss: 0.184 | Acc: 92.805 (4218/4545)
4
Train Loss: 0.145 | Acc: 95.270 (4330/4545)
Train Loss: 0.000 | Acc: 100.000 (4545/4545)
5
Train Loss: 0.302 | Acc: 89.351 (4061/4545)
Train Loss: 0.023 | Acc: 99.098 (4504/4545)
6
Train Loss: 0.457 | Acc: 84.796 (3854/4545)
Train Loss: 0.042 | Acc: 98.834 (4492/4545)
7
Train Loss: 0.684 | Acc: 82.882 (3767/4545)
Train Loss: 0.023 | Acc: 99.274 (4512/4545)
8
Train Loss: 0.564 | Acc: 82.464 (3748/4545)
Train Loss: 0.095 | Acc: 96.656 (4393/4545)
9
Train Loss: 0.534 | Acc: 83.278 (3785/4545)
Train Loss: 0.050 | Acc: 98.240 (4465/4545)
10
Train Loss: 0.421 | Acc: 87.283 (3967/4545)
Train Loss: 0.044 | Acc: 98.614 (4482/4545)
layer2.0
layer1.0
1.bn1
layer3.0
linear
layer1.1
layer4.1
layer4.0
1.conv1
layer3.1
layer2.1
Test Loss: 4.937 | Acc: 10.000 (1000/10000)
mseloss[1]:0.6077319979667664, 0.6151180267333984, 0.5974035263061523, 0.2427542805671692
mseloss[2]:0.5967134237289429, 0.6722750067710876, 1.0164073705673218, 0.3443675637245178
mseloss[3]:0.5861437320709229, 0.6950554251670837, 1.1390167474746704, 0.2840586006641388
mseloss[4]:0.5641191005706787, 0.5973672866821289, 0.5332053303718567, 0.20204350352287292
mseloss[5]:0.6035574078559875, 0.6889085173606873, 1.06010901927948, 0.3245285451412201
mseloss[6]:0.5760669708251953, 0.58730149269104, 0.41148775815963745, 0.18457506597042084
mseloss[7]:0.5831303000450134, 0.6711559295654297, 0.8653178215026855, 0.31592121720314026
mseloss[8]:0.6027395129203796, 0.6658391356468201, 1.0368478298187256, 0.28143227100372314
mseloss[9]:0.567908763885498, 0.5991719365119934, 0.43370211124420166, 0.25147056579589844
Epoch:191
0
Train Loss: 0.468 | Acc: 85.347 (3879/4545)
Train Loss: 0.026 | Acc: 99.318 (4514/4545)
1
Train Loss: 0.365 | Acc: 88.999 (4045/4545)
Train Loss: 0.040 | Acc: 98.526 (4478/4545)
2
Train Loss: 0.803 | Acc: 76.766 (3489/4545)
Train Loss: 0.023 | Acc: 99.164 (4507/4545)
3
Train Loss: 0.560 | Acc: 81.738 (3715/4545)
Train Loss: 0.039 | Acc: 98.724 (4487/4545)
4
Train Loss: 0.648 | Acc: 79.868 (3630/4545)
Train Loss: 0.091 | Acc: 96.854 (4402/4545)
5
Train Loss: 0.921 | Acc: 70.055 (3184/4545)
Train Loss: 0.176 | Acc: 93.069 (4230/4545)
6
Train Loss: 0.538 | Acc: 83.454 (3793/4545)
Train Loss: 0.062 | Acc: 97.910 (4450/4545)
7
Train Loss: 0.658 | Acc: 77.976 (3544/4545)
Train Loss: 0.109 | Acc: 95.974 (4362/4545)
8
Train Loss: 0.519 | Acc: 85.083 (3867/4545)
Train Loss: 0.000 | Acc: 100.000 (4545/4545)
9
Train Loss: 0.131 | Acc: 96.392 (4381/4545)
Train Loss: 0.000 | Acc: 100.000 (4545/4545)
10
Train Loss: 0.798 | Acc: 74.675 (3394/4545)
Train Loss: 0.084 | Acc: 96.876 (4403/4545)
layer1.1
linear
layer1.0
layer3.0
1.conv1
layer4.0
layer2.1
1.bn1
layer3.1
layer4.1
layer2.0
Test Loss: 5.555 | Acc: 16.400 (1640/10000)
mseloss[1]:0.5771622657775879, 0.6153606176376343, 0.4659302532672882, 0.12610624730587006
mseloss[2]:0.596458375453949, 0.6806159019470215, 1.0275862216949463, 0.22351200878620148
mseloss[3]:0.5943931341171265, 0.6640605330467224, 0.7456677556037903, 0.19776426255702972
mseloss[4]:0.5998626947402954, 0.6803081631660461, 0.9859971404075623, 0.13997313380241394
mseloss[5]:0.5980504155158997, 0.6828052401542664, 0.9188123345375061, 0.2616886496543884
mseloss[6]:0.5888567566871643, 0.7542428970336914, 1.1716548204421997, 0.23290379345417023
mseloss[7]:0.5860886573791504, 0.6487984657287598, 0.9137890338897705, 0.3005288541316986
mseloss[8]:0.5770301818847656, 0.6200826168060303, 0.5961143970489502, 0.1702440232038498
mseloss[9]:0.5817508101463318, 0.6980150938034058, 0.9721648097038269, 0.1785922348499298
Epoch:192
0
Train Loss: 0.252 | Acc: 91.551 (4161/4545)
Train Loss: 0.020 | Acc: 99.318 (4514/4545)
1
Train Loss: 0.924 | Acc: 78.372 (3562/4545)
Train Loss: 0.051 | Acc: 98.174 (4462/4545)
2
Train Loss: 0.280 | Acc: 91.705 (4168/4545)
Train Loss: 0.047 | Acc: 98.592 (4481/4545)
3
Train Loss: 0.755 | Acc: 80.110 (3641/4545)
Train Loss: 0.104 | Acc: 96.392 (4381/4545)
4
Train Loss: 0.292 | Acc: 90.495 (4113/4545)
Train Loss: 0.027 | Acc: 99.120 (4505/4545)
5
Train Loss: 0.659 | Acc: 78.570 (3571/4545)
Train Loss: 0.118 | Acc: 95.380 (4335/4545)
6
Train Loss: 0.924 | Acc: 74.741 (3397/4545)
Train Loss: 0.099 | Acc: 96.414 (4382/4545)
7
Train Loss: 0.422 | Acc: 86.161 (3916/4545)
Train Loss: 0.049 | Acc: 98.460 (4475/4545)
8
Train Loss: 0.364 | Acc: 89.549 (4070/4545)
Train Loss: 0.000 | Acc: 100.000 (4545/4545)
9
Train Loss: 0.076 | Acc: 98.592 (4481/4545)
Train Loss: 0.000 | Acc: 100.000 (4545/4545)
10
Train Loss: 0.624 | Acc: 76.876 (3494/4545)
Train Loss: 0.162 | Acc: 93.267 (4239/4545)
layer3.0
layer2.1
layer1.1
linear
layer4.0
layer3.1
layer2.0
layer1.0
layer4.1
1.conv1
1.bn1
Test Loss: 2.382 | Acc: 21.840 (2184/10000)
mseloss[1]:0.5507671236991882, 0.6034371256828308, 0.6374751329421997, 0.2328660488128662
mseloss[2]:0.5764787197113037, 0.6612958312034607, 0.8673608899116516, 0.2535547614097595
mseloss[3]:0.5776691436767578, 0.6651739478111267, 0.9535790681838989, 0.25803762674331665
mseloss[4]:0.5665602684020996, 0.5825443863868713, 0.6658931970596313, 0.26728489995002747
mseloss[5]:0.5665944218635559, 0.5574201941490173, 0.46517565846443176, 0.19709157943725586
mseloss[6]:0.6066426634788513, 0.6121299862861633, 0.8238359689712524, 0.2776046693325043
mseloss[7]:0.5774753093719482, 0.5899311900138855, 0.5782371163368225, 0.28966963291168213
mseloss[8]:0.5457172393798828, 0.553595781326294, 0.5884177088737488, 0.23487155139446259
mseloss[9]:0.5707523226737976, 0.5697561502456665, 0.5310506820678711, 0.23244470357894897
Epoch:193
0
Train Loss: 0.151 | Acc: 94.609 (4300/4545)
Train Loss: 0.000 | Acc: 100.000 (4545/4545)
1
Train Loss: 0.101 | Acc: 96.348 (4379/4545)
Train Loss: 0.000 | Acc: 100.000 (4545/4545)
2
Train Loss: 0.504 | Acc: 85.765 (3898/4545)
Train Loss: 0.073 | Acc: 97.206 (4418/4545)
3
Train Loss: 0.498 | Acc: 87.283 (3967/4545)
Train Loss: 0.056 | Acc: 97.998 (4454/4545)
4
Train Loss: 0.278 | Acc: 89.241 (4056/4545)
Train Loss: 0.032 | Acc: 98.812 (4491/4545)
5
Train Loss: 0.287 | Acc: 91.485 (4158/4545)
Train Loss: 0.027 | Acc: 98.988 (4499/4545)
6
Train Loss: 0.504 | Acc: 80.924 (3678/4545)
Train Loss: 0.145 | Acc: 94.323 (4287/4545)
7
Train Loss: 0.242 | Acc: 91.617 (4164/4545)
Train Loss: 0.012 | Acc: 99.516 (4523/4545)
8
Train Loss: 0.557 | Acc: 82.508 (3750/4545)
Train Loss: 0.100 | Acc: 96.568 (4389/4545)
9
Train Loss: 0.920 | Acc: 81.562 (3707/4545)
Train Loss: 0.054 | Acc: 98.240 (4465/4545)
10
Train Loss: 0.532 | Acc: 82.002 (3727/4545)
Train Loss: 0.115 | Acc: 95.402 (4336/4545)
layer1.1
layer4.1
layer4.0
layer2.1
layer3.0
1.bn1
layer1.0
layer2.0
layer3.1
1.conv1
linear
Test Loss: 4.102 | Acc: 16.810 (1681/10000)
mseloss[1]:0.5343895554542542, 0.5170670747756958, 0.4521385729312897, 0.21085789799690247
mseloss[2]:0.597228467464447, 0.5597937703132629, 0.6706615686416626, 0.2544287145137787
mseloss[3]:0.573749840259552, 0.6055299043655396, 0.8993525505065918, 0.26567432284355164
mseloss[4]:0.555986762046814, 0.552194356918335, 0.46613451838493347, 0.19629117846488953
mseloss[5]:0.5563969612121582, 0.5947500467300415, 0.9089112281799316, 0.2664099335670471
mseloss[6]:0.5701931118965149, 0.5537469983100891, 0.6617199182510376, 0.2675071656703949
mseloss[7]:0.5486100316047668, 0.5454608798027039, 0.6255521178245544, 0.2727144658565521
mseloss[8]:0.5818362832069397, 0.6162037253379822, 1.0348743200302124, 0.2584749758243561
mseloss[9]:0.5531194806098938, 0.5410991907119751, 0.5455530285835266, 0.27511560916900635
Epoch:194
0
Train Loss: 0.535 | Acc: 88.339 (4015/4545)
Train Loss: 0.000 | Acc: 100.000 (4545/4545)
1
Train Loss: 0.579 | Acc: 85.215 (3873/4545)
Train Loss: 0.025 | Acc: 99.120 (4505/4545)
2
Train Loss: 0.602 | Acc: 79.846 (3629/4545)
Train Loss: 0.148 | Acc: 93.949 (4270/4545)
3
Train Loss: 0.391 | Acc: 87.063 (3957/4545)
Train Loss: 0.098 | Acc: 96.458 (4384/4545)
4
Train Loss: 0.272 | Acc: 89.835 (4083/4545)
Train Loss: 0.089 | Acc: 96.766 (4398/4545)
5
Train Loss: 0.895 | Acc: 79.208 (3600/4545)
Train Loss: 0.039 | Acc: 98.570 (4480/4545)
6
Train Loss: 0.597 | Acc: 84.884 (3858/4545)
Train Loss: 0.021 | Acc: 99.230 (4510/4545)
7
Train Loss: 0.945 | Acc: 79.560 (3616/4545)
Train Loss: 0.027 | Acc: 99.142 (4506/4545)
8
Train Loss: 0.587 | Acc: 84.114 (3823/4545)
Train Loss: 0.052 | Acc: 98.306 (4468/4545)
9
Train Loss: 0.421 | Acc: 87.987 (3999/4545)
Train Loss: 0.000 | Acc: 100.000 (4545/4545)
10
Train Loss: 0.259 | Acc: 90.517 (4114/4545)
Train Loss: 0.078 | Acc: 96.854 (4402/4545)
layer1.1
1.conv1
layer3.0
layer3.1
layer4.0
layer1.0
layer4.1
1.bn1
layer2.1
linear
layer2.0
Test Loss: 21.447 | Acc: 10.000 (1000/10000)
mseloss[1]:0.5683173537254333, 0.549976646900177, 0.46960458159446716, 0.23690365254878998
mseloss[2]:0.5960336327552795, 0.5933135151863098, 0.6657662987709045, 0.28103843331336975
mseloss[3]:0.615566611289978, 0.6518681645393372, 0.8516536355018616, 0.2230350226163864
mseloss[4]:0.6019686460494995, 0.6181893944740295, 0.6633148193359375, 0.3324457108974457
mseloss[5]:0.5612905621528625, 0.5874111652374268, 0.7027270197868347, 0.24796538054943085
mseloss[6]:0.5912895798683167, 0.614425539970398, 0.6408537030220032, 0.3403913974761963
mseloss[7]:0.5949676632881165, 0.6237466931343079, 0.8359115719795227, 0.266195148229599
mseloss[8]:0.6054604649543762, 0.660361647605896, 0.8608325719833374, 0.2371336668729782
mseloss[9]:0.5533568859100342, 0.5544935464859009, 0.5533573627471924, 0.19890986382961273
Epoch:195
0
Train Loss: 1.058 | Acc: 75.820 (3446/4545)
Train Loss: 0.101 | Acc: 96.458 (4384/4545)
1
Train Loss: 0.888 | Acc: 76.084 (3458/4545)
Train Loss: 0.142 | Acc: 94.323 (4287/4545)
2
Train Loss: 1.034 | Acc: 77.030 (3501/4545)
Train Loss: 0.042 | Acc: 98.614 (4482/4545)
3
Train Loss: 0.703 | Acc: 83.432 (3792/4545)
Train Loss: 0.030 | Acc: 99.230 (4510/4545)
4
Train Loss: 0.420 | Acc: 82.464 (3748/4545)
Train Loss: 0.114 | Acc: 95.358 (4334/4545)
5
Train Loss: 0.176 | Acc: 93.179 (4235/4545)
Train Loss: 0.000 | Acc: 100.000 (4545/4545)
6
Train Loss: 1.289 | Acc: 73.509 (3341/4545)
Train Loss: 0.042 | Acc: 98.504 (4477/4545)
7
Train Loss: 1.285 | Acc: 74.631 (3392/4545)
Train Loss: 0.031 | Acc: 98.856 (4493/4545)
8
Train Loss: 0.430 | Acc: 85.127 (3869/4545)
Train Loss: 0.043 | Acc: 98.570 (4480/4545)
9
Train Loss: 1.149 | Acc: 77.404 (3518/4545)
Train Loss: 0.000 | Acc: 100.000 (4545/4545)
10
Train Loss: 0.983 | Acc: 76.282 (3467/4545)
Train Loss: 0.058 | Acc: 98.042 (4456/4545)
layer2.1
layer4.1
layer3.1
1.conv1
layer4.0
layer3.0
layer2.0
linear
1.bn1
layer1.0
layer1.1
Test Loss: 4.991 | Acc: 17.510 (1751/10000)
mseloss[1]:0.5909222960472107, 0.6127453446388245, 0.8527733683586121, 0.1894604116678238
mseloss[2]:0.5744624137878418, 0.609882652759552, 0.7347877621650696, 0.15240442752838135
mseloss[3]:0.5814527273178101, 0.6125321984291077, 0.8639930486679077, 0.2853626608848572
mseloss[4]:0.5823737382888794, 0.5980062484741211, 0.8535332679748535, 0.33171704411506653
mseloss[5]:0.6084094643592834, 0.7307526469230652, 0.9154679179191589, 0.17146988213062286
mseloss[6]:0.5862112641334534, 0.6392562985420227, 0.8701305985450745, 0.19128835201263428
mseloss[7]:0.5888212323188782, 0.6376892924308777, 0.9471750259399414, 0.14449645578861237
mseloss[8]:0.5771573781967163, 0.5832167267799377, 0.6364741921424866, 0.1307453215122223
mseloss[9]:0.605766236782074, 0.7620338201522827, 1.030265212059021, 0.18937961757183075
Epoch:196
0
Train Loss: 0.132 | Acc: 96.282 (4376/4545)
Train Loss: 0.024 | Acc: 99.252 (4511/4545)
1
Train Loss: 0.470 | Acc: 85.853 (3902/4545)
Train Loss: 0.000 | Acc: 100.000 (4545/4545)
2
Train Loss: 0.615 | Acc: 78.504 (3568/4545)
Train Loss: 0.145 | Acc: 94.279 (4285/4545)
3
Train Loss: 0.523 | Acc: 82.640 (3756/4545)
Train Loss: 0.092 | Acc: 96.612 (4391/4545)
4
Train Loss: 0.400 | Acc: 86.029 (3910/4545)
Train Loss: 0.027 | Acc: 99.010 (4500/4545)
5
Train Loss: 0.538 | Acc: 83.432 (3792/4545)
Train Loss: 0.040 | Acc: 98.614 (4482/4545)
6
Train Loss: 0.463 | Acc: 86.975 (3953/4545)
Train Loss: 0.000 | Acc: 100.000 (4545/4545)
7
Train Loss: 0.416 | Acc: 87.239 (3965/4545)
Train Loss: 0.053 | Acc: 98.196 (4463/4545)
8
Train Loss: 0.537 | Acc: 79.604 (3618/4545)
Train Loss: 0.140 | Acc: 94.829 (4310/4545)
9
Train Loss: 0.610 | Acc: 81.958 (3725/4545)
Train Loss: 0.119 | Acc: 95.710 (4350/4545)
10
Train Loss: 0.383 | Acc: 87.437 (3974/4545)
Train Loss: 0.024 | Acc: 99.230 (4510/4545)
layer2.0
layer4.1
layer3.1
1.bn1
layer3.0
1.conv1
layer1.0
linear
layer2.1
layer4.0
layer1.1
Test Loss: 4.424 | Acc: 9.960 (996/10000)
mseloss[1]:0.55925053358078, 0.7345239520072937, 0.8371153473854065, 0.2560289800167084
mseloss[2]:0.5579670667648315, 0.5666180849075317, 0.6341047883033752, 0.18796458840370178
mseloss[3]:0.5766980648040771, 0.596503734588623, 0.6989321112632751, 0.1863134354352951
mseloss[4]:0.5362939834594727, 0.5842648148536682, 0.6026418805122375, 0.17253679037094116
mseloss[5]:0.5492508411407471, 0.5803094506263733, 0.8759627342224121, 0.27057841420173645
mseloss[6]:0.5448070764541626, 0.6939354538917542, 0.8736023902893066, 0.26339125633239746
mseloss[7]:0.5605379939079285, 0.6552102565765381, 0.7841387391090393, 0.17580440640449524
mseloss[8]:0.5590399503707886, 0.559822678565979, 0.6483687162399292, 0.236160546541214
mseloss[9]:0.5694993138313293, 0.6379178762435913, 1.1024309396743774, 0.19066573679447174
Epoch:197
0
Train Loss: 0.966 | Acc: 73.839 (3356/4545)
Train Loss: 0.158 | Acc: 94.015 (4273/4545)
1
Train Loss: 0.125 | Acc: 94.279 (4285/4545)
Train Loss: 0.000 | Acc: 100.000 (4545/4545)
2
Train Loss: 0.394 | Acc: 87.195 (3963/4545)
Train Loss: 0.027 | Acc: 99.076 (4503/4545)
3
Train Loss: 0.569 | Acc: 82.464 (3748/4545)
Train Loss: 0.121 | Acc: 95.292 (4331/4545)
4
Train Loss: 0.523 | Acc: 84.686 (3849/4545)
Train Loss: 0.035 | Acc: 98.834 (4492/4545)
5
Train Loss: 0.553 | Acc: 85.303 (3877/4545)
Train Loss: 0.000 | Acc: 100.000 (4545/4545)
6
Train Loss: 0.172 | Acc: 94.059 (4275/4545)
Train Loss: 0.041 | Acc: 98.438 (4474/4545)
7
Train Loss: 0.759 | Acc: 78.570 (3571/4545)
Train Loss: 0.140 | Acc: 94.741 (4306/4545)
8
Train Loss: 1.007 | Acc: 78.966 (3589/4545)
Train Loss: 0.041 | Acc: 98.460 (4475/4545)
9
Train Loss: 0.698 | Acc: 83.542 (3797/4545)
Train Loss: 0.038 | Acc: 99.076 (4503/4545)
10
Train Loss: 0.890 | Acc: 77.492 (3522/4545)
Train Loss: 0.136 | Acc: 94.851 (4311/4545)
linear
layer2.0
layer4.0
layer1.1
layer4.1
1.bn1
layer2.1
1.conv1
layer3.1
layer1.0
layer3.0
Test Loss: 5.595 | Acc: 10.540 (1054/10000)
mseloss[1]:0.5651165246963501, 0.5719225406646729, 0.698530912399292, 0.29950347542762756
mseloss[2]:0.5674885511398315, 0.5524455308914185, 0.6814388632774353, 0.2509816288948059
mseloss[3]:0.6018308401107788, 0.6405524611473083, 0.8850576281547546, 0.2495601624250412
mseloss[4]:0.5793289542198181, 0.5728762149810791, 0.7398847341537476, 0.2684346139431
mseloss[5]:0.5701137185096741, 0.5726026892662048, 0.6850559115409851, 0.3058030307292938
mseloss[6]:0.5799501538276672, 0.5539848804473877, 0.6406832337379456, 0.2560805380344391
mseloss[7]:0.5729361176490784, 0.5381296277046204, 0.5904662013053894, 0.38575848937034607
mseloss[8]:0.5582831501960754, 0.5428924560546875, 0.6618101596832275, 0.2949613332748413
mseloss[9]:0.571660578250885, 0.5493220686912537, 0.6315996646881104, 0.407869428396225
Epoch:198
0
Train Loss: 0.394 | Acc: 89.417 (4064/4545)
Train Loss: 0.000 | Acc: 100.000 (4545/4545)
1
Train Loss: 0.535 | Acc: 85.479 (3885/4545)
Train Loss: 0.025 | Acc: 99.120 (4505/4545)
2
Train Loss: 0.987 | Acc: 77.404 (3518/4545)
Train Loss: 0.072 | Acc: 97.228 (4419/4545)
3
Train Loss: 0.367 | Acc: 87.921 (3996/4545)
Train Loss: 0.037 | Acc: 98.922 (4496/4545)
4
Train Loss: 0.948 | Acc: 77.294 (3513/4545)
Train Loss: 0.106 | Acc: 96.194 (4372/4545)
5
Train Loss: 0.522 | Acc: 83.828 (3810/4545)
Train Loss: 0.121 | Acc: 95.578 (4344/4545)
6
Train Loss: 0.852 | Acc: 78.174 (3553/4545)
Train Loss: 0.048 | Acc: 98.284 (4467/4545)
7
Train Loss: 0.336 | Acc: 87.283 (3967/4545)
Train Loss: 0.137 | Acc: 94.521 (4296/4545)
8
Train Loss: 0.174 | Acc: 93.377 (4244/4545)
Train Loss: 0.013 | Acc: 99.670 (4530/4545)
9
Train Loss: 0.573 | Acc: 85.809 (3900/4545)
Train Loss: 0.000 | Acc: 100.000 (4545/4545)
10
Train Loss: 0.358 | Acc: 87.921 (3996/4545)
Train Loss: 0.019 | Acc: 99.318 (4514/4545)
layer1.0
layer4.1
1.conv1
layer2.0
layer2.1
linear
layer3.0
layer4.0
layer3.1
1.bn1
layer1.1
Test Loss: 9.360 | Acc: 14.990 (1499/10000)
mseloss[1]:0.520994246006012, 0.5229020714759827, 0.5249844193458557, 0.22274446487426758
mseloss[2]:0.5685197114944458, 0.5567725300788879, 0.6358990669250488, 0.24966630339622498
mseloss[3]:0.5210562944412231, 0.5452298521995544, 0.6915989518165588, 0.17828933894634247
mseloss[4]:0.5697522759437561, 0.6082832217216492, 0.8968563675880432, 0.25309839844703674
mseloss[5]:0.5833331942558289, 0.5831517577171326, 0.7167436480522156, 0.3950677514076233
mseloss[6]:0.5311014652252197, 0.5097622275352478, 0.567485511302948, 0.22363875806331635
mseloss[7]:0.567492663860321, 0.5680133700370789, 0.6968620419502258, 0.36931756138801575
mseloss[8]:0.503753662109375, 0.4700931906700134, 0.43130871653556824, 0.19890056550502777
mseloss[9]:0.5232948064804077, 0.48496225476264954, 0.3905566334724426, 0.1678839772939682
Epoch:199
0
Train Loss: 0.529 | Acc: 84.136 (3824/4545)
Train Loss: 0.086 | Acc: 97.030 (4410/4545)
1
Train Loss: 0.477 | Acc: 86.491 (3931/4545)
Train Loss: 0.044 | Acc: 98.416 (4473/4545)
2
Train Loss: 0.399 | Acc: 88.955 (4043/4545)
Train Loss: 0.034 | Acc: 98.856 (4493/4545)
3
Train Loss: 0.371 | Acc: 90.011 (4091/4545)
Train Loss: 0.000 | Acc: 100.000 (4545/4545)
4
Train Loss: 0.340 | Acc: 89.505 (4068/4545)
Train Loss: 0.010 | Acc: 99.670 (4530/4545)
5
Train Loss: 0.285 | Acc: 91.727 (4169/4545)
Train Loss: 0.000 | Acc: 100.000 (4545/4545)
6
Train Loss: 0.332 | Acc: 90.605 (4118/4545)
Train Loss: 0.030 | Acc: 99.098 (4504/4545)
7
Train Loss: 0.208 | Acc: 94.103 (4277/4545)
Train Loss: 0.025 | Acc: 99.186 (4508/4545)
8
Train Loss: 0.374 | Acc: 85.083 (3867/4545)
Train Loss: 0.113 | Acc: 96.216 (4373/4545)
9
Train Loss: 0.526 | Acc: 80.968 (3680/4545)
Train Loss: 0.161 | Acc: 93.553 (4252/4545)
10
Train Loss: 0.588 | Acc: 83.168 (3780/4545)
Train Loss: 0.063 | Acc: 97.954 (4452/4545)
linear
1.conv1
layer1.0
layer4.1
layer4.0
layer2.1
layer2.0
layer1.1
layer3.0
1.bn1
layer3.1
Test Loss: 2.629 | Acc: 20.290 (2029/10000)
mseloss[1]:0.5582774877548218, 0.6322617530822754, 0.5766239762306213, 0.12663644552230835
mseloss[2]:0.5352296233177185, 0.591956615447998, 0.7275150418281555, 0.11808157712221146
mseloss[3]:0.5613894462585449, 0.741783857345581, 1.0821337699890137, 0.17808477580547333
mseloss[4]:0.5450325608253479, 0.6137048602104187, 0.9952645897865295, 0.20150114595890045
mseloss[5]:0.5725838541984558, 0.7704809904098511, 1.0464967489242554, 0.15397608280181885
mseloss[6]:0.5334631204605103, 0.6279840469360352, 1.0279189348220825, 0.20357650518417358
mseloss[7]:0.5528404712677002, 0.614245593547821, 0.9877646565437317, 0.20036257803440094
mseloss[8]:0.5528200268745422, 0.5445292592048645, 0.5339699387550354, 0.18180838227272034
mseloss[9]:0.5544949769973755, 0.6121922135353088, 0.955531656742096, 0.21569271385669708

Evaluating on additional CIFAR-10 testset
Traceback (most recent call last):
  File "/home/jndx/STRAGGLER/mono-cnn-pytorch-main/FedMono/train.py", line 340, in <module>
    corruption_types = [
  File "/home/jndx/STRAGGLER/mono-cnn-pytorch-main/FedMono/train.py", line 183, in test
    net.eval()
AttributeError: 'function' object has no attribute 'eval'
